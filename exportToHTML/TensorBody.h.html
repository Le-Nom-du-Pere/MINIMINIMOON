<html>
<head>
<title>TensorBody.h</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #333333;}
.s1 { color: #000080; font-weight: bold;}
.s2 { color: #660e7a; font-weight: bold;}
.s3 { color: #969896; font-style: italic;}
.s4 { color: #006666; font-weight: bold;}
.s5 { color: #183691; font-weight: bold;}
.s6 { color: #0086b3;}
.ln { color: #333333; font-weight: normal; font-style: normal; }
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
TensorBody.h</font>
</center></td></tr></table>
<pre><a name="l1"><span class="ln">1    </span></a><span class="s0">#pragma once</span>
<a name="l2"><span class="ln">2    </span></a>
<a name="l3"><span class="ln">3    </span></a><span class="s1">#ifdef </span><span class="s0">TORCH_ASSERT_NO_OPERATORS</span>
<a name="l4"><span class="ln">4    </span></a><span class="s1">#error </span><span class="s0">This change adds a dependency on native_functions.yaml,            \</span>
<a name="l5"><span class="ln">5    </span></a>  <span class="s0">meaning the file will need to be re-compiled every time an </span><span class="s2">operator     </span><span class="s0">\</span>
<a name="l6"><span class="ln">6    </span></a>  <span class="s0">is changed or added. Consider </span><span class="s1">if </span><span class="s0">your change would be better placed in  \</span>
<a name="l7"><span class="ln">7    </span></a>  <span class="s0">another file, or </span><span class="s1">if </span><span class="s0">a more specific header might achieve the same goal. \</span>
<a name="l8"><span class="ln">8    </span></a>  <span class="s0">See NOTE: [Tensor vs. TensorBase]</span>
<a name="l9"><span class="ln">9    </span></a><span class="s1">#endif</span>
<a name="l10"><span class="ln">10   </span></a>
<a name="l11"><span class="ln">11   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/Device.h&gt;</span>
<a name="l12"><span class="ln">12   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/Layout.h&gt;</span>
<a name="l13"><span class="ln">13   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/MemoryFormat.h&gt;</span>
<a name="l14"><span class="ln">14   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/QScheme.h&gt;</span>
<a name="l15"><span class="ln">15   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/Stream.h&gt;</span>
<a name="l16"><span class="ln">16   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/Scalar.h&gt;</span>
<a name="l17"><span class="ln">17   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/ScalarType.h&gt;</span>
<a name="l18"><span class="ln">18   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/ScalarTypeToTypeMeta.h&gt;</span>
<a name="l19"><span class="ln">19   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/Storage.h&gt;</span>
<a name="l20"><span class="ln">20   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/TensorImpl.h&gt;</span>
<a name="l21"><span class="ln">21   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/UndefinedTensorImpl.h&gt;</span>
<a name="l22"><span class="ln">22   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/WrapDimMinimal.h&gt;</span>
<a name="l23"><span class="ln">23   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/util/Exception.h&gt;</span>
<a name="l24"><span class="ln">24   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/util/ExclusivelyOwned.h&gt;</span>
<a name="l25"><span class="ln">25   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/util/Deprecated.h&gt;</span>
<a name="l26"><span class="ln">26   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/util/MaybeOwned.h&gt;</span>
<a name="l27"><span class="ln">27   </span></a><span class="s1">#include </span><span class="s0">&lt;optional&gt;</span>
<a name="l28"><span class="ln">28   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/util/OptionalArrayRef.h&gt;</span>
<a name="l29"><span class="ln">29   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/util/intrusive_ptr.h&gt;</span>
<a name="l30"><span class="ln">30   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/macros/Export.h&gt;</span>
<a name="l31"><span class="ln">31   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/CheckMemoryFormat.h&gt;</span>
<a name="l32"><span class="ln">32   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/DeprecatedTypePropertiesRegistry.h&gt;</span>
<a name="l33"><span class="ln">33   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/DeprecatedTypeProperties.h&gt;</span>
<a name="l34"><span class="ln">34   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/NamedTensor.h&gt;</span>
<a name="l35"><span class="ln">35   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/QuantizerBase.h&gt;</span>
<a name="l36"><span class="ln">36   </span></a><span class="s1">#include </span><span class="s0">&lt;c10/core/SymInt.h&gt;</span>
<a name="l37"><span class="ln">37   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/TensorAccessor.h&gt;</span>
<a name="l38"><span class="ln">38   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/core/TensorBase.h&gt;</span>
<a name="l39"><span class="ln">39   </span></a>
<a name="l40"><span class="ln">40   </span></a>
<a name="l41"><span class="ln">41   </span></a><span class="s1">#include </span><span class="s0">&lt;ATen/MethodOperators.h&gt;</span>
<a name="l42"><span class="ln">42   </span></a>
<a name="l43"><span class="ln">43   </span></a><span class="s2">namespace </span><span class="s0">c10{</span>
<a name="l44"><span class="ln">44   </span></a><span class="s0">template&lt;</span><span class="s2">class </span><span class="s0">T&gt; </span><span class="s2">class </span><span class="s0">List;</span>
<a name="l45"><span class="ln">45   </span></a><span class="s0">template&lt;</span><span class="s2">class </span><span class="s0">T&gt; </span><span class="s2">class </span><span class="s0">IListRef;</span>
<a name="l46"><span class="ln">46   </span></a><span class="s0">}</span>
<a name="l47"><span class="ln">47   </span></a><span class="s2">namespace </span><span class="s0">at {</span>
<a name="l48"><span class="ln">48   </span></a><span class="s1">struct </span><span class="s0">Generator;</span>
<a name="l49"><span class="ln">49   </span></a><span class="s1">struct </span><span class="s0">Type;</span>
<a name="l50"><span class="ln">50   </span></a><span class="s2">class </span><span class="s0">DeprecatedTypeProperties;</span>
<a name="l51"><span class="ln">51   </span></a><span class="s2">class </span><span class="s0">Tensor;</span>
<a name="l52"><span class="ln">52   </span></a><span class="s0">} </span><span class="s3">// namespace at</span>
<a name="l53"><span class="ln">53   </span></a><span class="s2">namespace </span><span class="s0">at {</span>
<a name="l54"><span class="ln">54   </span></a><span class="s2">namespace </span><span class="s0">indexing {</span>
<a name="l55"><span class="ln">55   </span></a><span class="s1">struct </span><span class="s0">TensorIndex;</span>
<a name="l56"><span class="ln">56   </span></a><span class="s0">} </span><span class="s3">// namespace indexing</span>
<a name="l57"><span class="ln">57   </span></a><span class="s0">} </span><span class="s3">// namespace at</span>
<a name="l58"><span class="ln">58   </span></a>
<a name="l59"><span class="ln">59   </span></a><span class="s2">namespace </span><span class="s0">torch { </span><span class="s2">namespace </span><span class="s0">autograd {</span>
<a name="l60"><span class="ln">60   </span></a>
<a name="l61"><span class="ln">61   </span></a><span class="s1">struct </span><span class="s0">Node;</span>
<a name="l62"><span class="ln">62   </span></a>
<a name="l63"><span class="ln">63   </span></a><span class="s0">}} </span><span class="s3">// namespace torch::autograd</span>
<a name="l64"><span class="ln">64   </span></a>
<a name="l65"><span class="ln">65   </span></a><span class="s2">namespace </span><span class="s0">at {</span>
<a name="l66"><span class="ln">66   </span></a>
<a name="l67"><span class="ln">67   </span></a><span class="s2">class </span><span class="s0">OptionalTensorRef;</span>
<a name="l68"><span class="ln">68   </span></a><span class="s2">class </span><span class="s0">TensorRef;</span>
<a name="l69"><span class="ln">69   </span></a><span class="s2">class </span><span class="s0">Tensor;</span>
<a name="l70"><span class="ln">70   </span></a><span class="s2">using </span><span class="s0">TensorList = ArrayRef&lt;Tensor&gt;;</span>
<a name="l71"><span class="ln">71   </span></a><span class="s2">using </span><span class="s0">ITensorList = c10::IListRef&lt;Tensor&gt;;</span>
<a name="l72"><span class="ln">72   </span></a>
<a name="l73"><span class="ln">73   </span></a><span class="s2">using </span><span class="s0">Stream = c10::Stream;</span>
<a name="l74"><span class="ln">74   </span></a>
<a name="l75"><span class="ln">75   </span></a><span class="s3">// Tensor is a &quot;generic&quot; object holding a pointer to the underlying TensorImpl object, which</span>
<a name="l76"><span class="ln">76   </span></a><span class="s3">// has an embedded reference count. In this way, Tensor is similar to boost::intrusive_ptr.</span>
<a name="l77"><span class="ln">77   </span></a><span class="s3">//</span>
<a name="l78"><span class="ln">78   </span></a><span class="s3">// For example:</span>
<a name="l79"><span class="ln">79   </span></a><span class="s3">//</span>
<a name="l80"><span class="ln">80   </span></a><span class="s3">// void func(Tensor a) {</span>
<a name="l81"><span class="ln">81   </span></a><span class="s3">//   Tensor b = a;</span>
<a name="l82"><span class="ln">82   </span></a><span class="s3">//   ...</span>
<a name="l83"><span class="ln">83   </span></a><span class="s3">// }</span>
<a name="l84"><span class="ln">84   </span></a><span class="s3">//</span>
<a name="l85"><span class="ln">85   </span></a><span class="s3">// In this example, when we say Tensor b = a, we are creating a new object that points to the</span>
<a name="l86"><span class="ln">86   </span></a><span class="s3">// same underlying TensorImpl, and bumps its reference count. When b goes out of scope, the</span>
<a name="l87"><span class="ln">87   </span></a><span class="s3">// destructor decrements the reference count by calling release() on the TensorImpl it points to.</span>
<a name="l88"><span class="ln">88   </span></a><span class="s3">// The existing constructors, operator overloads, etc. take care to implement the correct semantics.</span>
<a name="l89"><span class="ln">89   </span></a><span class="s3">//</span>
<a name="l90"><span class="ln">90   </span></a><span class="s3">// Note that Tensor can also be NULL, i.e. it is not associated with any underlying TensorImpl, and</span>
<a name="l91"><span class="ln">91   </span></a><span class="s3">// special care must be taken to handle this.</span>
<a name="l92"><span class="ln">92   </span></a><span class="s2">class </span><span class="s0">TORCH_API Tensor: </span><span class="s2">public </span><span class="s0">TensorBase {</span>
<a name="l93"><span class="ln">93   </span></a> <span class="s2">protected</span><span class="s0">:</span>
<a name="l94"><span class="ln">94   </span></a>  <span class="s3">// Create a Tensor with a +0 reference count. Special care must be</span>
<a name="l95"><span class="ln">95   </span></a>  <span class="s3">// taken to avoid decrementing this reference count at destruction</span>
<a name="l96"><span class="ln">96   </span></a>  <span class="s3">// time. Intended to support MaybeOwnedTraits&lt;Tensor&gt;.</span>
<a name="l97"><span class="ln">97   </span></a>  <span class="s2">explicit </span><span class="s0">Tensor(unsafe_borrow_t, </span><span class="s1">const </span><span class="s0">TensorBase&amp; rhs): TensorBase(unsafe_borrow_t{}, rhs) {}</span>
<a name="l98"><span class="ln">98   </span></a>  <span class="s2">friend </span><span class="s0">MaybeOwnedTraits&lt;Tensor&gt;;</span>
<a name="l99"><span class="ln">99   </span></a>  <span class="s2">friend </span><span class="s0">OptionalTensorRef;</span>
<a name="l100"><span class="ln">100  </span></a>  <span class="s2">friend </span><span class="s0">TensorRef;</span>
<a name="l101"><span class="ln">101  </span></a>
<a name="l102"><span class="ln">102  </span></a> <span class="s2">public</span><span class="s0">:</span>
<a name="l103"><span class="ln">103  </span></a>  <span class="s0">Tensor() = </span><span class="s1">default</span><span class="s0">;</span>
<a name="l104"><span class="ln">104  </span></a>  <span class="s3">// This constructor should not be used by end users and is an implementation</span>
<a name="l105"><span class="ln">105  </span></a>  <span class="s3">// detail invoked by autogenerated code.</span>
<a name="l106"><span class="ln">106  </span></a>  <span class="s2">explicit </span><span class="s0">Tensor(</span>
<a name="l107"><span class="ln">107  </span></a>      <span class="s0">c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt; tensor_impl)</span>
<a name="l108"><span class="ln">108  </span></a>      <span class="s0">: TensorBase(std::move(tensor_impl)) {}</span>
<a name="l109"><span class="ln">109  </span></a>  <span class="s0">Tensor(</span><span class="s1">const </span><span class="s0">Tensor &amp;tensor) = </span><span class="s1">default</span><span class="s0">;</span>
<a name="l110"><span class="ln">110  </span></a>  <span class="s0">Tensor(Tensor &amp;&amp;tensor) = </span><span class="s1">default</span><span class="s0">;</span>
<a name="l111"><span class="ln">111  </span></a>
<a name="l112"><span class="ln">112  </span></a>  <span class="s3">// Implicitly move-constructible from TensorBase, but must be explicit to increase refcount</span>
<a name="l113"><span class="ln">113  </span></a>  <span class="s2">explicit </span><span class="s0">Tensor(</span><span class="s1">const </span><span class="s0">TensorBase &amp;base): TensorBase(base) {}</span>
<a name="l114"><span class="ln">114  </span></a>  <span class="s3">/*implicit*/ </span><span class="s0">Tensor(TensorBase &amp;&amp;base): TensorBase(std::move(base)) {}</span>
<a name="l115"><span class="ln">115  </span></a>
<a name="l116"><span class="ln">116  </span></a>  <span class="s3">// Creates a new wrapper from TensorImpl. Intentionally a free method because</span>
<a name="l117"><span class="ln">117  </span></a>  <span class="s3">// it should be used with care. Checks necessary invariants</span>
<a name="l118"><span class="ln">118  </span></a>  <span class="s1">static </span><span class="s0">Tensor wrap_tensor_impl(</span>
<a name="l119"><span class="ln">119  </span></a>      <span class="s0">c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt; tensor_impl) {</span>
<a name="l120"><span class="ln">120  </span></a>    <span class="s1">return </span><span class="s0">TensorBase::wrap_tensor_impl(std::move(tensor_impl));</span>
<a name="l121"><span class="ln">121  </span></a>  <span class="s0">}</span>
<a name="l122"><span class="ln">122  </span></a>
<a name="l123"><span class="ln">123  </span></a>  <span class="s0">Tensor contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l124"><span class="ln">124  </span></a>    <span class="s1">return </span><span class="s0">TensorBase::contiguous(memory_format);</span>
<a name="l125"><span class="ln">125  </span></a>  <span class="s0">}</span>
<a name="l126"><span class="ln">126  </span></a>
<a name="l127"><span class="ln">127  </span></a>  <span class="s0">Tensor conj() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l128"><span class="ln">128  </span></a>    <span class="s1">if </span><span class="s0">(!</span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">is_complex()) {</span>
<a name="l129"><span class="ln">129  </span></a>      <span class="s1">return </span><span class="s0">*</span><span class="s2">this</span><span class="s0">;</span>
<a name="l130"><span class="ln">130  </span></a>    <span class="s0">}</span>
<a name="l131"><span class="ln">131  </span></a>
<a name="l132"><span class="ln">132  </span></a>    <span class="s1">switch </span><span class="s0">(</span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">layout()) {</span>
<a name="l133"><span class="ln">133  </span></a>      <span class="s1">case </span><span class="s0">at::kSparse:</span>
<a name="l134"><span class="ln">134  </span></a>      <span class="s1">case </span><span class="s0">at::kSparseCsr:</span>
<a name="l135"><span class="ln">135  </span></a>      <span class="s1">case </span><span class="s0">at::kSparseCsc:</span>
<a name="l136"><span class="ln">136  </span></a>      <span class="s1">case </span><span class="s0">at::kSparseBsr:</span>
<a name="l137"><span class="ln">137  </span></a>      <span class="s1">case </span><span class="s0">at::kSparseBsc:</span>
<a name="l138"><span class="ln">138  </span></a>        <span class="s1">return </span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">conj_physical();</span>
<a name="l139"><span class="ln">139  </span></a>      <span class="s1">default</span><span class="s0">:</span>
<a name="l140"><span class="ln">140  </span></a>        <span class="s1">return </span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">_conj();</span>
<a name="l141"><span class="ln">141  </span></a>    <span class="s0">}</span>
<a name="l142"><span class="ln">142  </span></a>  <span class="s0">}</span>
<a name="l143"><span class="ln">143  </span></a>
<a name="l144"><span class="ln">144  </span></a>  <span class="s3">// Aliased by Dimname overloads, so need explicit using</span>
<a name="l145"><span class="ln">145  </span></a>  <span class="s2">using </span><span class="s0">TensorBase::size;</span>
<a name="l146"><span class="ln">146  </span></a>  <span class="s2">using </span><span class="s0">TensorBase::sym_size;</span>
<a name="l147"><span class="ln">147  </span></a>  <span class="s2">using </span><span class="s0">TensorBase::stride;</span>
<a name="l148"><span class="ln">148  </span></a>
<a name="l149"><span class="ln">149  </span></a>  <span class="s3">/// Should be used if *this can reasonably be expected to be contiguous and</span>
<a name="l150"><span class="ln">150  </span></a>  <span class="s3">/// performance is important.</span>
<a name="l151"><span class="ln">151  </span></a>  <span class="s3">/// Compared to contiguous, it saves a reference count</span>
<a name="l152"><span class="ln">152  </span></a>  <span class="s3">/// increment/decrement if *this is already contiguous, at the cost</span>
<a name="l153"><span class="ln">153  </span></a>  <span class="s3">/// in all cases of an extra pointer of stack usage, an extra branch</span>
<a name="l154"><span class="ln">154  </span></a>  <span class="s3">/// to access, and an extra branch at destruction time.</span>
<a name="l155"><span class="ln">155  </span></a>  <span class="s0">c10::MaybeOwned&lt;Tensor&gt; expect_contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) </span><span class="s1">const </span><span class="s0">&amp;;</span>
<a name="l156"><span class="ln">156  </span></a>
<a name="l157"><span class="ln">157  </span></a>  <span class="s3">// Use .contiguous() instead. Trying to borrow from a prvalue Tensor</span>
<a name="l158"><span class="ln">158  </span></a>  <span class="s3">// will only lead to trouble and dangling references.</span>
<a name="l159"><span class="ln">159  </span></a>  <span class="s0">c10::MaybeOwned&lt;Tensor&gt; expect_contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) &amp;&amp; = </span><span class="s1">delete</span><span class="s0">;</span>
<a name="l160"><span class="ln">160  </span></a>
<a name="l161"><span class="ln">161  </span></a>  <span class="s3">// The following overloads are very intruiging.  Consider the following</span>
<a name="l162"><span class="ln">162  </span></a>  <span class="s3">// program:</span>
<a name="l163"><span class="ln">163  </span></a>  <span class="s3">//</span>
<a name="l164"><span class="ln">164  </span></a>  <span class="s3">//    x[1] = 3;</span>
<a name="l165"><span class="ln">165  </span></a>  <span class="s3">//</span>
<a name="l166"><span class="ln">166  </span></a>  <span class="s3">// We would expect that the first entry of x is written to 3.  But how can we</span>
<a name="l167"><span class="ln">167  </span></a>  <span class="s3">// actually achieve this?  x[1] evaluates to a tensor...</span>
<a name="l168"><span class="ln">168  </span></a>  <span class="s3">//</span>
<a name="l169"><span class="ln">169  </span></a>  <span class="s3">// The answer is, using a ref-qualifier.  x[1] is an rvalue, which cannot be</span>
<a name="l170"><span class="ln">170  </span></a>  <span class="s3">// (profitably) assigned to in the traditional sense, so we overload</span>
<a name="l171"><span class="ln">171  </span></a>  <span class="s3">// assignment to mean, &quot;Actually, copy 3 into the tensor data.&quot;  This is done</span>
<a name="l172"><span class="ln">172  </span></a>  <span class="s3">// with an rvalue-reference ref-qualified overload (the methods with &amp;&amp; at the</span>
<a name="l173"><span class="ln">173  </span></a>  <span class="s3">// end of their type.)</span>
<a name="l174"><span class="ln">174  </span></a>  <span class="s3">//</span>
<a name="l175"><span class="ln">175  </span></a>  <span class="s3">// There's one more fly in the ointment: We also want</span>
<a name="l176"><span class="ln">176  </span></a>  <span class="s3">//</span>
<a name="l177"><span class="ln">177  </span></a>  <span class="s3">//    Tensor x = y;</span>
<a name="l178"><span class="ln">178  </span></a>  <span class="s3">//</span>
<a name="l179"><span class="ln">179  </span></a>  <span class="s3">// to work, and we want it NOT to copy.  So we need a traditional operator=</span>
<a name="l180"><span class="ln">180  </span></a>  <span class="s3">// overload.  But we MUST specify a mutable lvalue ref-qualifier, to</span>
<a name="l181"><span class="ln">181  </span></a>  <span class="s3">// disambiguate the traditional overload from the rvalue-reference</span>
<a name="l182"><span class="ln">182  </span></a>  <span class="s3">// ref-qualified overload.  Otherwise, it will be ambiguous, because</span>
<a name="l183"><span class="ln">183  </span></a>  <span class="s3">// a non ref-qualified method is eligible for all situations.</span>
<a name="l184"><span class="ln">184  </span></a>
<a name="l185"><span class="ln">185  </span></a>  <span class="s3">// Unfortunately, we have to write these constructors out manually</span>
<a name="l186"><span class="ln">186  </span></a>  <span class="s3">// to work around an MSVC bug:</span>
<a name="l187"><span class="ln">187  </span></a>  <span class="s3">//    error C2580: 'at::Tensor &amp;at::Tensor::operator =(const at::Tensor &amp;) &amp;':</span>
<a name="l188"><span class="ln">188  </span></a>  <span class="s3">//    multiple versions of a defaulted special member functions are not allowed</span>
<a name="l189"><span class="ln">189  </span></a>  <span class="s3">// Tensor&amp; operator=(const Tensor&amp;) &amp; = default;</span>
<a name="l190"><span class="ln">190  </span></a>  <span class="s3">// Tensor&amp; operator=(Tensor&amp;&amp;) &amp; = default;</span>
<a name="l191"><span class="ln">191  </span></a>
<a name="l192"><span class="ln">192  </span></a>  <span class="s3">// Also MSVC will wrongly issue the following warning with the aforementioned fix</span>
<a name="l193"><span class="ln">193  </span></a>  <span class="s3">//    warning C4522: 'at::Tensor': multiple assignment operators specified</span>
<a name="l194"><span class="ln">194  </span></a>  <span class="s3">// Let's just skip the warning.</span>
<a name="l195"><span class="ln">195  </span></a>  <span class="s3">//</span>
<a name="l196"><span class="ln">196  </span></a>  <span class="s3">// TODO: temporarily disabled</span>
<a name="l197"><span class="ln">197  </span></a>
<a name="l198"><span class="ln">198  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(</span><span class="s1">const </span><span class="s0">TensorBase&amp; x) &amp; noexcept {</span>
<a name="l199"><span class="ln">199  </span></a>    <span class="s0">impl_ = x.getIntrusivePtr();</span>
<a name="l200"><span class="ln">200  </span></a>    <span class="s1">return </span><span class="s0">*</span><span class="s2">this</span><span class="s0">;</span>
<a name="l201"><span class="ln">201  </span></a>  <span class="s0">}</span>
<a name="l202"><span class="ln">202  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(TensorBase&amp;&amp; x) &amp; noexcept {</span>
<a name="l203"><span class="ln">203  </span></a>    <span class="s0">impl_ = x.unsafeReleaseIntrusivePtr();</span>
<a name="l204"><span class="ln">204  </span></a>    <span class="s1">return </span><span class="s0">*</span><span class="s2">this</span><span class="s0">;</span>
<a name="l205"><span class="ln">205  </span></a>  <span class="s0">}</span>
<a name="l206"><span class="ln">206  </span></a>
<a name="l207"><span class="ln">207  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(</span><span class="s1">const </span><span class="s0">Tensor &amp;x) &amp; noexcept {</span>
<a name="l208"><span class="ln">208  </span></a>    <span class="s1">return </span><span class="s2">operator</span><span class="s0">=(</span><span class="s2">static_cast</span><span class="s0">&lt;</span><span class="s1">const </span><span class="s0">TensorBase&amp;&gt;(x));</span>
<a name="l209"><span class="ln">209  </span></a>  <span class="s0">}</span>
<a name="l210"><span class="ln">210  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(Tensor &amp;&amp;x) &amp; noexcept {</span>
<a name="l211"><span class="ln">211  </span></a>    <span class="s1">return </span><span class="s2">operator</span><span class="s0">=(</span><span class="s2">static_cast</span><span class="s0">&lt;TensorBase&amp;&amp;&gt;(x));</span>
<a name="l212"><span class="ln">212  </span></a>  <span class="s0">}</span>
<a name="l213"><span class="ln">213  </span></a>
<a name="l214"><span class="ln">214  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(</span><span class="s1">const </span><span class="s0">Scalar &amp;v) &amp;&amp; {</span>
<a name="l215"><span class="ln">215  </span></a>    <span class="s1">return </span><span class="s0">fill_(v);</span>
<a name="l216"><span class="ln">216  </span></a>  <span class="s0">}</span>
<a name="l217"><span class="ln">217  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(</span><span class="s1">const </span><span class="s0">Tensor &amp;rhs) &amp;&amp; {</span>
<a name="l218"><span class="ln">218  </span></a>    <span class="s1">return </span><span class="s0">copy_(rhs);</span>
<a name="l219"><span class="ln">219  </span></a>  <span class="s0">}</span>
<a name="l220"><span class="ln">220  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">=(Tensor&amp;&amp; rhs) &amp;&amp; {</span>
<a name="l221"><span class="ln">221  </span></a>    <span class="s1">return </span><span class="s0">copy_(rhs);</span>
<a name="l222"><span class="ln">222  </span></a>  <span class="s0">}</span>
<a name="l223"><span class="ln">223  </span></a>
<a name="l224"><span class="ln">224  </span></a>  <span class="s0">C10_DEPRECATED_MESSAGE(</span><span class="s5">&quot;Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device().&quot;</span><span class="s0">)</span>
<a name="l225"><span class="ln">225  </span></a>  <span class="s0">DeprecatedTypeProperties &amp; type() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l226"><span class="ln">226  </span></a>    <span class="s1">return </span><span class="s0">globalDeprecatedTypePropertiesRegistry().getDeprecatedTypeProperties(</span>
<a name="l227"><span class="ln">227  </span></a>        <span class="s0">dispatchKeyToBackend(legacyExtractDispatchKey(key_set())),</span>
<a name="l228"><span class="ln">228  </span></a>        <span class="s0">scalar_type());</span>
<a name="l229"><span class="ln">229  </span></a>  <span class="s0">}</span>
<a name="l230"><span class="ln">230  </span></a>
<a name="l231"><span class="ln">231  </span></a>  <span class="s0">Tensor toType(ScalarType t) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l232"><span class="ln">232  </span></a>    <span class="s1">return </span><span class="s0">to(options().dtype(t), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l233"><span class="ln">233  </span></a>  <span class="s0">}</span>
<a name="l234"><span class="ln">234  </span></a>
<a name="l235"><span class="ln">235  </span></a>  <span class="s3">// TODO: Deprecate me</span>
<a name="l236"><span class="ln">236  </span></a>  <span class="s0">Tensor toBackend(Backend b) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l237"><span class="ln">237  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(backendToDeviceType(b)).layout(layout_from_backend(b)), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l238"><span class="ln">238  </span></a>  <span class="s0">}</span>
<a name="l239"><span class="ln">239  </span></a>
<a name="l240"><span class="ln">240  </span></a>  <span class="s0">C10_DEPRECATED_MESSAGE(</span><span class="s5">&quot;Tensor.is_variable() is deprecated; everything is a variable now. (If you want to assert that variable has been appropriately handled already, use at::impl::variable_excluded_from_dispatch())&quot;</span><span class="s0">)</span>
<a name="l241"><span class="ln">241  </span></a>  <span class="s1">bool </span><span class="s0">is_variable() </span><span class="s1">const </span><span class="s0">noexcept {</span>
<a name="l242"><span class="ln">242  </span></a>    <span class="s1">return </span><span class="s0">!at::impl::variable_excluded_from_dispatch();</span>
<a name="l243"><span class="ln">243  </span></a>  <span class="s0">}</span>
<a name="l244"><span class="ln">244  </span></a>
<a name="l245"><span class="ln">245  </span></a>  <span class="s0">template&lt;</span><span class="s2">typename </span><span class="s0">T&gt;</span>
<a name="l246"><span class="ln">246  </span></a>  <span class="s0">C10_DEPRECATED_MESSAGE(</span><span class="s5">&quot;Tensor.data&lt;T&gt;() is deprecated. Please use Tensor.data_ptr&lt;T&gt;() instead.&quot;</span><span class="s0">)</span>
<a name="l247"><span class="ln">247  </span></a>  <span class="s0">T * data() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l248"><span class="ln">248  </span></a>    <span class="s1">return </span><span class="s0">data_ptr&lt;T&gt;();</span>
<a name="l249"><span class="ln">249  </span></a>  <span class="s0">}</span>
<a name="l250"><span class="ln">250  </span></a>
<a name="l251"><span class="ln">251  </span></a>  <span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">T&gt;</span>
<a name="l252"><span class="ln">252  </span></a>  <span class="s0">T item() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l253"><span class="ln">253  </span></a>
<a name="l254"><span class="ln">254  </span></a>  <span class="s0">template&lt;</span><span class="s2">typename </span><span class="s0">T, size_t N, template &lt;</span><span class="s2">typename </span><span class="s0">U&gt; </span><span class="s2">class </span><span class="s0">PtrTraits = DefaultPtrTraits, </span><span class="s2">typename </span><span class="s0">index_t = int64_t&gt;</span>
<a name="l255"><span class="ln">255  </span></a>  <span class="s0">C10_DEPRECATED_MESSAGE(</span><span class="s5">&quot;packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead&quot;</span><span class="s0">)</span>
<a name="l256"><span class="ln">256  </span></a>  <span class="s0">GenericPackedTensorAccessor&lt;T,N,PtrTraits,index_t&gt; packed_accessor() </span><span class="s1">const </span><span class="s0">&amp; {</span>
<a name="l257"><span class="ln">257  </span></a>    <span class="s1">return </span><span class="s0">generic_packed_accessor&lt;T,N,PtrTraits,index_t&gt;();</span>
<a name="l258"><span class="ln">258  </span></a>  <span class="s0">}</span>
<a name="l259"><span class="ln">259  </span></a>  <span class="s0">template&lt;</span><span class="s2">typename </span><span class="s0">T, size_t N, template &lt;</span><span class="s2">typename </span><span class="s0">U&gt; </span><span class="s2">class </span><span class="s0">PtrTraits = DefaultPtrTraits, </span><span class="s2">typename </span><span class="s0">index_t = int64_t&gt;</span>
<a name="l260"><span class="ln">260  </span></a>  <span class="s0">C10_DEPRECATED_MESSAGE(</span><span class="s5">&quot;packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead&quot;</span><span class="s0">)</span>
<a name="l261"><span class="ln">261  </span></a>  <span class="s0">GenericPackedTensorAccessor&lt;T,N,PtrTraits,index_t&gt; packed_accessor() &amp;&amp; = </span><span class="s1">delete</span><span class="s0">;</span>
<a name="l262"><span class="ln">262  </span></a>
<a name="l263"><span class="ln">263  </span></a>  <span class="s0">Tensor </span><span class="s2">operator</span><span class="s0">~() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l264"><span class="ln">264  </span></a>    <span class="s1">return </span><span class="s0">bitwise_not();</span>
<a name="l265"><span class="ln">265  </span></a>  <span class="s0">}</span>
<a name="l266"><span class="ln">266  </span></a>  <span class="s0">Tensor </span><span class="s2">operator</span><span class="s0">-() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l267"><span class="ln">267  </span></a>    <span class="s1">return </span><span class="s0">neg();</span>
<a name="l268"><span class="ln">268  </span></a>  <span class="s0">}</span>
<a name="l269"><span class="ln">269  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">+=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l270"><span class="ln">270  </span></a>    <span class="s1">return </span><span class="s0">add_(other);</span>
<a name="l271"><span class="ln">271  </span></a>  <span class="s0">}</span>
<a name="l272"><span class="ln">272  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">+=(</span><span class="s1">const </span><span class="s0">Scalar &amp; other) {</span>
<a name="l273"><span class="ln">273  </span></a>    <span class="s1">return </span><span class="s0">add_(other);</span>
<a name="l274"><span class="ln">274  </span></a>  <span class="s0">}</span>
<a name="l275"><span class="ln">275  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">-=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l276"><span class="ln">276  </span></a>    <span class="s1">return </span><span class="s0">sub_(other);</span>
<a name="l277"><span class="ln">277  </span></a>  <span class="s0">}</span>
<a name="l278"><span class="ln">278  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">-=(</span><span class="s1">const </span><span class="s0">Scalar &amp; other) {</span>
<a name="l279"><span class="ln">279  </span></a>    <span class="s1">return </span><span class="s0">sub_(other);</span>
<a name="l280"><span class="ln">280  </span></a>  <span class="s0">}</span>
<a name="l281"><span class="ln">281  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">*=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l282"><span class="ln">282  </span></a>    <span class="s1">return </span><span class="s0">mul_(other);</span>
<a name="l283"><span class="ln">283  </span></a>  <span class="s0">}</span>
<a name="l284"><span class="ln">284  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">*=(</span><span class="s1">const </span><span class="s0">Scalar &amp; other) {</span>
<a name="l285"><span class="ln">285  </span></a>    <span class="s1">return </span><span class="s0">mul_(other);</span>
<a name="l286"><span class="ln">286  </span></a>  <span class="s0">}</span>
<a name="l287"><span class="ln">287  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">/=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l288"><span class="ln">288  </span></a>    <span class="s1">return </span><span class="s0">div_(other);</span>
<a name="l289"><span class="ln">289  </span></a>  <span class="s0">}</span>
<a name="l290"><span class="ln">290  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">/=(</span><span class="s1">const </span><span class="s0">Scalar &amp; other) {</span>
<a name="l291"><span class="ln">291  </span></a>    <span class="s1">return </span><span class="s0">div_(other);</span>
<a name="l292"><span class="ln">292  </span></a>  <span class="s0">}</span>
<a name="l293"><span class="ln">293  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">&amp;=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l294"><span class="ln">294  </span></a>    <span class="s1">return </span><span class="s0">bitwise_and_(other);</span>
<a name="l295"><span class="ln">295  </span></a>  <span class="s0">}</span>
<a name="l296"><span class="ln">296  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">|=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l297"><span class="ln">297  </span></a>    <span class="s1">return </span><span class="s0">bitwise_or_(other);</span>
<a name="l298"><span class="ln">298  </span></a>  <span class="s0">}</span>
<a name="l299"><span class="ln">299  </span></a>  <span class="s0">Tensor&amp; </span><span class="s2">operator</span><span class="s0">^=(</span><span class="s1">const </span><span class="s0">Tensor &amp; other) {</span>
<a name="l300"><span class="ln">300  </span></a>    <span class="s1">return </span><span class="s0">bitwise_xor_(other);</span>
<a name="l301"><span class="ln">301  </span></a>  <span class="s0">}</span>
<a name="l302"><span class="ln">302  </span></a>  <span class="s0">Tensor </span><span class="s2">operator</span><span class="s0">[](</span><span class="s1">const </span><span class="s0">Scalar &amp; index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l303"><span class="ln">303  </span></a>    <span class="s1">if </span><span class="s0">(!index.isIntegral(</span><span class="s1">false</span><span class="s0">)) {</span>
<a name="l304"><span class="ln">304  </span></a>      <span class="s0">TORCH_CHECK_INDEX(</span><span class="s1">false</span><span class="s0">, </span><span class="s5">&quot;Can only index tensors with integral scalars&quot;</span><span class="s0">);</span>
<a name="l305"><span class="ln">305  </span></a>    <span class="s0">}</span>
<a name="l306"><span class="ln">306  </span></a>    <span class="s1">return </span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s2">operator</span><span class="s0">[](index.toLong());</span>
<a name="l307"><span class="ln">307  </span></a>  <span class="s0">}</span>
<a name="l308"><span class="ln">308  </span></a>  <span class="s0">Tensor </span><span class="s2">operator</span><span class="s0">[](</span><span class="s1">const </span><span class="s0">Tensor &amp; index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l309"><span class="ln">309  </span></a>    <span class="s3">// These properties are checked in the Scalar constructor, but we already</span>
<a name="l310"><span class="ln">310  </span></a>    <span class="s3">// check them here to provide more useful diagnostics for the user.</span>
<a name="l311"><span class="ln">311  </span></a>    <span class="s1">if </span><span class="s0">(!index.defined()) {</span>
<a name="l312"><span class="ln">312  </span></a>      <span class="s0">TORCH_CHECK_INDEX(</span><span class="s1">false</span><span class="s0">, </span><span class="s5">&quot;Can only index with tensors that are defined&quot;</span><span class="s0">);</span>
<a name="l313"><span class="ln">313  </span></a>    <span class="s0">}</span>
<a name="l314"><span class="ln">314  </span></a>    <span class="s1">if </span><span class="s0">(index.dim() != </span><span class="s6">0</span><span class="s0">) {</span>
<a name="l315"><span class="ln">315  </span></a>      <span class="s0">TORCH_CHECK_INDEX(</span><span class="s1">false</span><span class="s0">,</span>
<a name="l316"><span class="ln">316  </span></a>                        <span class="s5">&quot;Can only index with tensors that are scalars (zero-dim)&quot;</span><span class="s0">);</span>
<a name="l317"><span class="ln">317  </span></a>    <span class="s0">}</span>
<a name="l318"><span class="ln">318  </span></a>    <span class="s3">// The Scalar(Tensor) constructor is explicit, so we need to call it.</span>
<a name="l319"><span class="ln">319  </span></a>    <span class="s1">return </span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s2">operator</span><span class="s0">[](index.item());</span>
<a name="l320"><span class="ln">320  </span></a>  <span class="s0">}</span>
<a name="l321"><span class="ln">321  </span></a>  <span class="s0">Tensor </span><span class="s2">operator</span><span class="s0">[](int64_t index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l322"><span class="ln">322  </span></a>    <span class="s1">return </span><span class="s0">select(</span><span class="s6">0</span><span class="s0">, index);</span>
<a name="l323"><span class="ln">323  </span></a>  <span class="s0">}</span>
<a name="l324"><span class="ln">324  </span></a>
<a name="l325"><span class="ln">325  </span></a>  <span class="s0">Tensor index(ArrayRef&lt;at::indexing::TensorIndex&gt; indices) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l326"><span class="ln">326  </span></a>  <span class="s0">Tensor index(std::initializer_list&lt;at::indexing::TensorIndex&gt; indices) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l327"><span class="ln">327  </span></a>
<a name="l328"><span class="ln">328  </span></a>  <span class="s0">Tensor &amp; index_put_(ArrayRef&lt;at::indexing::TensorIndex&gt; indices, Tensor </span><span class="s1">const </span><span class="s0">&amp; rhs);</span>
<a name="l329"><span class="ln">329  </span></a>  <span class="s0">Tensor &amp; index_put_(ArrayRef&lt;at::indexing::TensorIndex&gt; indices, </span><span class="s1">const </span><span class="s0">Scalar&amp; v);</span>
<a name="l330"><span class="ln">330  </span></a>  <span class="s0">Tensor &amp; index_put_(std::initializer_list&lt;at::indexing::TensorIndex&gt; indices, Tensor </span><span class="s1">const </span><span class="s0">&amp; rhs);</span>
<a name="l331"><span class="ln">331  </span></a>  <span class="s0">Tensor &amp; index_put_(std::initializer_list&lt;at::indexing::TensorIndex&gt; indices, </span><span class="s1">const </span><span class="s0">Scalar&amp; v);</span>
<a name="l332"><span class="ln">332  </span></a>
<a name="l333"><span class="ln">333  </span></a>  <span class="s0">Tensor cpu() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l334"><span class="ln">334  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::CPU), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l335"><span class="ln">335  </span></a>  <span class="s0">}</span>
<a name="l336"><span class="ln">336  </span></a>
<a name="l337"><span class="ln">337  </span></a>  <span class="s3">// TODO: The Python version also accepts arguments</span>
<a name="l338"><span class="ln">338  </span></a>  <span class="s0">Tensor cuda() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l339"><span class="ln">339  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::CUDA), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l340"><span class="ln">340  </span></a>  <span class="s0">}</span>
<a name="l341"><span class="ln">341  </span></a>
<a name="l342"><span class="ln">342  </span></a>  <span class="s0">Tensor hip() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l343"><span class="ln">343  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::HIP), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l344"><span class="ln">344  </span></a>  <span class="s0">}</span>
<a name="l345"><span class="ln">345  </span></a>
<a name="l346"><span class="ln">346  </span></a>  <span class="s0">Tensor ve() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l347"><span class="ln">347  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::VE), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l348"><span class="ln">348  </span></a>  <span class="s0">}</span>
<a name="l349"><span class="ln">349  </span></a>
<a name="l350"><span class="ln">350  </span></a>  <span class="s0">Tensor vulkan() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l351"><span class="ln">351  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::Vulkan), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l352"><span class="ln">352  </span></a>  <span class="s0">}</span>
<a name="l353"><span class="ln">353  </span></a>
<a name="l354"><span class="ln">354  </span></a>  <span class="s0">Tensor metal() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l355"><span class="ln">355  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::Metal), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l356"><span class="ln">356  </span></a>  <span class="s0">}</span>
<a name="l357"><span class="ln">357  </span></a>
<a name="l358"><span class="ln">358  </span></a>  <span class="s0">Tensor meta() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l359"><span class="ln">359  </span></a>    <span class="s1">return </span><span class="s0">to(options().device(c10::DeviceType::Meta), </span><span class="s3">/*non_blocking*/ </span><span class="s1">false</span><span class="s0">, </span><span class="s3">/*copy*/ </span><span class="s1">false</span><span class="s0">);</span>
<a name="l360"><span class="ln">360  </span></a>  <span class="s0">}</span>
<a name="l361"><span class="ln">361  </span></a>
<a name="l362"><span class="ln">362  </span></a>  <span class="s3">// ~~~~~ Autograd API ~~~~~</span>
<a name="l363"><span class="ln">363  </span></a>
<a name="l364"><span class="ln">364  </span></a>  <span class="s3">/// \fn bool is_leaf() const;</span>
<a name="l365"><span class="ln">365  </span></a>  <span class="s3">///</span>
<a name="l366"><span class="ln">366  </span></a>  <span class="s3">/// All Tensors that have `requires_grad()` which is ``false`` will be leaf Tensors by convention.</span>
<a name="l367"><span class="ln">367  </span></a>  <span class="s3">///</span>
<a name="l368"><span class="ln">368  </span></a>  <span class="s3">/// For Tensors that have `requires_grad()` which is ``true``, they will be leaf Tensors if they were</span>
<a name="l369"><span class="ln">369  </span></a>  <span class="s3">/// created by the user. This means that they are not the result of an operation and so</span>
<a name="l370"><span class="ln">370  </span></a>  <span class="s3">/// `grad_fn()` is `nullptr`.</span>
<a name="l371"><span class="ln">371  </span></a>  <span class="s3">///</span>
<a name="l372"><span class="ln">372  </span></a>  <span class="s3">/// Only leaf Tensors will have their `grad()` populated during a call to `backward()`.</span>
<a name="l373"><span class="ln">373  </span></a>  <span class="s3">/// To get `grad()` populated for non-leaf Tensors, you can use `retain_grad()`.</span>
<a name="l374"><span class="ln">374  </span></a>  <span class="s3">///</span>
<a name="l375"><span class="ln">375  </span></a>  <span class="s3">/// Example:</span>
<a name="l376"><span class="ln">376  </span></a>  <span class="s3">/// @code</span>
<a name="l377"><span class="ln">377  </span></a>  <span class="s3">/// auto a = torch::rand(10, torch::requires_grad());</span>
<a name="l378"><span class="ln">378  </span></a>  <span class="s3">/// std::cout &lt;&lt; a.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<a name="l379"><span class="ln">379  </span></a>  <span class="s3">///</span>
<a name="l380"><span class="ln">380  </span></a>  <span class="s3">/// auto b = torch::rand(10, torch::requires_grad()).to(torch::kCUDA);</span>
<a name="l381"><span class="ln">381  </span></a>  <span class="s3">/// std::cout &lt;&lt; b.is_leaf() &lt;&lt; std::endl; // prints `false`</span>
<a name="l382"><span class="ln">382  </span></a>  <span class="s3">/// // b was created by the operation that cast a cpu Tensor into a cuda Tensor</span>
<a name="l383"><span class="ln">383  </span></a>  <span class="s3">///</span>
<a name="l384"><span class="ln">384  </span></a>  <span class="s3">/// auto c = torch::rand(10, torch::requires_grad()) + 2;</span>
<a name="l385"><span class="ln">385  </span></a>  <span class="s3">/// std::cout &lt;&lt; c.is_leaf() &lt;&lt; std::endl; // prints `false`</span>
<a name="l386"><span class="ln">386  </span></a>  <span class="s3">/// // c was created by the addition operation</span>
<a name="l387"><span class="ln">387  </span></a>  <span class="s3">///</span>
<a name="l388"><span class="ln">388  </span></a>  <span class="s3">/// auto d = torch::rand(10).cuda();</span>
<a name="l389"><span class="ln">389  </span></a>  <span class="s3">/// std::cout &lt;&lt; d.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<a name="l390"><span class="ln">390  </span></a>  <span class="s3">/// // d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)</span>
<a name="l391"><span class="ln">391  </span></a>  <span class="s3">///</span>
<a name="l392"><span class="ln">392  </span></a>  <span class="s3">/// auto e = torch::rand(10).cuda().requires_grad_();</span>
<a name="l393"><span class="ln">393  </span></a>  <span class="s3">/// std::cout &lt;&lt; e.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<a name="l394"><span class="ln">394  </span></a>  <span class="s3">/// // e requires gradients and has no operations creating it</span>
<a name="l395"><span class="ln">395  </span></a>  <span class="s3">///</span>
<a name="l396"><span class="ln">396  </span></a>  <span class="s3">/// auto f = torch::rand(10, torch::device(torch::kCUDA).requires_grad(true));</span>
<a name="l397"><span class="ln">397  </span></a>  <span class="s3">/// std::cout &lt;&lt; f.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<a name="l398"><span class="ln">398  </span></a>  <span class="s3">/// // f requires grad, has no operation creating it</span>
<a name="l399"><span class="ln">399  </span></a>  <span class="s3">/// @endcode</span>
<a name="l400"><span class="ln">400  </span></a>
<a name="l401"><span class="ln">401  </span></a>  <span class="s3">/// \fn void backward(const Tensor &amp; gradient={}, std::optional&lt;bool&gt; retain_graph=std::nullopt, bool create_graph=false, std::optional&lt;TensorList&gt; inputs=std::nullopt) const;</span>
<a name="l402"><span class="ln">402  </span></a>  <span class="s3">///</span>
<a name="l403"><span class="ln">403  </span></a>  <span class="s3">/// Computes the gradient of current tensor with respect to graph leaves.</span>
<a name="l404"><span class="ln">404  </span></a>  <span class="s3">///</span>
<a name="l405"><span class="ln">405  </span></a>  <span class="s3">/// The graph is differentiated using the chain rule. If the tensor is</span>
<a name="l406"><span class="ln">406  </span></a>  <span class="s3">/// non-scalar (i.e. its data has more than one element) and requires</span>
<a name="l407"><span class="ln">407  </span></a>  <span class="s3">/// gradient, the function additionally requires specifying ``gradient``.</span>
<a name="l408"><span class="ln">408  </span></a>  <span class="s3">/// It should be a tensor of matching type and location, that contains</span>
<a name="l409"><span class="ln">409  </span></a>  <span class="s3">/// the gradient of the differentiated function w.r.t. this Tensor.</span>
<a name="l410"><span class="ln">410  </span></a>  <span class="s3">///</span>
<a name="l411"><span class="ln">411  </span></a>  <span class="s3">/// This function accumulates gradients in the leaves - you might need to</span>
<a name="l412"><span class="ln">412  </span></a>  <span class="s3">/// zero them before calling it.</span>
<a name="l413"><span class="ln">413  </span></a>  <span class="s3">///</span>
<a name="l414"><span class="ln">414  </span></a>  <span class="s3">/// \param gradient Gradient w.r.t. the</span>
<a name="l415"><span class="ln">415  </span></a>  <span class="s3">///     tensor. If it is a tensor, it will be automatically converted</span>
<a name="l416"><span class="ln">416  </span></a>  <span class="s3">///     to a Tensor that does not require grad unless ``create_graph`` is True.</span>
<a name="l417"><span class="ln">417  </span></a>  <span class="s3">///     None values can be specified for scalar Tensors or ones that</span>
<a name="l418"><span class="ln">418  </span></a>  <span class="s3">///     don't require grad. If a None value would be acceptable then</span>
<a name="l419"><span class="ln">419  </span></a>  <span class="s3">///     this argument is optional.</span>
<a name="l420"><span class="ln">420  </span></a>  <span class="s3">/// \param retain_graph If ``false``, the graph used to compute</span>
<a name="l421"><span class="ln">421  </span></a>  <span class="s3">///     the grads will be freed. Note that in nearly all cases setting</span>
<a name="l422"><span class="ln">422  </span></a>  <span class="s3">///     this option to True is not needed and often can be worked around</span>
<a name="l423"><span class="ln">423  </span></a>  <span class="s3">///     in a much more efficient way. Defaults to the value of</span>
<a name="l424"><span class="ln">424  </span></a>  <span class="s3">///     ``create_graph``.</span>
<a name="l425"><span class="ln">425  </span></a>  <span class="s3">/// \param create_graph If ``true``, graph of the derivative will</span>
<a name="l426"><span class="ln">426  </span></a>  <span class="s3">///     be constructed, allowing to compute higher order derivative</span>
<a name="l427"><span class="ln">427  </span></a>  <span class="s3">///     products. Defaults to ``false``.</span>
<a name="l428"><span class="ln">428  </span></a>  <span class="s3">/// \param inputs Inputs w.r.t. which the gradient will be accumulated into</span>
<a name="l429"><span class="ln">429  </span></a>  <span class="s3">///     ``at::Tensor::grad``. All other Tensors will be ignored. If not</span>
<a name="l430"><span class="ln">430  </span></a>  <span class="s3">///     provided, the gradient is accumulated into all the leaf Tensors</span>
<a name="l431"><span class="ln">431  </span></a>  <span class="s3">///     that were used to compute the current tensor.</span>
<a name="l432"><span class="ln">432  </span></a>  <span class="s3">///     When inputs are provided and a given input is not a leaf,</span>
<a name="l433"><span class="ln">433  </span></a>  <span class="s3">///     the current implementation will call its grad_fn (even though it is not strictly needed to get this gradients).</span>
<a name="l434"><span class="ln">434  </span></a>  <span class="s3">///     It is an implementation detail on which the user should not rely.</span>
<a name="l435"><span class="ln">435  </span></a>  <span class="s3">///     See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.</span>
<a name="l436"><span class="ln">436  </span></a>  <span class="s1">void </span><span class="s0">backward(</span><span class="s1">const </span><span class="s0">Tensor &amp; gradient={}, std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; retain_graph=std::nullopt, </span><span class="s1">bool </span><span class="s0">create_graph=</span><span class="s1">false</span><span class="s0">, std::optional&lt;TensorList&gt; inputs=std::nullopt) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l437"><span class="ln">437  </span></a>    <span class="s3">// NB: Adding this wrapper to _backward here because we'd like our</span>
<a name="l438"><span class="ln">438  </span></a>    <span class="s3">// 'backwards' api to accept the 'inputs' argument optionally. Since code gen</span>
<a name="l439"><span class="ln">439  </span></a>    <span class="s3">// currently does not support optional of TensorList our approach is to replace</span>
<a name="l440"><span class="ln">440  </span></a>    <span class="s3">// backward in native_functions.yaml with _backward and call it here instead.</span>
<a name="l441"><span class="ln">441  </span></a>    <span class="s1">if </span><span class="s0">(inputs.has_value()) {</span>
<a name="l442"><span class="ln">442  </span></a>      <span class="s0">TORCH_CHECK(inputs.value().size() &gt; </span><span class="s6">0</span><span class="s0">, </span><span class="s5">&quot;'inputs' argument to backward cannot be empty&quot;</span><span class="s0">)</span>
<a name="l443"><span class="ln">443  </span></a>      <span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">_backward(inputs.value(), gradient, retain_graph, create_graph);</span>
<a name="l444"><span class="ln">444  </span></a>    <span class="s0">} </span><span class="s1">else </span><span class="s0">{</span>
<a name="l445"><span class="ln">445  </span></a>      <span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">_backward({}, gradient, retain_graph, create_graph);</span>
<a name="l446"><span class="ln">446  </span></a>    <span class="s0">}</span>
<a name="l447"><span class="ln">447  </span></a>  <span class="s0">}</span>
<a name="l448"><span class="ln">448  </span></a>
<a name="l449"><span class="ln">449  </span></a>  <span class="s3">/// \fn Tensor detach() const;</span>
<a name="l450"><span class="ln">450  </span></a>  <span class="s3">///</span>
<a name="l451"><span class="ln">451  </span></a>  <span class="s3">/// Returns a new Tensor, detached from the current graph.</span>
<a name="l452"><span class="ln">452  </span></a>  <span class="s3">/// The result will never require gradient.</span>
<a name="l453"><span class="ln">453  </span></a>
<a name="l454"><span class="ln">454  </span></a>  <span class="s3">/// \fn Tensor &amp; detach_() const;</span>
<a name="l455"><span class="ln">455  </span></a>  <span class="s3">///</span>
<a name="l456"><span class="ln">456  </span></a>  <span class="s3">/// Detaches the Tensor from the graph that created it, making it a leaf.</span>
<a name="l457"><span class="ln">457  </span></a>  <span class="s3">/// Views cannot be detached in-place.</span>
<a name="l458"><span class="ln">458  </span></a>
<a name="l459"><span class="ln">459  </span></a>  <span class="s3">/// \fn void retain_grad() const;</span>
<a name="l460"><span class="ln">460  </span></a>  <span class="s3">///</span>
<a name="l461"><span class="ln">461  </span></a>  <span class="s3">/// Enables this Tensor to have their :attr:`grad` populated during</span>
<a name="l462"><span class="ln">462  </span></a>  <span class="s3">/// :func:`backward`. This is a no-op for leaf tensors.</span>
<a name="l463"><span class="ln">463  </span></a>
<a name="l464"><span class="ln">464  </span></a>  <span class="s3">/// \fn bool retains_grad() const;</span>
<a name="l465"><span class="ln">465  </span></a>  <span class="s3">///</span>
<a name="l466"><span class="ln">466  </span></a>  <span class="s3">/// Is ``true`` if this Tensor is non-leaf and its :attr:`grad` is enabled to be</span>
<a name="l467"><span class="ln">467  </span></a>  <span class="s3">/// populated during :func:`backward`, ``false`` otherwise.</span>
<a name="l468"><span class="ln">468  </span></a>
<a name="l469"><span class="ln">469  </span></a>  <span class="s1">const </span><span class="s0">Tensor&amp; set_requires_grad(</span><span class="s1">bool </span><span class="s0">requires_grad) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l470"><span class="ln">470  </span></a>    <span class="s0">TensorBase::set_requires_grad(requires_grad);</span>
<a name="l471"><span class="ln">471  </span></a>    <span class="s1">return </span><span class="s0">*</span><span class="s2">this</span><span class="s0">;</span>
<a name="l472"><span class="ln">472  </span></a>  <span class="s0">}</span>
<a name="l473"><span class="ln">473  </span></a>
<a name="l474"><span class="ln">474  </span></a>  <span class="s3">/// Return a mutable reference to the gradient. This is conventionally</span>
<a name="l475"><span class="ln">475  </span></a>  <span class="s3">/// used as `t.grad() = x` to set a gradient to a completely new tensor.</span>
<a name="l476"><span class="ln">476  </span></a>  <span class="s3">/// Note that this function work with a non-const Tensor and is not</span>
<a name="l477"><span class="ln">477  </span></a>  <span class="s3">/// thread safe.</span>
<a name="l478"><span class="ln">478  </span></a>  <span class="s0">Tensor&amp; mutable_grad() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l479"><span class="ln">479  </span></a>    <span class="s1">return </span><span class="s0">impl_</span><span class="s4">-&gt;</span><span class="s0">mutable_grad();</span>
<a name="l480"><span class="ln">480  </span></a>  <span class="s0">}</span>
<a name="l481"><span class="ln">481  </span></a>
<a name="l482"><span class="ln">482  </span></a>  <span class="s3">/// This function returns an undefined tensor by default and returns a defined tensor</span>
<a name="l483"><span class="ln">483  </span></a>  <span class="s3">/// the first time a call to `backward()` computes gradients for this Tensor.</span>
<a name="l484"><span class="ln">484  </span></a>  <span class="s3">/// The attribute will then contain the gradients computed and future calls</span>
<a name="l485"><span class="ln">485  </span></a>  <span class="s3">/// to `backward()` will accumulate (add) gradients into it.</span>
<a name="l486"><span class="ln">486  </span></a>  <span class="s1">const </span><span class="s0">Tensor&amp; grad() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l487"><span class="ln">487  </span></a>    <span class="s1">const </span><span class="s0">Tensor&amp; maybe_grad = impl_</span><span class="s4">-&gt;</span><span class="s0">grad();</span>
<a name="l488"><span class="ln">488  </span></a>    <span class="s1">if </span><span class="s0">(!is_leaf() &amp;&amp; !retains_grad() &amp;&amp; !maybe_grad.defined()) {</span>
<a name="l489"><span class="ln">489  </span></a>      <span class="s0">TORCH_WARN(</span>
<a name="l490"><span class="ln">490  </span></a>        <span class="s5">&quot;The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad &quot;</span>
<a name="l491"><span class="ln">491  </span></a>        <span class="s5">&quot;attribute won't be populated during autograd.backward(). If you indeed want the .grad &quot;</span>
<a name="l492"><span class="ln">492  </span></a>        <span class="s5">&quot;field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. &quot;</span>
<a name="l493"><span class="ln">493  </span></a>        <span class="s5">&quot;If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor &quot;</span>
<a name="l494"><span class="ln">494  </span></a>        <span class="s5">&quot;instead. See github.com/pytorch/pytorch/pull/30531 for more informations.&quot;</span><span class="s0">);</span>
<a name="l495"><span class="ln">495  </span></a>    <span class="s0">}</span>
<a name="l496"><span class="ln">496  </span></a>    <span class="s1">return </span><span class="s0">maybe_grad;</span>
<a name="l497"><span class="ln">497  </span></a>  <span class="s0">}</span>
<a name="l498"><span class="ln">498  </span></a>
<a name="l499"><span class="ln">499  </span></a>  <span class="s3">// The Forward AD API functions below are low level and are not to be used by end</span>
<a name="l500"><span class="ln">500  </span></a>  <span class="s3">// users who should use the API provided in torch/csrc/autograd.h</span>
<a name="l501"><span class="ln">501  </span></a>
<a name="l502"><span class="ln">502  </span></a>  <span class="s3">/// This function returns the forward gradient for this Tensor at the given level.</span>
<a name="l503"><span class="ln">503  </span></a>  <span class="s1">const </span><span class="s0">Tensor&amp; _fw_grad(uint64_t level) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l504"><span class="ln">504  </span></a>    <span class="s1">return </span><span class="s0">impl_</span><span class="s4">-&gt;</span><span class="s0">_fw_grad(level, *</span><span class="s2">this</span><span class="s0">);</span>
<a name="l505"><span class="ln">505  </span></a>  <span class="s0">}</span>
<a name="l506"><span class="ln">506  </span></a>
<a name="l507"><span class="ln">507  </span></a>  <span class="s3">/// This function can be used to set the value of the forward grad.</span>
<a name="l508"><span class="ln">508  </span></a>  <span class="s3">/// Note that the given new_grad might not be used directly if it has different</span>
<a name="l509"><span class="ln">509  </span></a>  <span class="s3">/// metadata (size/stride/storage offset) compared to this Tensor. In that case,</span>
<a name="l510"><span class="ln">510  </span></a>  <span class="s3">/// new_grad content will be copied into a new Tensor</span>
<a name="l511"><span class="ln">511  </span></a>  <span class="s1">void </span><span class="s0">_set_fw_grad(</span><span class="s1">const </span><span class="s0">TensorBase&amp; new_grad, uint64_t level, </span><span class="s1">bool </span><span class="s0">is_inplace_op) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l512"><span class="ln">512  </span></a>    <span class="s0">impl_</span><span class="s4">-&gt;</span><span class="s0">_set_fw_grad(new_grad, *</span><span class="s2">this</span><span class="s0">, level, is_inplace_op);</span>
<a name="l513"><span class="ln">513  </span></a>  <span class="s0">}</span>
<a name="l514"><span class="ln">514  </span></a>
<a name="l515"><span class="ln">515  </span></a>
<a name="l516"><span class="ln">516  </span></a>  <span class="s3">// STOP.  Thinking of adding a method here, which only makes use</span>
<a name="l517"><span class="ln">517  </span></a>  <span class="s3">// of other ATen methods?  Define it in native_functions.yaml.</span>
<a name="l518"><span class="ln">518  </span></a>
<a name="l519"><span class="ln">519  </span></a>  <span class="s3">//example</span>
<a name="l520"><span class="ln">520  </span></a>  <span class="s3">//Tensor * add(Tensor &amp; b);</span>
<a name="l521"><span class="ln">521  </span></a>  <span class="s1">void </span><span class="s0">__dispatch__backward(at::TensorList inputs, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; gradient={}, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; retain_graph=::std::nullopt, </span><span class="s1">bool </span><span class="s0">create_graph=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l522"><span class="ln">522  </span></a>  <span class="s1">void </span><span class="s0">__dispatch_set_data(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; new_data) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l523"><span class="ln">523  </span></a>  <span class="s0">at::Tensor __dispatch_data() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l524"><span class="ln">524  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_leaf() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l525"><span class="ln">525  </span></a>  <span class="s0">int64_t __dispatch_output_nr() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l526"><span class="ln">526  </span></a>  <span class="s0">int64_t __dispatch__version() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l527"><span class="ln">527  </span></a>  <span class="s0">at::Tensor &amp; __dispatch_requires_grad_(</span><span class="s1">bool </span><span class="s0">requires_grad=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l528"><span class="ln">528  </span></a>  <span class="s1">void </span><span class="s0">__dispatch_retain_grad() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l529"><span class="ln">529  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_retains_grad() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l530"><span class="ln">530  </span></a>  <span class="s0">at::Tensor _fw_primal(int64_t level) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l531"><span class="ln">531  </span></a>  <span class="s0">at::Tensor &amp; rename_(::std::optional&lt;at::DimnameList&gt; names) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l532"><span class="ln">532  </span></a>  <span class="s0">at::Tensor rename(::std::optional&lt;at::DimnameList&gt; names) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l533"><span class="ln">533  </span></a>  <span class="s0">at::Tensor align_to(at::DimnameList names) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l534"><span class="ln">534  </span></a>  <span class="s0">at::Tensor align_to(at::DimnameList order, int64_t ellipsis_idx) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l535"><span class="ln">535  </span></a>  <span class="s0">at::Tensor align_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l536"><span class="ln">536  </span></a>  <span class="s0">at::Tensor refine_names(at::DimnameList names) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l537"><span class="ln">537  </span></a>  <span class="s0">at::Tensor abs() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l538"><span class="ln">538  </span></a>  <span class="s0">at::Tensor &amp; abs_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l539"><span class="ln">539  </span></a>  <span class="s0">at::Tensor absolute() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l540"><span class="ln">540  </span></a>  <span class="s0">at::Tensor &amp; absolute_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l541"><span class="ln">541  </span></a>  <span class="s0">at::Tensor angle() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l542"><span class="ln">542  </span></a>  <span class="s0">at::Tensor sgn() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l543"><span class="ln">543  </span></a>  <span class="s0">at::Tensor &amp; sgn_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l544"><span class="ln">544  </span></a>  <span class="s0">at::Tensor chalf(::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l545"><span class="ln">545  </span></a>  <span class="s0">at::Tensor _conj() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l546"><span class="ln">546  </span></a>  <span class="s0">at::Tensor __dispatch_conj() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l547"><span class="ln">547  </span></a>  <span class="s0">at::Tensor _conj_physical() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l548"><span class="ln">548  </span></a>  <span class="s0">at::Tensor conj_physical() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l549"><span class="ln">549  </span></a>  <span class="s0">at::Tensor &amp; conj_physical_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l550"><span class="ln">550  </span></a>  <span class="s0">at::Tensor resolve_conj() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l551"><span class="ln">551  </span></a>  <span class="s0">at::Tensor resolve_neg() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l552"><span class="ln">552  </span></a>  <span class="s0">at::Tensor _neg_view() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l553"><span class="ln">553  </span></a>  <span class="s0">at::Tensor acos() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l554"><span class="ln">554  </span></a>  <span class="s0">at::Tensor &amp; acos_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l555"><span class="ln">555  </span></a>  <span class="s0">at::Tensor arccos() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l556"><span class="ln">556  </span></a>  <span class="s0">at::Tensor &amp; arccos_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l557"><span class="ln">557  </span></a>  <span class="s0">at::Tensor add(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l558"><span class="ln">558  </span></a>  <span class="s0">at::Tensor &amp; add_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l559"><span class="ln">559  </span></a>  <span class="s0">at::Tensor add(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l560"><span class="ln">560  </span></a>  <span class="s0">at::Tensor &amp; add_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l561"><span class="ln">561  </span></a>  <span class="s0">at::Tensor addmv(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l562"><span class="ln">562  </span></a>  <span class="s0">at::Tensor &amp; addmv_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l563"><span class="ln">563  </span></a>  <span class="s0">at::Tensor addr(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l564"><span class="ln">564  </span></a>  <span class="s0">at::Tensor &amp; addr_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l565"><span class="ln">565  </span></a>  <span class="s0">at::Tensor _is_all_true() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l566"><span class="ln">566  </span></a>  <span class="s0">at::Tensor _is_any_true() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l567"><span class="ln">567  </span></a>  <span class="s0">at::Tensor all(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l568"><span class="ln">568  </span></a>  <span class="s0">at::Tensor all(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l569"><span class="ln">569  </span></a>  <span class="s0">at::Tensor all(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l570"><span class="ln">570  </span></a>  <span class="s1">bool </span><span class="s0">allclose(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">double </span><span class="s0">rtol=</span><span class="s6">1</span><span class="s0">e-05, </span><span class="s1">double </span><span class="s0">atol=</span><span class="s6">1</span><span class="s0">e-08, </span><span class="s1">bool </span><span class="s0">equal_nan=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l571"><span class="ln">571  </span></a>  <span class="s0">at::Tensor any(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l572"><span class="ln">572  </span></a>  <span class="s0">at::Tensor any(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l573"><span class="ln">573  </span></a>  <span class="s0">at::Tensor any(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l574"><span class="ln">574  </span></a>  <span class="s0">at::Tensor argmax(::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l575"><span class="ln">575  </span></a>  <span class="s0">at::Tensor argmin(::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l576"><span class="ln">576  </span></a>  <span class="s0">at::Tensor acosh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l577"><span class="ln">577  </span></a>  <span class="s0">at::Tensor &amp; acosh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l578"><span class="ln">578  </span></a>  <span class="s0">at::Tensor arccosh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l579"><span class="ln">579  </span></a>  <span class="s0">at::Tensor &amp; arccosh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l580"><span class="ln">580  </span></a>  <span class="s0">at::Tensor asinh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l581"><span class="ln">581  </span></a>  <span class="s0">at::Tensor &amp; asinh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l582"><span class="ln">582  </span></a>  <span class="s0">at::Tensor arcsinh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l583"><span class="ln">583  </span></a>  <span class="s0">at::Tensor &amp; arcsinh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l584"><span class="ln">584  </span></a>  <span class="s0">at::Tensor atanh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l585"><span class="ln">585  </span></a>  <span class="s0">at::Tensor &amp; atanh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l586"><span class="ln">586  </span></a>  <span class="s0">at::Tensor arctanh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l587"><span class="ln">587  </span></a>  <span class="s0">at::Tensor &amp; arctanh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l588"><span class="ln">588  </span></a>  <span class="s0">at::Tensor as_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l589"><span class="ln">589  </span></a>  <span class="s0">at::Tensor as_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l590"><span class="ln">590  </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; as_strided_(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l591"><span class="ln">591  </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; as_strided__symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l592"><span class="ln">592  </span></a>  <span class="s0">at::Tensor asin() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l593"><span class="ln">593  </span></a>  <span class="s0">at::Tensor &amp; asin_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l594"><span class="ln">594  </span></a>  <span class="s0">at::Tensor arcsin() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l595"><span class="ln">595  </span></a>  <span class="s0">at::Tensor &amp; arcsin_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l596"><span class="ln">596  </span></a>  <span class="s0">at::Tensor atan() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l597"><span class="ln">597  </span></a>  <span class="s0">at::Tensor &amp; atan_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l598"><span class="ln">598  </span></a>  <span class="s0">at::Tensor arctan() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l599"><span class="ln">599  </span></a>  <span class="s0">at::Tensor &amp; arctan_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l600"><span class="ln">600  </span></a>  <span class="s0">at::Tensor baddbmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l601"><span class="ln">601  </span></a>  <span class="s0">at::Tensor &amp; baddbmm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l602"><span class="ln">602  </span></a>  <span class="s0">at::Tensor bernoulli(::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l603"><span class="ln">603  </span></a>  <span class="s0">at::Tensor &amp; bernoulli_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; p, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l604"><span class="ln">604  </span></a>  <span class="s0">at::Tensor &amp; bernoulli_(</span><span class="s1">double </span><span class="s0">p=</span><span class="s6">0.5</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l605"><span class="ln">605  </span></a>  <span class="s0">at::Tensor bernoulli(</span><span class="s1">double </span><span class="s0">p, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l606"><span class="ln">606  </span></a>  <span class="s0">at::Tensor bincount(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weights={}, int64_t minlength=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l607"><span class="ln">607  </span></a>  <span class="s0">at::Tensor bincount_symint(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weights={}, c10::SymInt minlength=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l608"><span class="ln">608  </span></a>  <span class="s0">at::Tensor bitwise_not() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l609"><span class="ln">609  </span></a>  <span class="s0">at::Tensor &amp; bitwise_not_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l610"><span class="ln">610  </span></a>  <span class="s0">at::Tensor copysign(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l611"><span class="ln">611  </span></a>  <span class="s0">at::Tensor &amp; copysign_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l612"><span class="ln">612  </span></a>  <span class="s0">at::Tensor copysign(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l613"><span class="ln">613  </span></a>  <span class="s0">at::Tensor &amp; copysign_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l614"><span class="ln">614  </span></a>  <span class="s0">at::Tensor _lazy_clone() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l615"><span class="ln">615  </span></a>  <span class="s0">at::Tensor logical_not() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l616"><span class="ln">616  </span></a>  <span class="s0">at::Tensor &amp; logical_not_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l617"><span class="ln">617  </span></a>  <span class="s0">at::Tensor logical_xor(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l618"><span class="ln">618  </span></a>  <span class="s0">at::Tensor &amp; logical_xor_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l619"><span class="ln">619  </span></a>  <span class="s0">at::Tensor logical_and(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l620"><span class="ln">620  </span></a>  <span class="s0">at::Tensor &amp; logical_and_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l621"><span class="ln">621  </span></a>  <span class="s0">at::Tensor logical_or(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l622"><span class="ln">622  </span></a>  <span class="s0">at::Tensor &amp; logical_or_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l623"><span class="ln">623  </span></a>  <span class="s0">at::Tensor bmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l624"><span class="ln">624  </span></a>  <span class="s0">at::Tensor broadcast_to(at::IntArrayRef size) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l625"><span class="ln">625  </span></a>  <span class="s0">at::Tensor broadcast_to_symint(c10::SymIntArrayRef size) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l626"><span class="ln">626  </span></a>  <span class="s0">at::Tensor ceil() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l627"><span class="ln">627  </span></a>  <span class="s0">at::Tensor &amp; ceil_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l628"><span class="ln">628  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unsafe_chunk(int64_t chunks, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l629"><span class="ln">629  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; chunk(int64_t chunks, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l630"><span class="ln">630  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; tensor_split(int64_t sections, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l631"><span class="ln">631  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; tensor_split_symint(c10::SymInt sections, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l632"><span class="ln">632  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; tensor_split(at::IntArrayRef indices, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l633"><span class="ln">633  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; tensor_split_symint(c10::SymIntArrayRef indices, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l634"><span class="ln">634  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; tensor_split(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor_indices_or_sections, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l635"><span class="ln">635  </span></a>  <span class="s0">at::Tensor clamp(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l636"><span class="ln">636  </span></a>  <span class="s0">at::Tensor clamp(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min={}, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l637"><span class="ln">637  </span></a>  <span class="s0">at::Tensor &amp; clamp_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l638"><span class="ln">638  </span></a>  <span class="s0">at::Tensor &amp; clamp_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min={}, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l639"><span class="ln">639  </span></a>  <span class="s0">at::Tensor clamp_max(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; max) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l640"><span class="ln">640  </span></a>  <span class="s0">at::Tensor clamp_max(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; max) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l641"><span class="ln">641  </span></a>  <span class="s0">at::Tensor &amp; clamp_max_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; max) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l642"><span class="ln">642  </span></a>  <span class="s0">at::Tensor &amp; clamp_max_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; max) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l643"><span class="ln">643  </span></a>  <span class="s0">at::Tensor clamp_min(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; min) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l644"><span class="ln">644  </span></a>  <span class="s0">at::Tensor clamp_min(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; min) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l645"><span class="ln">645  </span></a>  <span class="s0">at::Tensor &amp; clamp_min_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; min) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l646"><span class="ln">646  </span></a>  <span class="s0">at::Tensor &amp; clamp_min_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; min) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l647"><span class="ln">647  </span></a>  <span class="s0">at::Tensor clip(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l648"><span class="ln">648  </span></a>  <span class="s0">at::Tensor clip(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min={}, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l649"><span class="ln">649  </span></a>  <span class="s0">at::Tensor &amp; clip_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l650"><span class="ln">650  </span></a>  <span class="s0">at::Tensor &amp; clip_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min={}, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l651"><span class="ln">651  </span></a>  <span class="s0">at::Tensor __dispatch_contiguous(at::MemoryFormat memory_format=c10::MemoryFormat::Contiguous) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l652"><span class="ln">652  </span></a>  <span class="s0">at::Tensor &amp; copy_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l653"><span class="ln">653  </span></a>  <span class="s0">at::Tensor cos() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l654"><span class="ln">654  </span></a>  <span class="s0">at::Tensor &amp; cos_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l655"><span class="ln">655  </span></a>  <span class="s0">at::Tensor cosh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l656"><span class="ln">656  </span></a>  <span class="s0">at::Tensor &amp; cosh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l657"><span class="ln">657  </span></a>  <span class="s0">at::Tensor count_nonzero(at::IntArrayRef dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l658"><span class="ln">658  </span></a>  <span class="s0">at::Tensor count_nonzero(::std::optional&lt;int64_t&gt; dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l659"><span class="ln">659  </span></a>  <span class="s0">at::Tensor cov(int64_t correction=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; fweights={}, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; aweights={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l660"><span class="ln">660  </span></a>  <span class="s0">at::Tensor corrcoef() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l661"><span class="ln">661  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; cummax(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l662"><span class="ln">662  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; cummax(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l663"><span class="ln">663  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; cummin(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l664"><span class="ln">664  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; cummin(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l665"><span class="ln">665  </span></a>  <span class="s0">at::Tensor cumprod(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l666"><span class="ln">666  </span></a>  <span class="s0">at::Tensor &amp; cumprod_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l667"><span class="ln">667  </span></a>  <span class="s0">at::Tensor cumprod(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l668"><span class="ln">668  </span></a>  <span class="s0">at::Tensor &amp; cumprod_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l669"><span class="ln">669  </span></a>  <span class="s0">at::Tensor cumsum(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l670"><span class="ln">670  </span></a>  <span class="s0">at::Tensor &amp; cumsum_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l671"><span class="ln">671  </span></a>  <span class="s0">at::Tensor cumsum(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l672"><span class="ln">672  </span></a>  <span class="s0">at::Tensor &amp; cumsum_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l673"><span class="ln">673  </span></a>  <span class="s0">at::Tensor diag_embed(int64_t offset=</span><span class="s6">0</span><span class="s0">, int64_t dim1=-</span><span class="s6">2</span><span class="s0">, int64_t dim2=-</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l674"><span class="ln">674  </span></a>  <span class="s0">at::Tensor diagflat(int64_t offset=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l675"><span class="ln">675  </span></a>  <span class="s0">at::Tensor diagonal(int64_t offset=</span><span class="s6">0</span><span class="s0">, int64_t dim1=</span><span class="s6">0</span><span class="s0">, int64_t dim2=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l676"><span class="ln">676  </span></a>  <span class="s0">at::Tensor diagonal(at::Dimname outdim, at::Dimname dim1, at::Dimname dim2, int64_t offset=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l677"><span class="ln">677  </span></a>  <span class="s0">at::Tensor &amp; fill_diagonal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, </span><span class="s1">bool </span><span class="s0">wrap=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l678"><span class="ln">678  </span></a>  <span class="s0">at::Tensor diff(int64_t n=</span><span class="s6">1</span><span class="s0">, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; prepend={}, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; append={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l679"><span class="ln">679  </span></a>  <span class="s0">at::Tensor div(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l680"><span class="ln">680  </span></a>  <span class="s0">at::Tensor &amp; div_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l681"><span class="ln">681  </span></a>  <span class="s0">at::Tensor div(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l682"><span class="ln">682  </span></a>  <span class="s0">at::Tensor &amp; div_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l683"><span class="ln">683  </span></a>  <span class="s0">at::Tensor div(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l684"><span class="ln">684  </span></a>  <span class="s0">at::Tensor &amp; div_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l685"><span class="ln">685  </span></a>  <span class="s0">at::Tensor div(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l686"><span class="ln">686  </span></a>  <span class="s0">at::Tensor &amp; div_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l687"><span class="ln">687  </span></a>  <span class="s0">at::Tensor divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l688"><span class="ln">688  </span></a>  <span class="s0">at::Tensor &amp; divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l689"><span class="ln">689  </span></a>  <span class="s0">at::Tensor divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l690"><span class="ln">690  </span></a>  <span class="s0">at::Tensor &amp; divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l691"><span class="ln">691  </span></a>  <span class="s0">at::Tensor divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l692"><span class="ln">692  </span></a>  <span class="s0">at::Tensor &amp; divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l693"><span class="ln">693  </span></a>  <span class="s0">at::Tensor divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l694"><span class="ln">694  </span></a>  <span class="s0">at::Tensor &amp; divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l695"><span class="ln">695  </span></a>  <span class="s0">at::Tensor true_divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l696"><span class="ln">696  </span></a>  <span class="s0">at::Tensor &amp; true_divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l697"><span class="ln">697  </span></a>  <span class="s0">at::Tensor true_divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l698"><span class="ln">698  </span></a>  <span class="s0">at::Tensor &amp; true_divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l699"><span class="ln">699  </span></a>  <span class="s0">at::Tensor dot(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l700"><span class="ln">700  </span></a>  <span class="s0">at::Tensor vdot(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l701"><span class="ln">701  </span></a>  <span class="s0">at::Tensor new_empty(at::IntArrayRef size, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l702"><span class="ln">702  </span></a>  <span class="s0">at::Tensor new_empty(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l703"><span class="ln">703  </span></a>  <span class="s0">at::Tensor new_empty_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l704"><span class="ln">704  </span></a>  <span class="s0">at::Tensor new_empty_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l705"><span class="ln">705  </span></a>  <span class="s0">at::Tensor new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l706"><span class="ln">706  </span></a>  <span class="s0">at::Tensor new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l707"><span class="ln">707  </span></a>  <span class="s0">at::Tensor new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l708"><span class="ln">708  </span></a>  <span class="s0">at::Tensor new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l709"><span class="ln">709  </span></a>  <span class="s0">at::Tensor new_full(at::IntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l710"><span class="ln">710  </span></a>  <span class="s0">at::Tensor new_full(at::IntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l711"><span class="ln">711  </span></a>  <span class="s0">at::Tensor new_full_symint(c10::SymIntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l712"><span class="ln">712  </span></a>  <span class="s0">at::Tensor new_full_symint(c10::SymIntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l713"><span class="ln">713  </span></a>  <span class="s0">at::Tensor new_zeros(at::IntArrayRef size, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l714"><span class="ln">714  </span></a>  <span class="s0">at::Tensor new_zeros(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l715"><span class="ln">715  </span></a>  <span class="s0">at::Tensor new_zeros_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l716"><span class="ln">716  </span></a>  <span class="s0">at::Tensor new_zeros_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l717"><span class="ln">717  </span></a>  <span class="s0">at::Tensor new_ones(at::IntArrayRef size, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l718"><span class="ln">718  </span></a>  <span class="s0">at::Tensor new_ones(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l719"><span class="ln">719  </span></a>  <span class="s0">at::Tensor new_ones_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l720"><span class="ln">720  </span></a>  <span class="s0">at::Tensor new_ones_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l721"><span class="ln">721  </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; resize_(at::IntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l722"><span class="ln">722  </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; resize__symint(c10::SymIntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l723"><span class="ln">723  </span></a>  <span class="s0">at::Tensor erf() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l724"><span class="ln">724  </span></a>  <span class="s0">at::Tensor &amp; erf_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l725"><span class="ln">725  </span></a>  <span class="s0">at::Tensor erfc() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l726"><span class="ln">726  </span></a>  <span class="s0">at::Tensor &amp; erfc_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l727"><span class="ln">727  </span></a>  <span class="s0">at::Tensor exp() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l728"><span class="ln">728  </span></a>  <span class="s0">at::Tensor &amp; exp_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l729"><span class="ln">729  </span></a>  <span class="s0">at::Tensor exp2() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l730"><span class="ln">730  </span></a>  <span class="s0">at::Tensor &amp; exp2_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l731"><span class="ln">731  </span></a>  <span class="s0">at::Tensor expm1() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l732"><span class="ln">732  </span></a>  <span class="s0">at::Tensor &amp; expm1_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l733"><span class="ln">733  </span></a>  <span class="s0">at::Tensor expand(at::IntArrayRef size, </span><span class="s1">bool </span><span class="s0">implicit=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l734"><span class="ln">734  </span></a>  <span class="s0">at::Tensor expand_symint(c10::SymIntArrayRef size, </span><span class="s1">bool </span><span class="s0">implicit=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l735"><span class="ln">735  </span></a>  <span class="s0">at::Tensor expand_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l736"><span class="ln">736  </span></a>  <span class="s0">at::Tensor flatten(int64_t start_dim=</span><span class="s6">0</span><span class="s0">, int64_t end_dim=-</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l737"><span class="ln">737  </span></a>  <span class="s0">at::Tensor flatten(int64_t start_dim, int64_t end_dim, at::Dimname out_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l738"><span class="ln">738  </span></a>  <span class="s0">at::Tensor flatten(at::Dimname start_dim, at::Dimname end_dim, at::Dimname out_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l739"><span class="ln">739  </span></a>  <span class="s0">at::Tensor flatten(at::DimnameList dims, at::Dimname out_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l740"><span class="ln">740  </span></a>  <span class="s0">at::Tensor unflatten(int64_t dim, at::IntArrayRef sizes) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l741"><span class="ln">741  </span></a>  <span class="s0">at::Tensor unflatten_symint(int64_t dim, c10::SymIntArrayRef sizes) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l742"><span class="ln">742  </span></a>  <span class="s0">at::Tensor unflatten(at::Dimname dim, at::IntArrayRef sizes, at::DimnameList names) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l743"><span class="ln">743  </span></a>  <span class="s0">at::Tensor unflatten_symint(at::Dimname dim, c10::SymIntArrayRef sizes, at::DimnameList names) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l744"><span class="ln">744  </span></a>  <span class="s0">at::Tensor &amp; fill_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l745"><span class="ln">745  </span></a>  <span class="s0">at::Tensor &amp; fill_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l746"><span class="ln">746  </span></a>  <span class="s0">at::Tensor floor() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l747"><span class="ln">747  </span></a>  <span class="s0">at::Tensor &amp; floor_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l748"><span class="ln">748  </span></a>  <span class="s0">at::Tensor floor_divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l749"><span class="ln">749  </span></a>  <span class="s0">at::Tensor &amp; floor_divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l750"><span class="ln">750  </span></a>  <span class="s0">at::Tensor floor_divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l751"><span class="ln">751  </span></a>  <span class="s0">at::Tensor &amp; floor_divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l752"><span class="ln">752  </span></a>  <span class="s0">at::Tensor frac() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l753"><span class="ln">753  </span></a>  <span class="s0">at::Tensor &amp; frac_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l754"><span class="ln">754  </span></a>  <span class="s0">at::Tensor gcd(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l755"><span class="ln">755  </span></a>  <span class="s0">at::Tensor &amp; gcd_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l756"><span class="ln">756  </span></a>  <span class="s0">at::Tensor lcm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l757"><span class="ln">757  </span></a>  <span class="s0">at::Tensor &amp; lcm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l758"><span class="ln">758  </span></a>  <span class="s0">at::Tensor index(</span><span class="s1">const </span><span class="s0">c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l759"><span class="ln">759  </span></a>  <span class="s0">at::Tensor &amp; index_copy_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l760"><span class="ln">760  </span></a>  <span class="s0">at::Tensor index_copy(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l761"><span class="ln">761  </span></a>  <span class="s0">at::Tensor &amp; index_copy_(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l762"><span class="ln">762  </span></a>  <span class="s0">at::Tensor index_copy(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l763"><span class="ln">763  </span></a>  <span class="s0">at::Tensor &amp; index_put_(</span><span class="s1">const </span><span class="s0">c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; values, </span><span class="s1">bool </span><span class="s0">accumulate=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l764"><span class="ln">764  </span></a>  <span class="s0">at::Tensor index_put(</span><span class="s1">const </span><span class="s0">c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; values, </span><span class="s1">bool </span><span class="s0">accumulate=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l765"><span class="ln">765  </span></a>  <span class="s0">at::Tensor isclose(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">double </span><span class="s0">rtol=</span><span class="s6">1</span><span class="s0">e-05, </span><span class="s1">double </span><span class="s0">atol=</span><span class="s6">1</span><span class="s0">e-08, </span><span class="s1">bool </span><span class="s0">equal_nan=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l766"><span class="ln">766  </span></a>  <span class="s0">at::Tensor isnan() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l767"><span class="ln">767  </span></a>  <span class="s1">bool </span><span class="s0">is_distributed() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l768"><span class="ln">768  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_floating_point() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l769"><span class="ln">769  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_complex() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l770"><span class="ln">770  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_conj() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l771"><span class="ln">771  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch__is_zerotensor() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l772"><span class="ln">772  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_neg() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l773"><span class="ln">773  </span></a>  <span class="s0">at::Tensor isreal() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l774"><span class="ln">774  </span></a>  <span class="s1">bool </span><span class="s0">is_nonzero() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l775"><span class="ln">775  </span></a>  <span class="s1">bool </span><span class="s0">is_same_size(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l776"><span class="ln">776  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_signed() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l777"><span class="ln">777  </span></a>  <span class="s1">bool </span><span class="s0">__dispatch_is_inference() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l778"><span class="ln">778  </span></a>  <span class="s0">at::Tensor kron(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l779"><span class="ln">779  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; kthvalue(int64_t k, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l780"><span class="ln">780  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; kthvalue_symint(c10::SymInt k, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l781"><span class="ln">781  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; kthvalue(int64_t k, at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l782"><span class="ln">782  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; kthvalue_symint(c10::SymInt k, at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l783"><span class="ln">783  </span></a>  <span class="s0">at::Tensor nan_to_num(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; nan=::std::nullopt, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; posinf=::std::nullopt, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; neginf=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l784"><span class="ln">784  </span></a>  <span class="s0">at::Tensor &amp; nan_to_num_(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; nan=::std::nullopt, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; posinf=::std::nullopt, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; neginf=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l785"><span class="ln">785  </span></a>  <span class="s0">at::Tensor ldexp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l786"><span class="ln">786  </span></a>  <span class="s0">at::Tensor &amp; ldexp_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l787"><span class="ln">787  </span></a>  <span class="s0">at::Tensor log() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l788"><span class="ln">788  </span></a>  <span class="s0">at::Tensor &amp; log_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l789"><span class="ln">789  </span></a>  <span class="s0">at::Tensor log10() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l790"><span class="ln">790  </span></a>  <span class="s0">at::Tensor &amp; log10_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l791"><span class="ln">791  </span></a>  <span class="s0">at::Tensor log1p() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l792"><span class="ln">792  </span></a>  <span class="s0">at::Tensor &amp; log1p_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l793"><span class="ln">793  </span></a>  <span class="s0">at::Tensor log2() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l794"><span class="ln">794  </span></a>  <span class="s0">at::Tensor &amp; log2_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l795"><span class="ln">795  </span></a>  <span class="s0">at::Tensor logaddexp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l796"><span class="ln">796  </span></a>  <span class="s0">at::Tensor logaddexp2(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l797"><span class="ln">797  </span></a>  <span class="s0">at::Tensor xlogy(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l798"><span class="ln">798  </span></a>  <span class="s0">at::Tensor xlogy(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l799"><span class="ln">799  </span></a>  <span class="s0">at::Tensor &amp; xlogy_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l800"><span class="ln">800  </span></a>  <span class="s0">at::Tensor &amp; xlogy_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l801"><span class="ln">801  </span></a>  <span class="s0">at::Tensor log_softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l802"><span class="ln">802  </span></a>  <span class="s0">at::Tensor log_softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l803"><span class="ln">803  </span></a>  <span class="s0">at::Tensor logcumsumexp(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l804"><span class="ln">804  </span></a>  <span class="s0">at::Tensor logcumsumexp(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l805"><span class="ln">805  </span></a>  <span class="s0">at::Tensor logsumexp(at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l806"><span class="ln">806  </span></a>  <span class="s0">at::Tensor logsumexp(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l807"><span class="ln">807  </span></a>  <span class="s0">at::Tensor matmul(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l808"><span class="ln">808  </span></a>  <span class="s0">at::Tensor matrix_power(int64_t n) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l809"><span class="ln">809  </span></a>  <span class="s0">at::Tensor matrix_exp() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l810"><span class="ln">810  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; aminmax(::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l811"><span class="ln">811  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; max(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l812"><span class="ln">812  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; max(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l813"><span class="ln">813  </span></a>  <span class="s0">at::Tensor amax(at::IntArrayRef dim={}, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l814"><span class="ln">814  </span></a>  <span class="s0">at::Tensor mean(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l815"><span class="ln">815  </span></a>  <span class="s0">at::Tensor mean(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l816"><span class="ln">816  </span></a>  <span class="s0">at::Tensor mean(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l817"><span class="ln">817  </span></a>  <span class="s0">at::Tensor nanmean(at::OptionalIntArrayRef dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l818"><span class="ln">818  </span></a>  <span class="s0">at::Tensor median() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l819"><span class="ln">819  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; median(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l820"><span class="ln">820  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; median(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l821"><span class="ln">821  </span></a>  <span class="s0">at::Tensor nanmedian() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l822"><span class="ln">822  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; nanmedian(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l823"><span class="ln">823  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; nanmedian(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l824"><span class="ln">824  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; min(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l825"><span class="ln">825  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; min(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l826"><span class="ln">826  </span></a>  <span class="s0">at::Tensor amin(at::IntArrayRef dim={}, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l827"><span class="ln">827  </span></a>  <span class="s0">at::Tensor mm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l828"><span class="ln">828  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; mode(int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l829"><span class="ln">829  </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; mode(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l830"><span class="ln">830  </span></a>  <span class="s0">at::Tensor mul(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l831"><span class="ln">831  </span></a>  <span class="s0">at::Tensor &amp; mul_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l832"><span class="ln">832  </span></a>  <span class="s0">at::Tensor mul(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l833"><span class="ln">833  </span></a>  <span class="s0">at::Tensor &amp; mul_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l834"><span class="ln">834  </span></a>  <span class="s0">at::Tensor multiply(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l835"><span class="ln">835  </span></a>  <span class="s0">at::Tensor &amp; multiply_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l836"><span class="ln">836  </span></a>  <span class="s0">at::Tensor multiply(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l837"><span class="ln">837  </span></a>  <span class="s0">at::Tensor &amp; multiply_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l838"><span class="ln">838  </span></a>  <span class="s0">at::Tensor mv(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l839"><span class="ln">839  </span></a>  <span class="s0">at::Tensor mvlgamma(int64_t p) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l840"><span class="ln">840  </span></a>  <span class="s0">at::Tensor &amp; mvlgamma_(int64_t p) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l841"><span class="ln">841  </span></a>  <span class="s0">at::Tensor narrow_copy(int64_t dim, int64_t start, int64_t length) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l842"><span class="ln">842  </span></a>  <span class="s0">at::Tensor narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l843"><span class="ln">843  </span></a>  <span class="s0">at::Tensor narrow(int64_t dim, int64_t start, int64_t length) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l844"><span class="ln">844  </span></a>  <span class="s0">at::Tensor narrow_symint(int64_t dim, c10::SymInt start, c10::SymInt length) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l845"><span class="ln">845  </span></a>  <span class="s0">at::Tensor narrow(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; start, int64_t length) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l846"><span class="ln">846  </span></a>  <span class="s0">at::Tensor narrow_symint(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; start, c10::SymInt length) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l847"><span class="ln">847  </span></a>  <span class="s0">at::Tensor permute(at::IntArrayRef dims) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l848"><span class="ln">848  </span></a>  <span class="s0">at::Tensor movedim(at::IntArrayRef source, at::IntArrayRef destination) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l849"><span class="ln">849  </span></a>  <span class="s0">at::Tensor movedim(int64_t source, int64_t destination) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l850"><span class="ln">850  </span></a>  <span class="s0">at::Tensor moveaxis(at::IntArrayRef source, at::IntArrayRef destination) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l851"><span class="ln">851  </span></a>  <span class="s0">at::Tensor moveaxis(int64_t source, int64_t destination) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l852"><span class="ln">852  </span></a>  <span class="s0">at::Tensor numpy_T() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l853"><span class="ln">853  </span></a>  <span class="s0">at::Tensor matrix_H() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l854"><span class="ln">854  </span></a>  <span class="s0">at::Tensor mT() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l855"><span class="ln">855  </span></a>  <span class="s0">at::Tensor mH() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l856"><span class="ln">856  </span></a>  <span class="s0">at::Tensor adjoint() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l857"><span class="ln">857  </span></a>  <span class="s1">bool </span><span class="s0">is_pinned(::std::optional&lt;at::Device&gt; device=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l858"><span class="ln">858  </span></a>  <span class="s0">at::Tensor pin_memory(::std::optional&lt;at::Device&gt; device=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l859"><span class="ln">859  </span></a>  <span class="s0">at::Tensor pinverse(</span><span class="s1">double </span><span class="s0">rcond=</span><span class="s6">1</span><span class="s0">e-15) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l860"><span class="ln">860  </span></a>  <span class="s0">at::Tensor rad2deg() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l861"><span class="ln">861  </span></a>  <span class="s0">at::Tensor &amp; rad2deg_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l862"><span class="ln">862  </span></a>  <span class="s0">at::Tensor deg2rad() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l863"><span class="ln">863  </span></a>  <span class="s0">at::Tensor &amp; deg2rad_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l864"><span class="ln">864  </span></a>  <span class="s0">at::Tensor ravel() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l865"><span class="ln">865  </span></a>  <span class="s0">at::Tensor reciprocal() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l866"><span class="ln">866  </span></a>  <span class="s0">at::Tensor &amp; reciprocal_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l867"><span class="ln">867  </span></a>  <span class="s0">at::Tensor neg() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l868"><span class="ln">868  </span></a>  <span class="s0">at::Tensor &amp; neg_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l869"><span class="ln">869  </span></a>  <span class="s0">at::Tensor negative() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l870"><span class="ln">870  </span></a>  <span class="s0">at::Tensor &amp; negative_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l871"><span class="ln">871  </span></a>  <span class="s0">at::Tensor repeat(at::IntArrayRef repeats) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l872"><span class="ln">872  </span></a>  <span class="s0">at::Tensor repeat_symint(c10::SymIntArrayRef repeats) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l873"><span class="ln">873  </span></a>  <span class="s0">at::Tensor repeat_interleave(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;int64_t&gt; output_size=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l874"><span class="ln">874  </span></a>  <span class="s0">at::Tensor repeat_interleave_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; output_size=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l875"><span class="ln">875  </span></a>  <span class="s0">at::Tensor repeat_interleave(int64_t repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;int64_t&gt; output_size=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l876"><span class="ln">876  </span></a>  <span class="s0">at::Tensor repeat_interleave_symint(c10::SymInt repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; output_size=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l877"><span class="ln">877  </span></a>  <span class="s0">at::Tensor reshape(at::IntArrayRef shape) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l878"><span class="ln">878  </span></a>  <span class="s0">at::Tensor reshape_symint(c10::SymIntArrayRef shape) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l879"><span class="ln">879  </span></a>  <span class="s0">at::Tensor _reshape_alias(at::IntArrayRef size, at::IntArrayRef stride) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l880"><span class="ln">880  </span></a>  <span class="s0">at::Tensor _reshape_alias_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l881"><span class="ln">881  </span></a>  <span class="s0">at::Tensor reshape_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l882"><span class="ln">882  </span></a>  <span class="s0">at::Tensor round() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l883"><span class="ln">883  </span></a>  <span class="s0">at::Tensor &amp; round_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l884"><span class="ln">884  </span></a>  <span class="s0">at::Tensor round(int64_t decimals) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l885"><span class="ln">885  </span></a>  <span class="s0">at::Tensor &amp; round_(int64_t decimals) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l886"><span class="ln">886  </span></a>  <span class="s0">at::Tensor relu() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l887"><span class="ln">887  </span></a>  <span class="s0">at::Tensor &amp; relu_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l888"><span class="ln">888  </span></a>  <span class="s0">at::Tensor prelu(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; weight) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l889"><span class="ln">889  </span></a>  <span class="s0">at::Tensor hardshrink(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; lambd=</span><span class="s6">0.5</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l890"><span class="ln">890  </span></a>  <span class="s0">at::Tensor hardshrink_backward(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; grad_out, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; lambd) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l891"><span class="ln">891  </span></a>  <span class="s0">at::Tensor rsqrt() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l892"><span class="ln">892  </span></a>  <span class="s0">at::Tensor &amp; rsqrt_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l893"><span class="ln">893  </span></a>  <span class="s0">at::Tensor select(at::Dimname dim, int64_t index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l894"><span class="ln">894  </span></a>  <span class="s0">at::Tensor select(int64_t dim, int64_t index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l895"><span class="ln">895  </span></a>  <span class="s0">at::Tensor select_symint(int64_t dim, c10::SymInt index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l896"><span class="ln">896  </span></a>  <span class="s0">at::Tensor sigmoid() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l897"><span class="ln">897  </span></a>  <span class="s0">at::Tensor &amp; sigmoid_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l898"><span class="ln">898  </span></a>  <span class="s0">at::Tensor logit(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; eps=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l899"><span class="ln">899  </span></a>  <span class="s0">at::Tensor &amp; logit_(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; eps=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l900"><span class="ln">900  </span></a>  <span class="s0">at::Tensor sin() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l901"><span class="ln">901  </span></a>  <span class="s0">at::Tensor &amp; sin_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l902"><span class="ln">902  </span></a>  <span class="s0">at::Tensor sinc() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l903"><span class="ln">903  </span></a>  <span class="s0">at::Tensor &amp; sinc_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l904"><span class="ln">904  </span></a>  <span class="s0">at::Tensor sinh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l905"><span class="ln">905  </span></a>  <span class="s0">at::Tensor &amp; sinh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l906"><span class="ln">906  </span></a>  <span class="s0">at::Tensor detach() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l907"><span class="ln">907  </span></a>  <span class="s0">at::Tensor &amp; detach_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l908"><span class="ln">908  </span></a>  <span class="s0">int64_t size(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l909"><span class="ln">909  </span></a>  <span class="s0">at::Tensor slice(int64_t dim=</span><span class="s6">0</span><span class="s0">, ::std::optional&lt;int64_t&gt; start=::std::nullopt, ::std::optional&lt;int64_t&gt; end=::std::nullopt, int64_t step=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l910"><span class="ln">910  </span></a>  <span class="s0">at::Tensor slice_symint(int64_t dim=</span><span class="s6">0</span><span class="s0">, ::std::optional&lt;c10::SymInt&gt; start=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; end=::std::nullopt, c10::SymInt step=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l911"><span class="ln">911  </span></a>  <span class="s0">at::Tensor slice_inverse(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim=</span><span class="s6">0</span><span class="s0">, ::std::optional&lt;int64_t&gt; start=::std::nullopt, ::std::optional&lt;int64_t&gt; end=::std::nullopt, int64_t step=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l912"><span class="ln">912  </span></a>  <span class="s0">at::Tensor slice_inverse_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim=</span><span class="s6">0</span><span class="s0">, ::std::optional&lt;c10::SymInt&gt; start=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; end=::std::nullopt, c10::SymInt step=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l913"><span class="ln">913  </span></a>  <span class="s0">at::Tensor slice_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim=</span><span class="s6">0</span><span class="s0">, ::std::optional&lt;int64_t&gt; start=::std::nullopt, ::std::optional&lt;int64_t&gt; end=::std::nullopt, int64_t step=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l914"><span class="ln">914  </span></a>  <span class="s0">at::Tensor slice_scatter_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim=</span><span class="s6">0</span><span class="s0">, ::std::optional&lt;c10::SymInt&gt; start=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; end=::std::nullopt, c10::SymInt step=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l915"><span class="ln">915  </span></a>  <span class="s0">at::Tensor select_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, int64_t index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l916"><span class="ln">916  </span></a>  <span class="s0">at::Tensor select_scatter_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, c10::SymInt index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l917"><span class="ln">917  </span></a>  <span class="s0">at::Tensor diagonal_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t offset=</span><span class="s6">0</span><span class="s0">, int64_t dim1=</span><span class="s6">0</span><span class="s0">, int64_t dim2=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l918"><span class="ln">918  </span></a>  <span class="s0">at::Tensor as_strided_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l919"><span class="ln">919  </span></a>  <span class="s0">at::Tensor as_strided_scatter_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l920"><span class="ln">920  </span></a>  <span class="s0">at::Tensor smm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l921"><span class="ln">921  </span></a>  <span class="s0">at::Tensor softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l922"><span class="ln">922  </span></a>  <span class="s0">at::Tensor softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l923"><span class="ln">923  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unsafe_split(int64_t split_size, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l924"><span class="ln">924  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unsafe_split_symint(c10::SymInt split_size, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l925"><span class="ln">925  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; split(int64_t split_size, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l926"><span class="ln">926  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; split_symint(c10::SymInt split_size, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l927"><span class="ln">927  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; split(at::IntArrayRef split_size, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l928"><span class="ln">928  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; split_symint(c10::SymIntArrayRef split_size, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l929"><span class="ln">929  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unsafe_split_with_sizes(at::IntArrayRef split_sizes, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l930"><span class="ln">930  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unsafe_split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l931"><span class="ln">931  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; split_with_sizes(at::IntArrayRef split_sizes, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l932"><span class="ln">932  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l933"><span class="ln">933  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; hsplit(int64_t sections) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l934"><span class="ln">934  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; hsplit(at::IntArrayRef indices) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l935"><span class="ln">935  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; vsplit(int64_t sections) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l936"><span class="ln">936  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; vsplit(at::IntArrayRef indices) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l937"><span class="ln">937  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; dsplit(int64_t sections) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l938"><span class="ln">938  </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; dsplit(at::IntArrayRef indices) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l939"><span class="ln">939  </span></a>  <span class="s0">at::Tensor squeeze() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l940"><span class="ln">940  </span></a>  <span class="s0">at::Tensor squeeze(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l941"><span class="ln">941  </span></a>  <span class="s0">at::Tensor squeeze(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l942"><span class="ln">942  </span></a>  <span class="s0">at::Tensor squeeze(at::IntArrayRef dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l943"><span class="ln">943  </span></a>  <span class="s0">at::Tensor &amp; squeeze_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l944"><span class="ln">944  </span></a>  <span class="s0">at::Tensor &amp; squeeze_(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l945"><span class="ln">945  </span></a>  <span class="s0">at::Tensor &amp; squeeze_(at::IntArrayRef dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l946"><span class="ln">946  </span></a>  <span class="s0">at::Tensor &amp; squeeze_(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l947"><span class="ln">947  </span></a>  <span class="s0">at::Tensor sspaddmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l948"><span class="ln">948  </span></a>  <span class="s0">at::Tensor stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; window, </span><span class="s1">bool </span><span class="s0">normalized, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; onesided=::std::nullopt, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; return_complex=::std::nullopt, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; align_to_window=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l949"><span class="ln">949  </span></a>  <span class="s0">at::Tensor stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length=::std::nullopt, ::std::optional&lt;int64_t&gt; win_length=::std::nullopt, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; window={}, </span><span class="s1">bool </span><span class="s0">center=</span><span class="s2">true</span><span class="s0">, c10::string_view pad_mode=</span><span class="s5">&quot;reflect&quot;</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">normalized=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; onesided=::std::nullopt, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; return_complex=::std::nullopt, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; align_to_window=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l950"><span class="ln">950  </span></a>  <span class="s0">at::Tensor istft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length=::std::nullopt, ::std::optional&lt;int64_t&gt; win_length=::std::nullopt, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; window={}, </span><span class="s1">bool </span><span class="s0">center=</span><span class="s2">true</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">normalized=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; onesided=::std::nullopt, ::std::optional&lt;int64_t&gt; length=::std::nullopt, </span><span class="s1">bool </span><span class="s0">return_complex=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l951"><span class="ln">951  </span></a>  <span class="s0">int64_t stride(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l952"><span class="ln">952  </span></a>  <span class="s0">at::Tensor sum(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l953"><span class="ln">953  </span></a>  <span class="s0">at::Tensor sum(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l954"><span class="ln">954  </span></a>  <span class="s0">at::Tensor sum(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l955"><span class="ln">955  </span></a>  <span class="s0">at::Tensor nansum(at::OptionalIntArrayRef dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l956"><span class="ln">956  </span></a>  <span class="s0">at::Tensor sum_to_size(at::IntArrayRef size) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l957"><span class="ln">957  </span></a>  <span class="s0">at::Tensor sum_to_size_symint(c10::SymIntArrayRef size) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l958"><span class="ln">958  </span></a>  <span class="s0">at::Tensor sqrt() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l959"><span class="ln">959  </span></a>  <span class="s0">at::Tensor &amp; sqrt_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l960"><span class="ln">960  </span></a>  <span class="s0">at::Tensor square() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l961"><span class="ln">961  </span></a>  <span class="s0">at::Tensor &amp; square_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l962"><span class="ln">962  </span></a>  <span class="s0">at::Tensor std(</span><span class="s1">bool </span><span class="s0">unbiased) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l963"><span class="ln">963  </span></a>  <span class="s0">at::Tensor std(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l964"><span class="ln">964  </span></a>  <span class="s0">at::Tensor std(at::OptionalIntArrayRef dim=::std::nullopt, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l965"><span class="ln">965  </span></a>  <span class="s0">at::Tensor std(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l966"><span class="ln">966  </span></a>  <span class="s0">at::Tensor std(at::DimnameList dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l967"><span class="ln">967  </span></a>  <span class="s0">at::Tensor prod(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l968"><span class="ln">968  </span></a>  <span class="s0">at::Tensor prod(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l969"><span class="ln">969  </span></a>  <span class="s0">at::Tensor prod(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l970"><span class="ln">970  </span></a>  <span class="s0">at::Tensor t() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l971"><span class="ln">971  </span></a>  <span class="s0">at::Tensor &amp; t_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l972"><span class="ln">972  </span></a>  <span class="s0">at::Tensor tan() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l973"><span class="ln">973  </span></a>  <span class="s0">at::Tensor &amp; tan_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l974"><span class="ln">974  </span></a>  <span class="s0">at::Tensor tanh() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l975"><span class="ln">975  </span></a>  <span class="s0">at::Tensor &amp; tanh_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l976"><span class="ln">976  </span></a>  <span class="s0">at::Tensor tile(at::IntArrayRef dims) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l977"><span class="ln">977  </span></a>  <span class="s0">at::Tensor tile_symint(c10::SymIntArrayRef dims) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l978"><span class="ln">978  </span></a>  <span class="s0">at::Tensor transpose(int64_t dim0, int64_t dim1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l979"><span class="ln">979  </span></a>  <span class="s0">at::Tensor transpose(at::Dimname dim0, at::Dimname dim1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l980"><span class="ln">980  </span></a>  <span class="s0">at::Tensor &amp; transpose_(int64_t dim0, int64_t dim1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l981"><span class="ln">981  </span></a>  <span class="s0">at::Tensor flip(at::IntArrayRef dims) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l982"><span class="ln">982  </span></a>  <span class="s0">at::Tensor fliplr() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l983"><span class="ln">983  </span></a>  <span class="s0">at::Tensor flipud() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l984"><span class="ln">984  </span></a>  <span class="s0">at::Tensor roll(at::IntArrayRef shifts, at::IntArrayRef dims={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l985"><span class="ln">985  </span></a>  <span class="s0">at::Tensor roll_symint(c10::SymIntArrayRef shifts, at::IntArrayRef dims={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l986"><span class="ln">986  </span></a>  <span class="s0">at::Tensor rot90(int64_t k=</span><span class="s6">1</span><span class="s0">, at::IntArrayRef dims={</span><span class="s6">0</span><span class="s0">,</span><span class="s6">1</span><span class="s0">}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l987"><span class="ln">987  </span></a>  <span class="s0">at::Tensor _nested_tensor_size() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l988"><span class="ln">988  </span></a>  <span class="s0">at::Tensor _nested_tensor_strides() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l989"><span class="ln">989  </span></a>  <span class="s0">at::Tensor _nested_tensor_storage_offsets() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l990"><span class="ln">990  </span></a>  <span class="s0">at::Tensor trunc() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l991"><span class="ln">991  </span></a>  <span class="s0">at::Tensor &amp; trunc_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l992"><span class="ln">992  </span></a>  <span class="s0">at::Tensor fix() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l993"><span class="ln">993  </span></a>  <span class="s0">at::Tensor &amp; fix_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l994"><span class="ln">994  </span></a>  <span class="s0">at::Tensor type_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l995"><span class="ln">995  </span></a>  <span class="s0">at::Tensor unsqueeze(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l996"><span class="ln">996  </span></a>  <span class="s0">at::Tensor &amp; unsqueeze_(int64_t dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l997"><span class="ln">997  </span></a>  <span class="s0">at::Tensor var(</span><span class="s1">bool </span><span class="s0">unbiased) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l998"><span class="ln">998  </span></a>  <span class="s0">at::Tensor var(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l999"><span class="ln">999  </span></a>  <span class="s0">at::Tensor var(at::OptionalIntArrayRef dim=::std::nullopt, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1000"><span class="ln">1000 </span></a>  <span class="s0">at::Tensor var(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1001"><span class="ln">1001 </span></a>  <span class="s0">at::Tensor var(at::DimnameList dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1002"><span class="ln">1002 </span></a>  <span class="s0">at::Tensor view_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1003"><span class="ln">1003 </span></a>  <span class="s0">at::Tensor where(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; condition, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1004"><span class="ln">1004 </span></a>  <span class="s0">at::Tensor where(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; condition, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1005"><span class="ln">1005 </span></a>  <span class="s0">at::Tensor norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::ScalarType dtype) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1006"><span class="ln">1006 </span></a>  <span class="s0">at::Tensor norm(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; p=</span><span class="s6">2</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1007"><span class="ln">1007 </span></a>  <span class="s0">at::Tensor norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim, at::ScalarType dtype) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1008"><span class="ln">1008 </span></a>  <span class="s0">at::Tensor norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1009"><span class="ln">1009 </span></a>  <span class="s0">at::Tensor norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim, at::ScalarType dtype) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1010"><span class="ln">1010 </span></a>  <span class="s0">at::Tensor norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1011"><span class="ln">1011 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; frexp() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1012"><span class="ln">1012 </span></a>  <span class="s0">at::Tensor clone(::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1013"><span class="ln">1013 </span></a>  <span class="s0">at::Tensor positive() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1014"><span class="ln">1014 </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; resize_as_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; the_template, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1015"><span class="ln">1015 </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; resize_as_sparse_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; the_template) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1016"><span class="ln">1016 </span></a>  <span class="s0">at::Tensor &amp; zero_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1017"><span class="ln">1017 </span></a>  <span class="s0">at::Tensor sub(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1018"><span class="ln">1018 </span></a>  <span class="s0">at::Tensor &amp; sub_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1019"><span class="ln">1019 </span></a>  <span class="s0">at::Tensor sub(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1020"><span class="ln">1020 </span></a>  <span class="s0">at::Tensor &amp; sub_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1021"><span class="ln">1021 </span></a>  <span class="s0">at::Tensor subtract(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1022"><span class="ln">1022 </span></a>  <span class="s0">at::Tensor &amp; subtract_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1023"><span class="ln">1023 </span></a>  <span class="s0">at::Tensor subtract(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1024"><span class="ln">1024 </span></a>  <span class="s0">at::Tensor &amp; subtract_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1025"><span class="ln">1025 </span></a>  <span class="s0">at::Tensor heaviside(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; values) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1026"><span class="ln">1026 </span></a>  <span class="s0">at::Tensor &amp; heaviside_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; values) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1027"><span class="ln">1027 </span></a>  <span class="s0">at::Tensor addmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1028"><span class="ln">1028 </span></a>  <span class="s0">at::Tensor &amp; addmm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1029"><span class="ln">1029 </span></a>  <span class="s0">at::Tensor _addmm_activation(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">use_gelu=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1030"><span class="ln">1030 </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; sparse_resize_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1031"><span class="ln">1031 </span></a>  <span class="s1">const </span><span class="s0">at::Tensor &amp; sparse_resize_and_clear_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1032"><span class="ln">1032 </span></a>  <span class="s0">at::Tensor sparse_mask(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1033"><span class="ln">1033 </span></a>  <span class="s0">at::Tensor _sparse_mask_projection(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">bool </span><span class="s0">accumulate_matches=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1034"><span class="ln">1034 </span></a>  <span class="s0">at::Tensor to_dense(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; masked_grad=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1035"><span class="ln">1035 </span></a>  <span class="s0">at::Tensor _to_dense(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; masked_grad=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1036"><span class="ln">1036 </span></a>  <span class="s0">int64_t sparse_dim() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1037"><span class="ln">1037 </span></a>  <span class="s0">int64_t _dimI() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1038"><span class="ln">1038 </span></a>  <span class="s0">int64_t dense_dim() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1039"><span class="ln">1039 </span></a>  <span class="s0">int64_t _dimV() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1040"><span class="ln">1040 </span></a>  <span class="s0">int64_t _nnz() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1041"><span class="ln">1041 </span></a>  <span class="s0">at::Tensor coalesce() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1042"><span class="ln">1042 </span></a>  <span class="s1">bool </span><span class="s0">is_coalesced() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1043"><span class="ln">1043 </span></a>  <span class="s0">at::Tensor _indices() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1044"><span class="ln">1044 </span></a>  <span class="s0">at::Tensor _values() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1045"><span class="ln">1045 </span></a>  <span class="s0">at::Tensor &amp; _coalesced_(</span><span class="s1">bool </span><span class="s0">coalesced) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1046"><span class="ln">1046 </span></a>  <span class="s0">at::Tensor indices() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1047"><span class="ln">1047 </span></a>  <span class="s0">at::Tensor values() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1048"><span class="ln">1048 </span></a>  <span class="s0">at::Tensor crow_indices() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1049"><span class="ln">1049 </span></a>  <span class="s0">at::Tensor col_indices() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1050"><span class="ln">1050 </span></a>  <span class="s0">at::Tensor ccol_indices() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1051"><span class="ln">1051 </span></a>  <span class="s0">at::Tensor row_indices() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1052"><span class="ln">1052 </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unbind(int64_t dim=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1053"><span class="ln">1053 </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; unbind(at::Dimname dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1054"><span class="ln">1054 </span></a>  <span class="s0">at::Tensor to_sparse(int64_t sparse_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1055"><span class="ln">1055 </span></a>  <span class="s0">at::Tensor _to_sparse(int64_t sparse_dim) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1056"><span class="ln">1056 </span></a>  <span class="s0">at::Tensor to_sparse(::std::optional&lt;at::Layout&gt; layout=::std::nullopt, at::OptionalIntArrayRef blocksize=::std::nullopt, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1057"><span class="ln">1057 </span></a>  <span class="s0">at::Tensor _to_sparse(::std::optional&lt;at::Layout&gt; layout=::std::nullopt, at::OptionalIntArrayRef blocksize=::std::nullopt, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1058"><span class="ln">1058 </span></a>  <span class="s0">at::Tensor to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1059"><span class="ln">1059 </span></a>  <span class="s0">at::Tensor _to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1060"><span class="ln">1060 </span></a>  <span class="s0">at::Tensor to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1061"><span class="ln">1061 </span></a>  <span class="s0">at::Tensor _to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1062"><span class="ln">1062 </span></a>  <span class="s0">at::Tensor to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1063"><span class="ln">1063 </span></a>  <span class="s0">at::Tensor _to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1064"><span class="ln">1064 </span></a>  <span class="s0">at::Tensor to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1065"><span class="ln">1065 </span></a>  <span class="s0">at::Tensor _to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1066"><span class="ln">1066 </span></a>  <span class="s0">at::Tensor to_mkldnn(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1067"><span class="ln">1067 </span></a>  <span class="s0">at::Tensor dequantize() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1068"><span class="ln">1068 </span></a>  <span class="s1">double </span><span class="s0">q_scale() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1069"><span class="ln">1069 </span></a>  <span class="s0">int64_t q_zero_point() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1070"><span class="ln">1070 </span></a>  <span class="s0">at::Tensor q_per_channel_scales() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1071"><span class="ln">1071 </span></a>  <span class="s0">at::Tensor q_per_channel_zero_points() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1072"><span class="ln">1072 </span></a>  <span class="s0">int64_t q_per_channel_axis() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1073"><span class="ln">1073 </span></a>  <span class="s0">at::Tensor int_repr() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1074"><span class="ln">1074 </span></a>  <span class="s0">at::QScheme qscheme() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1075"><span class="ln">1075 </span></a>  <span class="s0">at::Tensor _autocast_to_reduced_precision(</span><span class="s1">bool </span><span class="s0">cuda_enabled, </span><span class="s1">bool </span><span class="s0">cpu_enabled, at::ScalarType cuda_dtype, at::ScalarType cpu_dtype) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1076"><span class="ln">1076 </span></a>  <span class="s0">at::Tensor _autocast_to_full_precision(</span><span class="s1">bool </span><span class="s0">cuda_enabled, </span><span class="s1">bool </span><span class="s0">cpu_enabled) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1077"><span class="ln">1077 </span></a>  <span class="s0">at::Tensor to(at::TensorOptions options={}, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">copy=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1078"><span class="ln">1078 </span></a>  <span class="s0">at::Tensor to(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory, </span><span class="s1">bool </span><span class="s0">non_blocking, </span><span class="s1">bool </span><span class="s0">copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1079"><span class="ln">1079 </span></a>  <span class="s0">at::Tensor to(at::Device device, at::ScalarType dtype, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">copy=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1080"><span class="ln">1080 </span></a>  <span class="s0">at::Tensor to(at::ScalarType dtype, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">copy=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1081"><span class="ln">1081 </span></a>  <span class="s0">at::Tensor to(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">copy=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1082"><span class="ln">1082 </span></a>  <span class="s0">at::Scalar item() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1083"><span class="ln">1083 </span></a>  <span class="s0">at::Tensor &amp; set_(at::Storage source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1084"><span class="ln">1084 </span></a>  <span class="s0">at::Tensor &amp; set_(at::Storage source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1085"><span class="ln">1085 </span></a>  <span class="s0">at::Tensor &amp; set__symint(at::Storage source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1086"><span class="ln">1086 </span></a>  <span class="s0">at::Tensor &amp; set_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1087"><span class="ln">1087 </span></a>  <span class="s0">at::Tensor &amp; set__symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride={}) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1088"><span class="ln">1088 </span></a>  <span class="s0">at::Tensor &amp; set_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1089"><span class="ln">1089 </span></a>  <span class="s0">at::Tensor &amp; set_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1090"><span class="ln">1090 </span></a>  <span class="s1">bool </span><span class="s0">is_set_to(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1091"><span class="ln">1091 </span></a>  <span class="s0">at::Tensor &amp; masked_fill_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1092"><span class="ln">1092 </span></a>  <span class="s0">at::Tensor masked_fill(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1093"><span class="ln">1093 </span></a>  <span class="s0">at::Tensor &amp; masked_fill_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1094"><span class="ln">1094 </span></a>  <span class="s0">at::Tensor masked_fill(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1095"><span class="ln">1095 </span></a>  <span class="s0">at::Tensor &amp; masked_scatter_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1096"><span class="ln">1096 </span></a>  <span class="s0">at::Tensor masked_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1097"><span class="ln">1097 </span></a>  <span class="s0">at::Tensor view(at::IntArrayRef size) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1098"><span class="ln">1098 </span></a>  <span class="s0">at::Tensor view_symint(c10::SymIntArrayRef size) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1099"><span class="ln">1099 </span></a>  <span class="s0">at::Tensor view(at::ScalarType dtype) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1100"><span class="ln">1100 </span></a>  <span class="s0">at::Tensor &amp; put_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">bool </span><span class="s0">accumulate=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1101"><span class="ln">1101 </span></a>  <span class="s0">at::Tensor put(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">bool </span><span class="s0">accumulate=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1102"><span class="ln">1102 </span></a>  <span class="s0">at::Tensor &amp; index_add_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1103"><span class="ln">1103 </span></a>  <span class="s0">at::Tensor index_add(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1104"><span class="ln">1104 </span></a>  <span class="s0">at::Tensor index_add(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1105"><span class="ln">1105 </span></a>  <span class="s0">at::Tensor &amp; index_reduce_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1106"><span class="ln">1106 </span></a>  <span class="s0">at::Tensor index_reduce(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1107"><span class="ln">1107 </span></a>  <span class="s0">at::Tensor &amp; index_fill_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1108"><span class="ln">1108 </span></a>  <span class="s0">at::Tensor index_fill(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1109"><span class="ln">1109 </span></a>  <span class="s0">at::Tensor &amp; index_fill_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1110"><span class="ln">1110 </span></a>  <span class="s0">at::Tensor index_fill(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1111"><span class="ln">1111 </span></a>  <span class="s0">at::Tensor &amp; index_fill_(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1112"><span class="ln">1112 </span></a>  <span class="s0">at::Tensor &amp; index_fill_(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1113"><span class="ln">1113 </span></a>  <span class="s0">at::Tensor index_fill(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1114"><span class="ln">1114 </span></a>  <span class="s0">at::Tensor index_fill(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1115"><span class="ln">1115 </span></a>  <span class="s0">at::Tensor scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1116"><span class="ln">1116 </span></a>  <span class="s0">at::Tensor &amp; scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1117"><span class="ln">1117 </span></a>  <span class="s0">at::Tensor scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1118"><span class="ln">1118 </span></a>  <span class="s0">at::Tensor &amp; scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1119"><span class="ln">1119 </span></a>  <span class="s0">at::Tensor scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1120"><span class="ln">1120 </span></a>  <span class="s0">at::Tensor &amp; scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1121"><span class="ln">1121 </span></a>  <span class="s0">at::Tensor scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value, c10::string_view reduce) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1122"><span class="ln">1122 </span></a>  <span class="s0">at::Tensor &amp; scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value, c10::string_view reduce) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1123"><span class="ln">1123 </span></a>  <span class="s0">at::Tensor scatter(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1124"><span class="ln">1124 </span></a>  <span class="s0">at::Tensor scatter(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1125"><span class="ln">1125 </span></a>  <span class="s0">at::Tensor scatter_add(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1126"><span class="ln">1126 </span></a>  <span class="s0">at::Tensor &amp; scatter_add_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1127"><span class="ln">1127 </span></a>  <span class="s0">at::Tensor scatter_add(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1128"><span class="ln">1128 </span></a>  <span class="s0">at::Tensor scatter_reduce(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1129"><span class="ln">1129 </span></a>  <span class="s0">at::Tensor &amp; scatter_reduce_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1130"><span class="ln">1130 </span></a>  <span class="s0">at::Tensor &amp; eq_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1131"><span class="ln">1131 </span></a>  <span class="s0">at::Tensor &amp; eq_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1132"><span class="ln">1132 </span></a>  <span class="s0">at::Tensor bitwise_and(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1133"><span class="ln">1133 </span></a>  <span class="s0">at::Tensor bitwise_and(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1134"><span class="ln">1134 </span></a>  <span class="s0">at::Tensor &amp; bitwise_and_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1135"><span class="ln">1135 </span></a>  <span class="s0">at::Tensor &amp; bitwise_and_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1136"><span class="ln">1136 </span></a>  <span class="s0">at::Tensor __and__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1137"><span class="ln">1137 </span></a>  <span class="s0">at::Tensor __and__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1138"><span class="ln">1138 </span></a>  <span class="s0">at::Tensor &amp; __iand__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1139"><span class="ln">1139 </span></a>  <span class="s0">at::Tensor &amp; __iand__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1140"><span class="ln">1140 </span></a>  <span class="s0">at::Tensor bitwise_or(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1141"><span class="ln">1141 </span></a>  <span class="s0">at::Tensor bitwise_or(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1142"><span class="ln">1142 </span></a>  <span class="s0">at::Tensor &amp; bitwise_or_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1143"><span class="ln">1143 </span></a>  <span class="s0">at::Tensor &amp; bitwise_or_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1144"><span class="ln">1144 </span></a>  <span class="s0">at::Tensor __or__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1145"><span class="ln">1145 </span></a>  <span class="s0">at::Tensor __or__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1146"><span class="ln">1146 </span></a>  <span class="s0">at::Tensor &amp; __ior__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1147"><span class="ln">1147 </span></a>  <span class="s0">at::Tensor &amp; __ior__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1148"><span class="ln">1148 </span></a>  <span class="s0">at::Tensor bitwise_xor(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1149"><span class="ln">1149 </span></a>  <span class="s0">at::Tensor bitwise_xor(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1150"><span class="ln">1150 </span></a>  <span class="s0">at::Tensor &amp; bitwise_xor_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1151"><span class="ln">1151 </span></a>  <span class="s0">at::Tensor &amp; bitwise_xor_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1152"><span class="ln">1152 </span></a>  <span class="s0">at::Tensor __xor__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1153"><span class="ln">1153 </span></a>  <span class="s0">at::Tensor __xor__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1154"><span class="ln">1154 </span></a>  <span class="s0">at::Tensor &amp; __ixor__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1155"><span class="ln">1155 </span></a>  <span class="s0">at::Tensor &amp; __ixor__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1156"><span class="ln">1156 </span></a>  <span class="s0">at::Tensor __lshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1157"><span class="ln">1157 </span></a>  <span class="s0">at::Tensor __lshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1158"><span class="ln">1158 </span></a>  <span class="s0">at::Tensor &amp; __ilshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1159"><span class="ln">1159 </span></a>  <span class="s0">at::Tensor &amp; __ilshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1160"><span class="ln">1160 </span></a>  <span class="s0">at::Tensor bitwise_left_shift(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1161"><span class="ln">1161 </span></a>  <span class="s0">at::Tensor &amp; bitwise_left_shift_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1162"><span class="ln">1162 </span></a>  <span class="s0">at::Tensor bitwise_left_shift(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1163"><span class="ln">1163 </span></a>  <span class="s0">at::Tensor &amp; bitwise_left_shift_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1164"><span class="ln">1164 </span></a>  <span class="s0">at::Tensor __rshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1165"><span class="ln">1165 </span></a>  <span class="s0">at::Tensor __rshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1166"><span class="ln">1166 </span></a>  <span class="s0">at::Tensor &amp; __irshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1167"><span class="ln">1167 </span></a>  <span class="s0">at::Tensor &amp; __irshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1168"><span class="ln">1168 </span></a>  <span class="s0">at::Tensor bitwise_right_shift(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1169"><span class="ln">1169 </span></a>  <span class="s0">at::Tensor &amp; bitwise_right_shift_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1170"><span class="ln">1170 </span></a>  <span class="s0">at::Tensor bitwise_right_shift(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1171"><span class="ln">1171 </span></a>  <span class="s0">at::Tensor &amp; bitwise_right_shift_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1172"><span class="ln">1172 </span></a>  <span class="s0">at::Tensor &amp; tril_(int64_t diagonal=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1173"><span class="ln">1173 </span></a>  <span class="s0">at::Tensor &amp; triu_(int64_t diagonal=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1174"><span class="ln">1174 </span></a>  <span class="s0">at::Tensor &amp; digamma_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1175"><span class="ln">1175 </span></a>  <span class="s0">at::Tensor &amp; lerp_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; weight) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1176"><span class="ln">1176 </span></a>  <span class="s0">at::Tensor &amp; lerp_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; weight) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1177"><span class="ln">1177 </span></a>  <span class="s0">at::Tensor &amp; addbmm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1178"><span class="ln">1178 </span></a>  <span class="s0">at::Tensor addbmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1179"><span class="ln">1179 </span></a>  <span class="s0">at::Tensor &amp; random_(int64_t from, ::std::optional&lt;int64_t&gt; to, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1180"><span class="ln">1180 </span></a>  <span class="s0">at::Tensor &amp; random_(int64_t to, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1181"><span class="ln">1181 </span></a>  <span class="s0">at::Tensor &amp; random_(::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1182"><span class="ln">1182 </span></a>  <span class="s0">at::Tensor &amp; uniform_(</span><span class="s1">double </span><span class="s0">from=</span><span class="s6">0</span><span class="s0">, </span><span class="s1">double </span><span class="s0">to=</span><span class="s6">1</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1183"><span class="ln">1183 </span></a>  <span class="s0">at::Tensor &amp; cauchy_(</span><span class="s1">double </span><span class="s0">median=</span><span class="s6">0</span><span class="s0">, </span><span class="s1">double </span><span class="s0">sigma=</span><span class="s6">1</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1184"><span class="ln">1184 </span></a>  <span class="s0">at::Tensor &amp; log_normal_(</span><span class="s1">double </span><span class="s0">mean=</span><span class="s6">1</span><span class="s0">, </span><span class="s1">double </span><span class="s0">std=</span><span class="s6">2</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1185"><span class="ln">1185 </span></a>  <span class="s0">at::Tensor &amp; exponential_(</span><span class="s1">double </span><span class="s0">lambd=</span><span class="s6">1</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1186"><span class="ln">1186 </span></a>  <span class="s0">at::Tensor &amp; geometric_(</span><span class="s1">double </span><span class="s0">p, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1187"><span class="ln">1187 </span></a>  <span class="s0">at::Tensor diag(int64_t diagonal=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1188"><span class="ln">1188 </span></a>  <span class="s0">at::Tensor cross(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;int64_t&gt; dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1189"><span class="ln">1189 </span></a>  <span class="s0">at::Tensor triu(int64_t diagonal=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1190"><span class="ln">1190 </span></a>  <span class="s0">at::Tensor tril(int64_t diagonal=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1191"><span class="ln">1191 </span></a>  <span class="s0">at::Tensor trace() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1192"><span class="ln">1192 </span></a>  <span class="s0">at::Tensor ne(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1193"><span class="ln">1193 </span></a>  <span class="s0">at::Tensor ne(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1194"><span class="ln">1194 </span></a>  <span class="s0">at::Tensor &amp; ne_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1195"><span class="ln">1195 </span></a>  <span class="s0">at::Tensor &amp; ne_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1196"><span class="ln">1196 </span></a>  <span class="s0">at::Tensor not_equal(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1197"><span class="ln">1197 </span></a>  <span class="s0">at::Tensor not_equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1198"><span class="ln">1198 </span></a>  <span class="s0">at::Tensor &amp; not_equal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1199"><span class="ln">1199 </span></a>  <span class="s0">at::Tensor &amp; not_equal_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1200"><span class="ln">1200 </span></a>  <span class="s0">at::Tensor eq(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1201"><span class="ln">1201 </span></a>  <span class="s0">at::Tensor eq(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1202"><span class="ln">1202 </span></a>  <span class="s0">at::Tensor ge(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1203"><span class="ln">1203 </span></a>  <span class="s0">at::Tensor ge(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1204"><span class="ln">1204 </span></a>  <span class="s0">at::Tensor &amp; ge_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1205"><span class="ln">1205 </span></a>  <span class="s0">at::Tensor &amp; ge_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1206"><span class="ln">1206 </span></a>  <span class="s0">at::Tensor greater_equal(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1207"><span class="ln">1207 </span></a>  <span class="s0">at::Tensor greater_equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1208"><span class="ln">1208 </span></a>  <span class="s0">at::Tensor &amp; greater_equal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1209"><span class="ln">1209 </span></a>  <span class="s0">at::Tensor &amp; greater_equal_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1210"><span class="ln">1210 </span></a>  <span class="s0">at::Tensor le(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1211"><span class="ln">1211 </span></a>  <span class="s0">at::Tensor le(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1212"><span class="ln">1212 </span></a>  <span class="s0">at::Tensor &amp; le_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1213"><span class="ln">1213 </span></a>  <span class="s0">at::Tensor &amp; le_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1214"><span class="ln">1214 </span></a>  <span class="s0">at::Tensor less_equal(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1215"><span class="ln">1215 </span></a>  <span class="s0">at::Tensor less_equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1216"><span class="ln">1216 </span></a>  <span class="s0">at::Tensor &amp; less_equal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1217"><span class="ln">1217 </span></a>  <span class="s0">at::Tensor &amp; less_equal_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1218"><span class="ln">1218 </span></a>  <span class="s0">at::Tensor gt(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1219"><span class="ln">1219 </span></a>  <span class="s0">at::Tensor gt(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1220"><span class="ln">1220 </span></a>  <span class="s0">at::Tensor &amp; gt_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1221"><span class="ln">1221 </span></a>  <span class="s0">at::Tensor &amp; gt_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1222"><span class="ln">1222 </span></a>  <span class="s0">at::Tensor greater(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1223"><span class="ln">1223 </span></a>  <span class="s0">at::Tensor greater(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1224"><span class="ln">1224 </span></a>  <span class="s0">at::Tensor &amp; greater_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1225"><span class="ln">1225 </span></a>  <span class="s0">at::Tensor &amp; greater_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1226"><span class="ln">1226 </span></a>  <span class="s0">at::Tensor lt(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1227"><span class="ln">1227 </span></a>  <span class="s0">at::Tensor lt(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1228"><span class="ln">1228 </span></a>  <span class="s0">at::Tensor &amp; lt_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1229"><span class="ln">1229 </span></a>  <span class="s0">at::Tensor &amp; lt_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1230"><span class="ln">1230 </span></a>  <span class="s0">at::Tensor less(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1231"><span class="ln">1231 </span></a>  <span class="s0">at::Tensor less(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1232"><span class="ln">1232 </span></a>  <span class="s0">at::Tensor &amp; less_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1233"><span class="ln">1233 </span></a>  <span class="s0">at::Tensor &amp; less_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1234"><span class="ln">1234 </span></a>  <span class="s0">at::Tensor take(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1235"><span class="ln">1235 </span></a>  <span class="s0">at::Tensor take_along_dim(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; indices, ::std::optional&lt;int64_t&gt; dim=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1236"><span class="ln">1236 </span></a>  <span class="s0">at::Tensor index_select(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1237"><span class="ln">1237 </span></a>  <span class="s0">at::Tensor index_select(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1238"><span class="ln">1238 </span></a>  <span class="s0">at::Tensor masked_select(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1239"><span class="ln">1239 </span></a>  <span class="s0">at::Tensor nonzero() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1240"><span class="ln">1240 </span></a>  <span class="s0">at::Tensor nonzero_static(int64_t size, int64_t fill_value=-</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1241"><span class="ln">1241 </span></a>  <span class="s0">at::Tensor nonzero_static_symint(c10::SymInt size, int64_t fill_value=-</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1242"><span class="ln">1242 </span></a>  <span class="s0">::std::vector&lt;at::Tensor&gt; nonzero_numpy() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1243"><span class="ln">1243 </span></a>  <span class="s0">at::Tensor argwhere() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1244"><span class="ln">1244 </span></a>  <span class="s0">at::Tensor gather(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">bool </span><span class="s0">sparse_grad=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1245"><span class="ln">1245 </span></a>  <span class="s0">at::Tensor gather(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">bool </span><span class="s0">sparse_grad=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1246"><span class="ln">1246 </span></a>  <span class="s0">at::Tensor addcmul(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1247"><span class="ln">1247 </span></a>  <span class="s0">at::Tensor &amp; addcmul_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1248"><span class="ln">1248 </span></a>  <span class="s0">at::Tensor addcdiv(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1249"><span class="ln">1249 </span></a>  <span class="s0">at::Tensor &amp; addcdiv_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value=</span><span class="s6">1</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1250"><span class="ln">1250 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; triangular_solve(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; A, </span><span class="s1">bool </span><span class="s0">upper=</span><span class="s2">true</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">transpose=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">unitriangular=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1251"><span class="ln">1251 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt; svd(</span><span class="s1">bool </span><span class="s0">some=</span><span class="s2">true</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">compute_uv=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1252"><span class="ln">1252 </span></a>  <span class="s0">at::Tensor swapaxes(int64_t axis0, int64_t axis1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1253"><span class="ln">1253 </span></a>  <span class="s0">at::Tensor &amp; swapaxes_(int64_t axis0, int64_t axis1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1254"><span class="ln">1254 </span></a>  <span class="s0">at::Tensor swapdims(int64_t dim0, int64_t dim1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1255"><span class="ln">1255 </span></a>  <span class="s0">at::Tensor &amp; swapdims_(int64_t dim0, int64_t dim1) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1256"><span class="ln">1256 </span></a>  <span class="s0">at::Tensor cholesky(</span><span class="s1">bool </span><span class="s0">upper=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1257"><span class="ln">1257 </span></a>  <span class="s0">at::Tensor cholesky_solve(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; input2, </span><span class="s1">bool </span><span class="s0">upper=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1258"><span class="ln">1258 </span></a>  <span class="s0">at::Tensor cholesky_inverse(</span><span class="s1">bool </span><span class="s0">upper=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1259"><span class="ln">1259 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; qr(</span><span class="s1">bool </span><span class="s0">some=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1260"><span class="ln">1260 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; geqrf() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1261"><span class="ln">1261 </span></a>  <span class="s0">at::Tensor orgqr(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; input2) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1262"><span class="ln">1262 </span></a>  <span class="s0">at::Tensor ormqr(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; input2, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; input3, </span><span class="s1">bool </span><span class="s0">left=</span><span class="s2">true</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">transpose=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1263"><span class="ln">1263 </span></a>  <span class="s0">at::Tensor lu_solve(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; LU_data, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; LU_pivots) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1264"><span class="ln">1264 </span></a>  <span class="s0">at::Tensor multinomial(int64_t num_samples, </span><span class="s1">bool </span><span class="s0">replacement=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1265"><span class="ln">1265 </span></a>  <span class="s0">at::Tensor multinomial_symint(c10::SymInt num_samples, </span><span class="s1">bool </span><span class="s0">replacement=</span><span class="s1">false</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1266"><span class="ln">1266 </span></a>  <span class="s0">at::Tensor &amp; lgamma_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1267"><span class="ln">1267 </span></a>  <span class="s0">at::Tensor lgamma() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1268"><span class="ln">1268 </span></a>  <span class="s0">at::Tensor digamma() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1269"><span class="ln">1269 </span></a>  <span class="s0">at::Tensor polygamma(int64_t n) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1270"><span class="ln">1270 </span></a>  <span class="s0">at::Tensor &amp; polygamma_(int64_t n) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1271"><span class="ln">1271 </span></a>  <span class="s0">at::Tensor erfinv() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1272"><span class="ln">1272 </span></a>  <span class="s0">at::Tensor &amp; erfinv_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1273"><span class="ln">1273 </span></a>  <span class="s0">at::Tensor i0() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1274"><span class="ln">1274 </span></a>  <span class="s0">at::Tensor &amp; i0_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1275"><span class="ln">1275 </span></a>  <span class="s0">at::Tensor sign() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1276"><span class="ln">1276 </span></a>  <span class="s0">at::Tensor &amp; sign_() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1277"><span class="ln">1277 </span></a>  <span class="s0">at::Tensor signbit() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1278"><span class="ln">1278 </span></a>  <span class="s0">at::Tensor dist(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; p=</span><span class="s6">2</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1279"><span class="ln">1279 </span></a>  <span class="s0">at::Tensor &amp; atan2_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1280"><span class="ln">1280 </span></a>  <span class="s0">at::Tensor atan2(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1281"><span class="ln">1281 </span></a>  <span class="s0">at::Tensor arctan2(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1282"><span class="ln">1282 </span></a>  <span class="s0">at::Tensor &amp; arctan2_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1283"><span class="ln">1283 </span></a>  <span class="s0">at::Tensor lerp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; weight) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1284"><span class="ln">1284 </span></a>  <span class="s0">at::Tensor lerp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; weight) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1285"><span class="ln">1285 </span></a>  <span class="s0">at::Tensor histc(int64_t bins=</span><span class="s6">100</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; min=</span><span class="s6">0</span><span class="s0">, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; max=</span><span class="s6">0</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1286"><span class="ln">1286 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; histogram(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; bins, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weight={}, </span><span class="s1">bool </span><span class="s0">density=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1287"><span class="ln">1287 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; histogram(int64_t bins=</span><span class="s6">100</span><span class="s0">, ::std::optional&lt;at::ArrayRef&lt;</span><span class="s1">double</span><span class="s0">&gt;&gt; range=::std::nullopt, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weight={}, </span><span class="s1">bool </span><span class="s0">density=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1288"><span class="ln">1288 </span></a>  <span class="s0">at::Tensor fmod(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1289"><span class="ln">1289 </span></a>  <span class="s0">at::Tensor &amp; fmod_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1290"><span class="ln">1290 </span></a>  <span class="s0">at::Tensor fmod(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1291"><span class="ln">1291 </span></a>  <span class="s0">at::Tensor &amp; fmod_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1292"><span class="ln">1292 </span></a>  <span class="s0">at::Tensor hypot(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1293"><span class="ln">1293 </span></a>  <span class="s0">at::Tensor &amp; hypot_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1294"><span class="ln">1294 </span></a>  <span class="s0">at::Tensor igamma(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1295"><span class="ln">1295 </span></a>  <span class="s0">at::Tensor &amp; igamma_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1296"><span class="ln">1296 </span></a>  <span class="s0">at::Tensor igammac(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1297"><span class="ln">1297 </span></a>  <span class="s0">at::Tensor &amp; igammac_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1298"><span class="ln">1298 </span></a>  <span class="s0">at::Tensor nextafter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1299"><span class="ln">1299 </span></a>  <span class="s0">at::Tensor &amp; nextafter_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1300"><span class="ln">1300 </span></a>  <span class="s0">at::Tensor remainder(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1301"><span class="ln">1301 </span></a>  <span class="s0">at::Tensor &amp; remainder_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1302"><span class="ln">1302 </span></a>  <span class="s0">at::Tensor remainder(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1303"><span class="ln">1303 </span></a>  <span class="s0">at::Tensor &amp; remainder_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1304"><span class="ln">1304 </span></a>  <span class="s0">at::Tensor min() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1305"><span class="ln">1305 </span></a>  <span class="s0">at::Tensor fmin(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1306"><span class="ln">1306 </span></a>  <span class="s0">at::Tensor max() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1307"><span class="ln">1307 </span></a>  <span class="s0">at::Tensor fmax(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1308"><span class="ln">1308 </span></a>  <span class="s0">at::Tensor maximum(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1309"><span class="ln">1309 </span></a>  <span class="s0">at::Tensor max(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1310"><span class="ln">1310 </span></a>  <span class="s0">at::Tensor minimum(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1311"><span class="ln">1311 </span></a>  <span class="s0">at::Tensor min(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1312"><span class="ln">1312 </span></a>  <span class="s0">at::Tensor quantile(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, c10::string_view interpolation=</span><span class="s5">&quot;linear&quot;</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1313"><span class="ln">1313 </span></a>  <span class="s0">at::Tensor quantile(</span><span class="s1">double </span><span class="s0">q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, c10::string_view interpolation=</span><span class="s5">&quot;linear&quot;</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1314"><span class="ln">1314 </span></a>  <span class="s0">at::Tensor nanquantile(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, c10::string_view interpolation=</span><span class="s5">&quot;linear&quot;</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1315"><span class="ln">1315 </span></a>  <span class="s0">at::Tensor nanquantile(</span><span class="s1">double </span><span class="s0">q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, </span><span class="s1">bool </span><span class="s0">keepdim=</span><span class="s1">false</span><span class="s0">, c10::string_view interpolation=</span><span class="s5">&quot;linear&quot;</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1316"><span class="ln">1316 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1317"><span class="ln">1317 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; stable, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1318"><span class="ln">1318 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1319"><span class="ln">1319 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; stable, at::Dimname dim, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1320"><span class="ln">1320 </span></a>  <span class="s0">at::Tensor msort() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1321"><span class="ln">1321 </span></a>  <span class="s0">at::Tensor argsort(int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1322"><span class="ln">1322 </span></a>  <span class="s0">at::Tensor argsort(</span><span class="s1">bool </span><span class="s0">stable, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1323"><span class="ln">1323 </span></a>  <span class="s0">at::Tensor argsort(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">descending=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1324"><span class="ln">1324 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; topk(int64_t k, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">largest=</span><span class="s2">true</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">sorted=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1325"><span class="ln">1325 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; topk_symint(c10::SymInt k, int64_t dim=-</span><span class="s6">1</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">largest=</span><span class="s2">true</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">sorted=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1326"><span class="ln">1326 </span></a>  <span class="s0">at::Tensor all() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1327"><span class="ln">1327 </span></a>  <span class="s0">at::Tensor any() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1328"><span class="ln">1328 </span></a>  <span class="s0">at::Tensor renorm(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; p, int64_t dim, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; maxnorm) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1329"><span class="ln">1329 </span></a>  <span class="s0">at::Tensor &amp; renorm_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; p, int64_t dim, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; maxnorm) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1330"><span class="ln">1330 </span></a>  <span class="s0">at::Tensor unfold(int64_t dimension, int64_t size, int64_t step) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1331"><span class="ln">1331 </span></a>  <span class="s1">bool </span><span class="s0">equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1332"><span class="ln">1332 </span></a>  <span class="s0">at::Tensor pow(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1333"><span class="ln">1333 </span></a>  <span class="s0">at::Tensor pow(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1334"><span class="ln">1334 </span></a>  <span class="s0">at::Tensor &amp; pow_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1335"><span class="ln">1335 </span></a>  <span class="s0">at::Tensor &amp; pow_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1336"><span class="ln">1336 </span></a>  <span class="s0">at::Tensor float_power(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1337"><span class="ln">1337 </span></a>  <span class="s0">at::Tensor float_power(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1338"><span class="ln">1338 </span></a>  <span class="s0">at::Tensor &amp; float_power_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1339"><span class="ln">1339 </span></a>  <span class="s0">at::Tensor &amp; float_power_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1340"><span class="ln">1340 </span></a>  <span class="s0">at::Tensor &amp; normal_(</span><span class="s1">double </span><span class="s0">mean=</span><span class="s6">0</span><span class="s0">, </span><span class="s1">double </span><span class="s0">std=</span><span class="s6">1</span><span class="s0">, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1341"><span class="ln">1341 </span></a>  <span class="s0">at::Tensor alias() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1342"><span class="ln">1342 </span></a>  <span class="s0">at::Tensor isfinite() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1343"><span class="ln">1343 </span></a>  <span class="s0">at::Tensor isinf() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1344"><span class="ln">1344 </span></a>  <span class="s1">void </span><span class="s0">record_stream(at::Stream s) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1345"><span class="ln">1345 </span></a>  <span class="s0">at::Tensor isposinf() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1346"><span class="ln">1346 </span></a>  <span class="s0">at::Tensor isneginf() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1347"><span class="ln">1347 </span></a>  <span class="s0">at::Tensor det() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1348"><span class="ln">1348 </span></a>  <span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; slogdet() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1349"><span class="ln">1349 </span></a>  <span class="s0">at::Tensor logdet() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1350"><span class="ln">1350 </span></a>  <span class="s0">at::Tensor inverse() </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1351"><span class="ln">1351 </span></a>  <span class="s0">at::Tensor inner(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1352"><span class="ln">1352 </span></a>  <span class="s0">at::Tensor outer(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1353"><span class="ln">1353 </span></a>  <span class="s0">at::Tensor ger(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1354"><span class="ln">1354 </span></a>  <span class="s0">at::Tensor to_padded_tensor(</span><span class="s1">double </span><span class="s0">padding, at::OptionalIntArrayRef output_size=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1355"><span class="ln">1355 </span></a>  <span class="s0">at::Tensor to_padded_tensor_symint(</span><span class="s1">double </span><span class="s0">padding, at::OptionalSymIntArrayRef output_size=::std::nullopt) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1356"><span class="ln">1356 </span></a>
<a name="l1357"><span class="ln">1357 </span></a>  <span class="s3">// Special C++ only overloads for std()-like functions (See gh-40287)</span>
<a name="l1358"><span class="ln">1358 </span></a>  <span class="s3">// These are needed because int -&gt; bool conversion takes precedence over int -&gt; IntArrayRef</span>
<a name="l1359"><span class="ln">1359 </span></a>  <span class="s3">// So, for example std(0) would select the std(unbiased=False) overload</span>
<a name="l1360"><span class="ln">1360 </span></a>
<a name="l1361"><span class="ln">1361 </span></a>  <span class="s0">Tensor var(</span><span class="s1">int </span><span class="s0">dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1362"><span class="ln">1362 </span></a>    <span class="s1">return </span><span class="s0">var(IntArrayRef{dim});</span>
<a name="l1363"><span class="ln">1363 </span></a>  <span class="s0">}</span>
<a name="l1364"><span class="ln">1364 </span></a>
<a name="l1365"><span class="ln">1365 </span></a>  <span class="s0">Tensor std(</span><span class="s1">int </span><span class="s0">dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1366"><span class="ln">1366 </span></a>    <span class="s1">return </span><span class="s0">std(IntArrayRef{dim});</span>
<a name="l1367"><span class="ln">1367 </span></a>  <span class="s0">}</span>
<a name="l1368"><span class="ln">1368 </span></a>
<a name="l1369"><span class="ln">1369 </span></a>  <span class="s3">// We changed .dtype() to return a TypeMeta in #12766. Ideally, we want the</span>
<a name="l1370"><span class="ln">1370 </span></a>  <span class="s3">// at::kDouble and its friends to be TypeMeta's, but that hasn't happened yet.</span>
<a name="l1371"><span class="ln">1371 </span></a>  <span class="s3">// Before that change, we make this method to maintain BC for C++ usage like</span>
<a name="l1372"><span class="ln">1372 </span></a>  <span class="s3">// `x.to(y.dtype)`.</span>
<a name="l1373"><span class="ln">1373 </span></a>  <span class="s3">// TODO: remove following two after at::kDouble and its friends are TypeMeta's.</span>
<a name="l1374"><span class="ln">1374 </span></a>  <span class="s2">inline </span><span class="s0">Tensor to(caffe2::TypeMeta type_meta, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">copy=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1375"><span class="ln">1375 </span></a>    <span class="s1">return </span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">to(</span><span class="s3">/*scalar_type=*/</span><span class="s0">typeMetaToScalarType(type_meta), non_blocking, copy);</span>
<a name="l1376"><span class="ln">1376 </span></a>  <span class="s0">}</span>
<a name="l1377"><span class="ln">1377 </span></a>  <span class="s2">inline </span><span class="s0">Tensor to(Device device, caffe2::TypeMeta type_meta, </span><span class="s1">bool </span><span class="s0">non_blocking=</span><span class="s1">false</span><span class="s0">, </span><span class="s1">bool </span><span class="s0">copy=</span><span class="s1">false</span><span class="s0">) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1378"><span class="ln">1378 </span></a>    <span class="s1">return </span><span class="s2">this</span><span class="s4">-&gt;</span><span class="s0">to(device, </span><span class="s3">/*scalar_type=*/</span><span class="s0">typeMetaToScalarType(type_meta), non_blocking, copy);</span>
<a name="l1379"><span class="ln">1379 </span></a>  <span class="s0">}</span>
<a name="l1380"><span class="ln">1380 </span></a>
<a name="l1381"><span class="ln">1381 </span></a>  <span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">F, </span><span class="s2">typename</span><span class="s0">... Args&gt;</span>
<a name="l1382"><span class="ln">1382 </span></a>  <span class="s0">decltype(</span><span class="s1">auto</span><span class="s0">) m(F func, Args&amp;&amp;... params) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1383"><span class="ln">1383 </span></a>    <span class="s1">return </span><span class="s0">func(*</span><span class="s2">this</span><span class="s0">, std::forward&lt;Args&gt;(params)...);</span>
<a name="l1384"><span class="ln">1384 </span></a>  <span class="s0">}</span>
<a name="l1385"><span class="ln">1385 </span></a>
<a name="l1386"><span class="ln">1386 </span></a>  <span class="s3">/// NOTE: This is similar to the legacy `.data()` function on `Variable`, and is intended</span>
<a name="l1387"><span class="ln">1387 </span></a>  <span class="s3">/// to be used from functions that need to access the `Variable`'s equivalent `Tensor`</span>
<a name="l1388"><span class="ln">1388 </span></a>  <span class="s3">/// (i.e. `Tensor` that shares the same storage and tensor metadata with the `Variable`).</span>
<a name="l1389"><span class="ln">1389 </span></a>  <span class="s3">///</span>
<a name="l1390"><span class="ln">1390 </span></a>  <span class="s3">/// One notable difference with the legacy `.data()` function is that changes to the</span>
<a name="l1391"><span class="ln">1391 </span></a>  <span class="s3">/// returned `Tensor`'s tensor metadata (e.g. sizes / strides / storage / storage_offset)</span>
<a name="l1392"><span class="ln">1392 </span></a>  <span class="s3">/// will not update the original `Variable`, due to the fact that this function</span>
<a name="l1393"><span class="ln">1393 </span></a>  <span class="s3">/// shallow-copies the `Variable`'s underlying TensorImpl.</span>
<a name="l1394"><span class="ln">1394 </span></a>  <span class="s0">at::Tensor tensor_data() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1395"><span class="ln">1395 </span></a>    <span class="s1">return </span><span class="s0">TensorBase::tensor_data();</span>
<a name="l1396"><span class="ln">1396 </span></a>  <span class="s0">}</span>
<a name="l1397"><span class="ln">1397 </span></a>
<a name="l1398"><span class="ln">1398 </span></a>  <span class="s3">/// NOTE: `var.variable_data()` in C++ has the same semantics as `tensor.data`</span>
<a name="l1399"><span class="ln">1399 </span></a>  <span class="s3">/// in Python, which create a new `Variable` that shares the same storage and</span>
<a name="l1400"><span class="ln">1400 </span></a>  <span class="s3">/// tensor metadata with the original `Variable`, but with a completely new</span>
<a name="l1401"><span class="ln">1401 </span></a>  <span class="s3">/// autograd history.</span>
<a name="l1402"><span class="ln">1402 </span></a>  <span class="s3">///</span>
<a name="l1403"><span class="ln">1403 </span></a>  <span class="s3">/// NOTE: If we change the tensor metadata (e.g. sizes / strides /</span>
<a name="l1404"><span class="ln">1404 </span></a>  <span class="s3">/// storage / storage_offset) of a variable created from `var.variable_data()`, those</span>
<a name="l1405"><span class="ln">1405 </span></a>  <span class="s3">/// changes will not update the original variable `var`. In `.variable_data()`, we set</span>
<a name="l1406"><span class="ln">1406 </span></a>  <span class="s3">/// `allow_tensor_metadata_change_` to false to make such changes explicitly illegal,</span>
<a name="l1407"><span class="ln">1407 </span></a>  <span class="s3">/// in order to prevent users from changing metadata of `var.variable_data()`</span>
<a name="l1408"><span class="ln">1408 </span></a>  <span class="s3">/// and expecting the original variable `var` to also be updated.</span>
<a name="l1409"><span class="ln">1409 </span></a>  <span class="s0">at::Tensor variable_data() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1410"><span class="ln">1410 </span></a>    <span class="s1">return </span><span class="s0">TensorBase::variable_data();</span>
<a name="l1411"><span class="ln">1411 </span></a>  <span class="s0">}</span>
<a name="l1412"><span class="ln">1412 </span></a>
<a name="l1413"><span class="ln">1413 </span></a>  <span class="s3">// Hooks</span>
<a name="l1414"><span class="ln">1414 </span></a>  <span class="s3">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<a name="l1415"><span class="ln">1415 </span></a>
<a name="l1416"><span class="ln">1416 </span></a>  <span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">T&gt;</span>
<a name="l1417"><span class="ln">1417 </span></a>  <span class="s2">using </span><span class="s0">hook_return_void_t = std::enable_if_t&lt;std::is_void&lt;</span><span class="s2">typename </span><span class="s0">std::invoke_result_t&lt;T&amp;, Tensor&gt;&gt;::value, </span><span class="s1">unsigned</span><span class="s0">&gt;;</span>
<a name="l1418"><span class="ln">1418 </span></a>  <span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">T&gt;</span>
<a name="l1419"><span class="ln">1419 </span></a>  <span class="s2">using </span><span class="s0">hook_return_var_t = std::enable_if_t&lt;std::is_same_v&lt;</span><span class="s2">typename </span><span class="s0">std::invoke_result_t&lt;T&amp;, Tensor&gt;, Tensor&gt;, </span><span class="s1">unsigned</span><span class="s0">&gt;;</span>
<a name="l1420"><span class="ln">1420 </span></a>
<a name="l1421"><span class="ln">1421 </span></a>  <span class="s3">/// Registers a backward hook.</span>
<a name="l1422"><span class="ln">1422 </span></a>  <span class="s3">///</span>
<a name="l1423"><span class="ln">1423 </span></a>  <span class="s3">/// The hook will be called every time a gradient with respect to the Tensor is computed.</span>
<a name="l1424"><span class="ln">1424 </span></a>  <span class="s3">/// The hook should have one of the following signature:</span>
<a name="l1425"><span class="ln">1425 </span></a>  <span class="s3">/// ```</span>
<a name="l1426"><span class="ln">1426 </span></a>  <span class="s3">/// hook(Tensor grad) -&gt; Tensor</span>
<a name="l1427"><span class="ln">1427 </span></a>  <span class="s3">/// ```</span>
<a name="l1428"><span class="ln">1428 </span></a>  <span class="s3">/// ```</span>
<a name="l1429"><span class="ln">1429 </span></a>  <span class="s3">/// hook(Tensor grad) -&gt; void</span>
<a name="l1430"><span class="ln">1430 </span></a>  <span class="s3">/// ```</span>
<a name="l1431"><span class="ln">1431 </span></a>  <span class="s3">/// The hook should not modify its argument, but it can optionally return a new gradient</span>
<a name="l1432"><span class="ln">1432 </span></a>  <span class="s3">/// which will be used in place of `grad`.</span>
<a name="l1433"><span class="ln">1433 </span></a>  <span class="s3">///</span>
<a name="l1434"><span class="ln">1434 </span></a>  <span class="s3">/// This function returns the index of the hook in the list which can be used to remove hook.</span>
<a name="l1435"><span class="ln">1435 </span></a>  <span class="s3">///</span>
<a name="l1436"><span class="ln">1436 </span></a>  <span class="s3">/// Example:</span>
<a name="l1437"><span class="ln">1437 </span></a>  <span class="s3">/// @code</span>
<a name="l1438"><span class="ln">1438 </span></a>  <span class="s3">/// auto v = torch::tensor({0., 0., 0.}, torch::requires_grad());</span>
<a name="l1439"><span class="ln">1439 </span></a>  <span class="s3">/// auto h = v.register_hook([](torch::Tensor grad){ return grad * 2; }); // double the gradient</span>
<a name="l1440"><span class="ln">1440 </span></a>  <span class="s3">/// v.backward(torch::tensor({1., 2., 3.}));</span>
<a name="l1441"><span class="ln">1441 </span></a>  <span class="s3">/// // This prints:</span>
<a name="l1442"><span class="ln">1442 </span></a>  <span class="s3">/// // ```</span>
<a name="l1443"><span class="ln">1443 </span></a>  <span class="s3">/// //  2</span>
<a name="l1444"><span class="ln">1444 </span></a>  <span class="s3">/// //  4</span>
<a name="l1445"><span class="ln">1445 </span></a>  <span class="s3">/// //  6</span>
<a name="l1446"><span class="ln">1446 </span></a>  <span class="s3">/// // [ CPUFloatType{3} ]</span>
<a name="l1447"><span class="ln">1447 </span></a>  <span class="s3">/// // ```</span>
<a name="l1448"><span class="ln">1448 </span></a>  <span class="s3">/// std::cout &lt;&lt; v.grad() &lt;&lt; std::endl;</span>
<a name="l1449"><span class="ln">1449 </span></a>  <span class="s3">/// v.remove_hook(h);  // removes the hook</span>
<a name="l1450"><span class="ln">1450 </span></a>  <span class="s3">/// @endcode</span>
<a name="l1451"><span class="ln">1451 </span></a>  <span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">T&gt;</span>
<a name="l1452"><span class="ln">1452 </span></a>  <span class="s0">hook_return_void_t&lt;T&gt; register_hook(T&amp;&amp; hook) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1453"><span class="ln">1453 </span></a>  <span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">T&gt;</span>
<a name="l1454"><span class="ln">1454 </span></a>  <span class="s0">hook_return_var_t&lt;T&gt; register_hook(T&amp;&amp; hook) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1455"><span class="ln">1455 </span></a>
<a name="l1456"><span class="ln">1456 </span></a>  <span class="s3">// Variable methods</span>
<a name="l1457"><span class="ln">1457 </span></a>  <span class="s3">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<a name="l1458"><span class="ln">1458 </span></a>
<a name="l1459"><span class="ln">1459 </span></a>  <span class="s0">Tensor data() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1460"><span class="ln">1460 </span></a>    <span class="s1">return </span><span class="s0">TensorBase::data();</span>
<a name="l1461"><span class="ln">1461 </span></a>  <span class="s0">}</span>
<a name="l1462"><span class="ln">1462 </span></a>
<a name="l1463"><span class="ln">1463 </span></a>  <span class="s1">void </span><span class="s0">_backward(TensorList inputs, </span><span class="s1">const </span><span class="s0">std::optional&lt;Tensor&gt;&amp; gradient, std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; keep_graph, </span><span class="s1">bool </span><span class="s0">create_graph) </span><span class="s1">const</span><span class="s0">;</span>
<a name="l1464"><span class="ln">1464 </span></a>
<a name="l1465"><span class="ln">1465 </span></a>  <span class="s1">const </span><span class="s0">Tensor&amp; requires_grad_(</span><span class="s1">bool </span><span class="s0">_requires_grad=</span><span class="s2">true</span><span class="s0">) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1466"><span class="ln">1466 </span></a>    <span class="s0">TensorBase::requires_grad_(_requires_grad);</span>
<a name="l1467"><span class="ln">1467 </span></a>    <span class="s1">return </span><span class="s0">*</span><span class="s2">this</span><span class="s0">;</span>
<a name="l1468"><span class="ln">1468 </span></a>  <span class="s0">}</span>
<a name="l1469"><span class="ln">1469 </span></a><span class="s0">};</span>
<a name="l1470"><span class="ln">1470 </span></a>
<a name="l1471"><span class="ln">1471 </span></a><span class="s2">namespace </span><span class="s0">detail {</span>
<a name="l1472"><span class="ln">1472 </span></a><span class="s3">// Helper creator for Tensor class which doesn't requires the users to pass</span>
<a name="l1473"><span class="ln">1473 </span></a><span class="s3">// in an intrusive_ptr instead it just converts the argument passed to</span>
<a name="l1474"><span class="ln">1474 </span></a><span class="s3">// requested intrusive_ptr type.</span>
<a name="l1475"><span class="ln">1475 </span></a><span class="s0">template &lt;</span><span class="s2">typename </span><span class="s0">T, </span><span class="s2">typename</span><span class="s0">... Args&gt;</span>
<a name="l1476"><span class="ln">1476 </span></a><span class="s0">Tensor make_tensor(Args&amp;&amp;... args) {</span>
<a name="l1477"><span class="ln">1477 </span></a>  <span class="s1">return </span><span class="s0">Tensor(c10::make_intrusive&lt;T&gt;(std::forward&lt;Args&gt;(args)...));</span>
<a name="l1478"><span class="ln">1478 </span></a><span class="s0">}</span>
<a name="l1479"><span class="ln">1479 </span></a>
<a name="l1480"><span class="ln">1480 </span></a><span class="s0">} </span><span class="s3">// namespace detail</span>
<a name="l1481"><span class="ln">1481 </span></a>
<a name="l1482"><span class="ln">1482 </span></a><span class="s0">} </span><span class="s3">// namespace at</span>
<a name="l1483"><span class="ln">1483 </span></a>
<a name="l1484"><span class="ln">1484 </span></a>
<a name="l1485"><span class="ln">1485 </span></a><span class="s2">namespace </span><span class="s0">at {</span>
<a name="l1486"><span class="ln">1486 </span></a>
<a name="l1487"><span class="ln">1487 </span></a><span class="s3">// aten::_backward(Tensor self, Tensor[] inputs, Tensor? gradient=None, bool? retain_graph=None, bool create_graph=False) -&gt; ()</span>
<a name="l1488"><span class="ln">1488 </span></a><span class="s2">inline </span><span class="s1">void </span><span class="s0">Tensor::__dispatch__backward(at::TensorList inputs, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; gradient, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; retain_graph, </span><span class="s1">bool </span><span class="s0">create_graph) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1489"><span class="ln">1489 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_backward::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), inputs, gradient, retain_graph, create_graph);</span>
<a name="l1490"><span class="ln">1490 </span></a><span class="s0">}</span>
<a name="l1491"><span class="ln">1491 </span></a>
<a name="l1492"><span class="ln">1492 </span></a><span class="s3">// aten::set_data(Tensor(a!) self, Tensor new_data) -&gt; ()</span>
<a name="l1493"><span class="ln">1493 </span></a><span class="s2">inline </span><span class="s1">void </span><span class="s0">Tensor::__dispatch_set_data(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; new_data) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1494"><span class="ln">1494 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set_data::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), new_data);</span>
<a name="l1495"><span class="ln">1495 </span></a><span class="s0">}</span>
<a name="l1496"><span class="ln">1496 </span></a>
<a name="l1497"><span class="ln">1497 </span></a><span class="s3">// aten::data(Tensor self) -&gt; Tensor</span>
<a name="l1498"><span class="ln">1498 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__dispatch_data() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1499"><span class="ln">1499 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::data::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1500"><span class="ln">1500 </span></a><span class="s0">}</span>
<a name="l1501"><span class="ln">1501 </span></a>
<a name="l1502"><span class="ln">1502 </span></a><span class="s3">// aten::is_leaf(Tensor self) -&gt; bool</span>
<a name="l1503"><span class="ln">1503 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_leaf() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1504"><span class="ln">1504 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_leaf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1505"><span class="ln">1505 </span></a><span class="s0">}</span>
<a name="l1506"><span class="ln">1506 </span></a>
<a name="l1507"><span class="ln">1507 </span></a><span class="s3">// aten::output_nr(Tensor self) -&gt; int</span>
<a name="l1508"><span class="ln">1508 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::__dispatch_output_nr() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1509"><span class="ln">1509 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::output_nr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1510"><span class="ln">1510 </span></a><span class="s0">}</span>
<a name="l1511"><span class="ln">1511 </span></a>
<a name="l1512"><span class="ln">1512 </span></a><span class="s3">// aten::_version(Tensor self) -&gt; int</span>
<a name="l1513"><span class="ln">1513 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::__dispatch__version() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1514"><span class="ln">1514 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_version::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1515"><span class="ln">1515 </span></a><span class="s0">}</span>
<a name="l1516"><span class="ln">1516 </span></a>
<a name="l1517"><span class="ln">1517 </span></a><span class="s3">// aten::requires_grad_(Tensor(a!) self, bool requires_grad=True) -&gt; Tensor(a!)</span>
<a name="l1518"><span class="ln">1518 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__dispatch_requires_grad_(</span><span class="s1">bool </span><span class="s0">requires_grad) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1519"><span class="ln">1519 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::requires_grad_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), requires_grad);</span>
<a name="l1520"><span class="ln">1520 </span></a><span class="s0">}</span>
<a name="l1521"><span class="ln">1521 </span></a>
<a name="l1522"><span class="ln">1522 </span></a><span class="s3">// aten::retain_grad(Tensor(a!) self) -&gt; ()</span>
<a name="l1523"><span class="ln">1523 </span></a><span class="s2">inline </span><span class="s1">void </span><span class="s0">Tensor::__dispatch_retain_grad() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1524"><span class="ln">1524 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::retain_grad::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1525"><span class="ln">1525 </span></a><span class="s0">}</span>
<a name="l1526"><span class="ln">1526 </span></a>
<a name="l1527"><span class="ln">1527 </span></a><span class="s3">// aten::retains_grad(Tensor self) -&gt; bool</span>
<a name="l1528"><span class="ln">1528 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_retains_grad() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1529"><span class="ln">1529 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::retains_grad::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1530"><span class="ln">1530 </span></a><span class="s0">}</span>
<a name="l1531"><span class="ln">1531 </span></a>
<a name="l1532"><span class="ln">1532 </span></a><span class="s3">// aten::_fw_primal(Tensor(a) self, int level) -&gt; Tensor(a)</span>
<a name="l1533"><span class="ln">1533 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_fw_primal(int64_t level) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1534"><span class="ln">1534 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_fw_primal::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), level);</span>
<a name="l1535"><span class="ln">1535 </span></a><span class="s0">}</span>
<a name="l1536"><span class="ln">1536 </span></a>
<a name="l1537"><span class="ln">1537 </span></a><span class="s3">// aten::rename_(Tensor(a!) self, Dimname[]? names) -&gt; Tensor(a!)</span>
<a name="l1538"><span class="ln">1538 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::rename_(::std::optional&lt;at::DimnameList&gt; names) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1539"><span class="ln">1539 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rename_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), names);</span>
<a name="l1540"><span class="ln">1540 </span></a><span class="s0">}</span>
<a name="l1541"><span class="ln">1541 </span></a>
<a name="l1542"><span class="ln">1542 </span></a><span class="s3">// aten::rename(Tensor(a) self, Dimname[]? names) -&gt; Tensor(a)</span>
<a name="l1543"><span class="ln">1543 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::rename(::std::optional&lt;at::DimnameList&gt; names) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1544"><span class="ln">1544 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rename::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), names);</span>
<a name="l1545"><span class="ln">1545 </span></a><span class="s0">}</span>
<a name="l1546"><span class="ln">1546 </span></a>
<a name="l1547"><span class="ln">1547 </span></a><span class="s3">// aten::align_to(Tensor(a) self, Dimname[] names) -&gt; Tensor(a)</span>
<a name="l1548"><span class="ln">1548 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::align_to(at::DimnameList names) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1549"><span class="ln">1549 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::align_to::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), names);</span>
<a name="l1550"><span class="ln">1550 </span></a><span class="s0">}</span>
<a name="l1551"><span class="ln">1551 </span></a>
<a name="l1552"><span class="ln">1552 </span></a><span class="s3">// aten::align_to.ellipsis_idx(Tensor(a) self, Dimname[] order, int ellipsis_idx) -&gt; Tensor(a)</span>
<a name="l1553"><span class="ln">1553 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::align_to(at::DimnameList order, int64_t ellipsis_idx) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1554"><span class="ln">1554 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::align_to_ellipsis_idx::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), order, ellipsis_idx);</span>
<a name="l1555"><span class="ln">1555 </span></a><span class="s0">}</span>
<a name="l1556"><span class="ln">1556 </span></a>
<a name="l1557"><span class="ln">1557 </span></a><span class="s3">// aten::align_as(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l1558"><span class="ln">1558 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::align_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1559"><span class="ln">1559 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::align_as::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1560"><span class="ln">1560 </span></a><span class="s0">}</span>
<a name="l1561"><span class="ln">1561 </span></a>
<a name="l1562"><span class="ln">1562 </span></a><span class="s3">// aten::refine_names(Tensor(a) self, Dimname[] names) -&gt; Tensor(a)</span>
<a name="l1563"><span class="ln">1563 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::refine_names(at::DimnameList names) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1564"><span class="ln">1564 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::refine_names::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), names);</span>
<a name="l1565"><span class="ln">1565 </span></a><span class="s0">}</span>
<a name="l1566"><span class="ln">1566 </span></a>
<a name="l1567"><span class="ln">1567 </span></a><span class="s3">// aten::abs(Tensor self) -&gt; Tensor</span>
<a name="l1568"><span class="ln">1568 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::abs() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1569"><span class="ln">1569 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::abs::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1570"><span class="ln">1570 </span></a><span class="s0">}</span>
<a name="l1571"><span class="ln">1571 </span></a>
<a name="l1572"><span class="ln">1572 </span></a><span class="s3">// aten::abs_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1573"><span class="ln">1573 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::abs_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1574"><span class="ln">1574 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::abs_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1575"><span class="ln">1575 </span></a><span class="s0">}</span>
<a name="l1576"><span class="ln">1576 </span></a>
<a name="l1577"><span class="ln">1577 </span></a><span class="s3">// aten::absolute(Tensor self) -&gt; Tensor</span>
<a name="l1578"><span class="ln">1578 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::absolute() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1579"><span class="ln">1579 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::absolute::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1580"><span class="ln">1580 </span></a><span class="s0">}</span>
<a name="l1581"><span class="ln">1581 </span></a>
<a name="l1582"><span class="ln">1582 </span></a><span class="s3">// aten::absolute_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1583"><span class="ln">1583 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::absolute_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1584"><span class="ln">1584 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::absolute_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1585"><span class="ln">1585 </span></a><span class="s0">}</span>
<a name="l1586"><span class="ln">1586 </span></a>
<a name="l1587"><span class="ln">1587 </span></a><span class="s3">// aten::angle(Tensor self) -&gt; Tensor</span>
<a name="l1588"><span class="ln">1588 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::angle() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1589"><span class="ln">1589 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::angle::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1590"><span class="ln">1590 </span></a><span class="s0">}</span>
<a name="l1591"><span class="ln">1591 </span></a>
<a name="l1592"><span class="ln">1592 </span></a><span class="s3">// aten::sgn(Tensor self) -&gt; Tensor</span>
<a name="l1593"><span class="ln">1593 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sgn() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1594"><span class="ln">1594 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sgn::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1595"><span class="ln">1595 </span></a><span class="s0">}</span>
<a name="l1596"><span class="ln">1596 </span></a>
<a name="l1597"><span class="ln">1597 </span></a><span class="s3">// aten::sgn_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1598"><span class="ln">1598 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sgn_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1599"><span class="ln">1599 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sgn_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1600"><span class="ln">1600 </span></a><span class="s0">}</span>
<a name="l1601"><span class="ln">1601 </span></a>
<a name="l1602"><span class="ln">1602 </span></a><span class="s3">// aten::chalf(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<a name="l1603"><span class="ln">1603 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::chalf(::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1604"><span class="ln">1604 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::chalf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), memory_format);</span>
<a name="l1605"><span class="ln">1605 </span></a><span class="s0">}</span>
<a name="l1606"><span class="ln">1606 </span></a>
<a name="l1607"><span class="ln">1607 </span></a><span class="s3">// aten::_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l1608"><span class="ln">1608 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_conj() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1609"><span class="ln">1609 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_conj::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1610"><span class="ln">1610 </span></a><span class="s0">}</span>
<a name="l1611"><span class="ln">1611 </span></a>
<a name="l1612"><span class="ln">1612 </span></a><span class="s3">// aten::conj(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l1613"><span class="ln">1613 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__dispatch_conj() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1614"><span class="ln">1614 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::conj::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1615"><span class="ln">1615 </span></a><span class="s0">}</span>
<a name="l1616"><span class="ln">1616 </span></a>
<a name="l1617"><span class="ln">1617 </span></a><span class="s3">// aten::_conj_physical(Tensor self) -&gt; Tensor</span>
<a name="l1618"><span class="ln">1618 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_conj_physical() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1619"><span class="ln">1619 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_conj_physical::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1620"><span class="ln">1620 </span></a><span class="s0">}</span>
<a name="l1621"><span class="ln">1621 </span></a>
<a name="l1622"><span class="ln">1622 </span></a><span class="s3">// aten::conj_physical(Tensor self) -&gt; Tensor</span>
<a name="l1623"><span class="ln">1623 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::conj_physical() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1624"><span class="ln">1624 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::conj_physical::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1625"><span class="ln">1625 </span></a><span class="s0">}</span>
<a name="l1626"><span class="ln">1626 </span></a>
<a name="l1627"><span class="ln">1627 </span></a><span class="s3">// aten::conj_physical_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1628"><span class="ln">1628 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::conj_physical_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1629"><span class="ln">1629 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::conj_physical_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1630"><span class="ln">1630 </span></a><span class="s0">}</span>
<a name="l1631"><span class="ln">1631 </span></a>
<a name="l1632"><span class="ln">1632 </span></a><span class="s3">// aten::resolve_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l1633"><span class="ln">1633 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::resolve_conj() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1634"><span class="ln">1634 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::resolve_conj::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1635"><span class="ln">1635 </span></a><span class="s0">}</span>
<a name="l1636"><span class="ln">1636 </span></a>
<a name="l1637"><span class="ln">1637 </span></a><span class="s3">// aten::resolve_neg(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l1638"><span class="ln">1638 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::resolve_neg() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1639"><span class="ln">1639 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::resolve_neg::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1640"><span class="ln">1640 </span></a><span class="s0">}</span>
<a name="l1641"><span class="ln">1641 </span></a>
<a name="l1642"><span class="ln">1642 </span></a><span class="s3">// aten::_neg_view(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l1643"><span class="ln">1643 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_neg_view() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1644"><span class="ln">1644 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_neg_view::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1645"><span class="ln">1645 </span></a><span class="s0">}</span>
<a name="l1646"><span class="ln">1646 </span></a>
<a name="l1647"><span class="ln">1647 </span></a><span class="s3">// aten::acos(Tensor self) -&gt; Tensor</span>
<a name="l1648"><span class="ln">1648 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::acos() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1649"><span class="ln">1649 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::acos::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1650"><span class="ln">1650 </span></a><span class="s0">}</span>
<a name="l1651"><span class="ln">1651 </span></a>
<a name="l1652"><span class="ln">1652 </span></a><span class="s3">// aten::acos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1653"><span class="ln">1653 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::acos_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1654"><span class="ln">1654 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::acos_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1655"><span class="ln">1655 </span></a><span class="s0">}</span>
<a name="l1656"><span class="ln">1656 </span></a>
<a name="l1657"><span class="ln">1657 </span></a><span class="s3">// aten::arccos(Tensor self) -&gt; Tensor</span>
<a name="l1658"><span class="ln">1658 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arccos() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1659"><span class="ln">1659 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arccos::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1660"><span class="ln">1660 </span></a><span class="s0">}</span>
<a name="l1661"><span class="ln">1661 </span></a>
<a name="l1662"><span class="ln">1662 </span></a><span class="s3">// aten::arccos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1663"><span class="ln">1663 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arccos_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1664"><span class="ln">1664 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arccos_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1665"><span class="ln">1665 </span></a><span class="s0">}</span>
<a name="l1666"><span class="ln">1666 </span></a>
<a name="l1667"><span class="ln">1667 </span></a><span class="s3">// aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<a name="l1668"><span class="ln">1668 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::add(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1669"><span class="ln">1669 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::add_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l1670"><span class="ln">1670 </span></a><span class="s0">}</span>
<a name="l1671"><span class="ln">1671 </span></a>
<a name="l1672"><span class="ln">1672 </span></a><span class="s3">// aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l1673"><span class="ln">1673 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::add_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1674"><span class="ln">1674 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::add__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l1675"><span class="ln">1675 </span></a><span class="s0">}</span>
<a name="l1676"><span class="ln">1676 </span></a>
<a name="l1677"><span class="ln">1677 </span></a><span class="s3">// aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<a name="l1678"><span class="ln">1678 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::add(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1679"><span class="ln">1679 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::add_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l1680"><span class="ln">1680 </span></a><span class="s0">}</span>
<a name="l1681"><span class="ln">1681 </span></a>
<a name="l1682"><span class="ln">1682 </span></a><span class="s3">// aten::add_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l1683"><span class="ln">1683 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::add_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1684"><span class="ln">1684 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::add__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l1685"><span class="ln">1685 </span></a><span class="s0">}</span>
<a name="l1686"><span class="ln">1686 </span></a>
<a name="l1687"><span class="ln">1687 </span></a><span class="s3">// aten::addmv(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<a name="l1688"><span class="ln">1688 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::addmv(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1689"><span class="ln">1689 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addmv::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat, vec, beta, alpha);</span>
<a name="l1690"><span class="ln">1690 </span></a><span class="s0">}</span>
<a name="l1691"><span class="ln">1691 </span></a>
<a name="l1692"><span class="ln">1692 </span></a><span class="s3">// aten::addmv_(Tensor(a!) self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l1693"><span class="ln">1693 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::addmv_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1694"><span class="ln">1694 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addmv_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat, vec, beta, alpha);</span>
<a name="l1695"><span class="ln">1695 </span></a><span class="s0">}</span>
<a name="l1696"><span class="ln">1696 </span></a>
<a name="l1697"><span class="ln">1697 </span></a><span class="s3">// aten::addr(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<a name="l1698"><span class="ln">1698 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::addr(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1699"><span class="ln">1699 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), vec1, vec2, beta, alpha);</span>
<a name="l1700"><span class="ln">1700 </span></a><span class="s0">}</span>
<a name="l1701"><span class="ln">1701 </span></a>
<a name="l1702"><span class="ln">1702 </span></a><span class="s3">// aten::addr_(Tensor(a!) self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l1703"><span class="ln">1703 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::addr_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1704"><span class="ln">1704 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addr_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), vec1, vec2, beta, alpha);</span>
<a name="l1705"><span class="ln">1705 </span></a><span class="s0">}</span>
<a name="l1706"><span class="ln">1706 </span></a>
<a name="l1707"><span class="ln">1707 </span></a><span class="s3">// aten::_is_all_true(Tensor self) -&gt; Tensor</span>
<a name="l1708"><span class="ln">1708 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_is_all_true() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1709"><span class="ln">1709 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_is_all_true::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1710"><span class="ln">1710 </span></a><span class="s0">}</span>
<a name="l1711"><span class="ln">1711 </span></a>
<a name="l1712"><span class="ln">1712 </span></a><span class="s3">// aten::_is_any_true(Tensor self) -&gt; Tensor</span>
<a name="l1713"><span class="ln">1713 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_is_any_true() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1714"><span class="ln">1714 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_is_any_true::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1715"><span class="ln">1715 </span></a><span class="s0">}</span>
<a name="l1716"><span class="ln">1716 </span></a>
<a name="l1717"><span class="ln">1717 </span></a><span class="s3">// aten::all.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l1718"><span class="ln">1718 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::all(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1719"><span class="ln">1719 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::all_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1720"><span class="ln">1720 </span></a><span class="s0">}</span>
<a name="l1721"><span class="ln">1721 </span></a>
<a name="l1722"><span class="ln">1722 </span></a><span class="s3">// aten::all.dims(Tensor self, int[]? dim=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l1723"><span class="ln">1723 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::all(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1724"><span class="ln">1724 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::all_dims::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1725"><span class="ln">1725 </span></a><span class="s0">}</span>
<a name="l1726"><span class="ln">1726 </span></a>
<a name="l1727"><span class="ln">1727 </span></a><span class="s3">// aten::all.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l1728"><span class="ln">1728 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::all(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1729"><span class="ln">1729 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::all_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1730"><span class="ln">1730 </span></a><span class="s0">}</span>
<a name="l1731"><span class="ln">1731 </span></a>
<a name="l1732"><span class="ln">1732 </span></a><span class="s3">// aten::allclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; bool</span>
<a name="l1733"><span class="ln">1733 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::allclose(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">double </span><span class="s0">rtol, </span><span class="s1">double </span><span class="s0">atol, </span><span class="s1">bool </span><span class="s0">equal_nan) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1734"><span class="ln">1734 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::allclose::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rtol, atol, equal_nan);</span>
<a name="l1735"><span class="ln">1735 </span></a><span class="s0">}</span>
<a name="l1736"><span class="ln">1736 </span></a>
<a name="l1737"><span class="ln">1737 </span></a><span class="s3">// aten::any.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l1738"><span class="ln">1738 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::any(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1739"><span class="ln">1739 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::any_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1740"><span class="ln">1740 </span></a><span class="s0">}</span>
<a name="l1741"><span class="ln">1741 </span></a>
<a name="l1742"><span class="ln">1742 </span></a><span class="s3">// aten::any.dims(Tensor self, int[]? dim=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l1743"><span class="ln">1743 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::any(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1744"><span class="ln">1744 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::any_dims::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1745"><span class="ln">1745 </span></a><span class="s0">}</span>
<a name="l1746"><span class="ln">1746 </span></a>
<a name="l1747"><span class="ln">1747 </span></a><span class="s3">// aten::any.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l1748"><span class="ln">1748 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::any(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1749"><span class="ln">1749 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::any_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1750"><span class="ln">1750 </span></a><span class="s0">}</span>
<a name="l1751"><span class="ln">1751 </span></a>
<a name="l1752"><span class="ln">1752 </span></a><span class="s3">// aten::argmax(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l1753"><span class="ln">1753 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::argmax(::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1754"><span class="ln">1754 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::argmax::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1755"><span class="ln">1755 </span></a><span class="s0">}</span>
<a name="l1756"><span class="ln">1756 </span></a>
<a name="l1757"><span class="ln">1757 </span></a><span class="s3">// aten::argmin(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l1758"><span class="ln">1758 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::argmin(::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1759"><span class="ln">1759 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::argmin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l1760"><span class="ln">1760 </span></a><span class="s0">}</span>
<a name="l1761"><span class="ln">1761 </span></a>
<a name="l1762"><span class="ln">1762 </span></a><span class="s3">// aten::acosh(Tensor self) -&gt; Tensor</span>
<a name="l1763"><span class="ln">1763 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::acosh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1764"><span class="ln">1764 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::acosh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1765"><span class="ln">1765 </span></a><span class="s0">}</span>
<a name="l1766"><span class="ln">1766 </span></a>
<a name="l1767"><span class="ln">1767 </span></a><span class="s3">// aten::acosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1768"><span class="ln">1768 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::acosh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1769"><span class="ln">1769 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::acosh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1770"><span class="ln">1770 </span></a><span class="s0">}</span>
<a name="l1771"><span class="ln">1771 </span></a>
<a name="l1772"><span class="ln">1772 </span></a><span class="s3">// aten::arccosh(Tensor self) -&gt; Tensor</span>
<a name="l1773"><span class="ln">1773 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arccosh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1774"><span class="ln">1774 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arccosh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1775"><span class="ln">1775 </span></a><span class="s0">}</span>
<a name="l1776"><span class="ln">1776 </span></a>
<a name="l1777"><span class="ln">1777 </span></a><span class="s3">// aten::arccosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1778"><span class="ln">1778 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arccosh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1779"><span class="ln">1779 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arccosh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1780"><span class="ln">1780 </span></a><span class="s0">}</span>
<a name="l1781"><span class="ln">1781 </span></a>
<a name="l1782"><span class="ln">1782 </span></a><span class="s3">// aten::asinh(Tensor self) -&gt; Tensor</span>
<a name="l1783"><span class="ln">1783 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::asinh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1784"><span class="ln">1784 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::asinh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1785"><span class="ln">1785 </span></a><span class="s0">}</span>
<a name="l1786"><span class="ln">1786 </span></a>
<a name="l1787"><span class="ln">1787 </span></a><span class="s3">// aten::asinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1788"><span class="ln">1788 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::asinh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1789"><span class="ln">1789 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::asinh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1790"><span class="ln">1790 </span></a><span class="s0">}</span>
<a name="l1791"><span class="ln">1791 </span></a>
<a name="l1792"><span class="ln">1792 </span></a><span class="s3">// aten::arcsinh(Tensor self) -&gt; Tensor</span>
<a name="l1793"><span class="ln">1793 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arcsinh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1794"><span class="ln">1794 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arcsinh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1795"><span class="ln">1795 </span></a><span class="s0">}</span>
<a name="l1796"><span class="ln">1796 </span></a>
<a name="l1797"><span class="ln">1797 </span></a><span class="s3">// aten::arcsinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1798"><span class="ln">1798 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arcsinh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1799"><span class="ln">1799 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arcsinh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1800"><span class="ln">1800 </span></a><span class="s0">}</span>
<a name="l1801"><span class="ln">1801 </span></a>
<a name="l1802"><span class="ln">1802 </span></a><span class="s3">// aten::atanh(Tensor self) -&gt; Tensor</span>
<a name="l1803"><span class="ln">1803 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::atanh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1804"><span class="ln">1804 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::atanh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1805"><span class="ln">1805 </span></a><span class="s0">}</span>
<a name="l1806"><span class="ln">1806 </span></a>
<a name="l1807"><span class="ln">1807 </span></a><span class="s3">// aten::atanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1808"><span class="ln">1808 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::atanh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1809"><span class="ln">1809 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::atanh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1810"><span class="ln">1810 </span></a><span class="s0">}</span>
<a name="l1811"><span class="ln">1811 </span></a>
<a name="l1812"><span class="ln">1812 </span></a><span class="s3">// aten::arctanh(Tensor self) -&gt; Tensor</span>
<a name="l1813"><span class="ln">1813 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arctanh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1814"><span class="ln">1814 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arctanh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1815"><span class="ln">1815 </span></a><span class="s0">}</span>
<a name="l1816"><span class="ln">1816 </span></a>
<a name="l1817"><span class="ln">1817 </span></a><span class="s3">// aten::arctanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1818"><span class="ln">1818 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arctanh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1819"><span class="ln">1819 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arctanh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1820"><span class="ln">1820 </span></a><span class="s0">}</span>
<a name="l1821"><span class="ln">1821 </span></a>
<a name="l1822"><span class="ln">1822 </span></a><span class="s3">// aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a)</span>
<a name="l1823"><span class="ln">1823 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::as_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1824"><span class="ln">1824 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::as_strided::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt);</span>
<a name="l1825"><span class="ln">1825 </span></a><span class="s0">}</span>
<a name="l1826"><span class="ln">1826 </span></a>
<a name="l1827"><span class="ln">1827 </span></a><span class="s3">// aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a)</span>
<a name="l1828"><span class="ln">1828 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::as_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1829"><span class="ln">1829 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::as_strided::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, stride, storage_offset);</span>
<a name="l1830"><span class="ln">1830 </span></a><span class="s0">}</span>
<a name="l1831"><span class="ln">1831 </span></a>
<a name="l1832"><span class="ln">1832 </span></a><span class="s3">// aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a!)</span>
<a name="l1833"><span class="ln">1833 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::as_strided_(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1834"><span class="ln">1834 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::as_strided_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt);</span>
<a name="l1835"><span class="ln">1835 </span></a><span class="s0">}</span>
<a name="l1836"><span class="ln">1836 </span></a>
<a name="l1837"><span class="ln">1837 </span></a><span class="s3">// aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a!)</span>
<a name="l1838"><span class="ln">1838 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::as_strided__symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1839"><span class="ln">1839 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::as_strided_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, stride, storage_offset);</span>
<a name="l1840"><span class="ln">1840 </span></a><span class="s0">}</span>
<a name="l1841"><span class="ln">1841 </span></a>
<a name="l1842"><span class="ln">1842 </span></a><span class="s3">// aten::asin(Tensor self) -&gt; Tensor</span>
<a name="l1843"><span class="ln">1843 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::asin() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1844"><span class="ln">1844 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::asin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1845"><span class="ln">1845 </span></a><span class="s0">}</span>
<a name="l1846"><span class="ln">1846 </span></a>
<a name="l1847"><span class="ln">1847 </span></a><span class="s3">// aten::asin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1848"><span class="ln">1848 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::asin_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1849"><span class="ln">1849 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::asin_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1850"><span class="ln">1850 </span></a><span class="s0">}</span>
<a name="l1851"><span class="ln">1851 </span></a>
<a name="l1852"><span class="ln">1852 </span></a><span class="s3">// aten::arcsin(Tensor self) -&gt; Tensor</span>
<a name="l1853"><span class="ln">1853 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arcsin() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1854"><span class="ln">1854 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arcsin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1855"><span class="ln">1855 </span></a><span class="s0">}</span>
<a name="l1856"><span class="ln">1856 </span></a>
<a name="l1857"><span class="ln">1857 </span></a><span class="s3">// aten::arcsin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1858"><span class="ln">1858 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arcsin_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1859"><span class="ln">1859 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arcsin_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1860"><span class="ln">1860 </span></a><span class="s0">}</span>
<a name="l1861"><span class="ln">1861 </span></a>
<a name="l1862"><span class="ln">1862 </span></a><span class="s3">// aten::atan(Tensor self) -&gt; Tensor</span>
<a name="l1863"><span class="ln">1863 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::atan() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1864"><span class="ln">1864 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::atan::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1865"><span class="ln">1865 </span></a><span class="s0">}</span>
<a name="l1866"><span class="ln">1866 </span></a>
<a name="l1867"><span class="ln">1867 </span></a><span class="s3">// aten::atan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1868"><span class="ln">1868 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::atan_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1869"><span class="ln">1869 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::atan_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1870"><span class="ln">1870 </span></a><span class="s0">}</span>
<a name="l1871"><span class="ln">1871 </span></a>
<a name="l1872"><span class="ln">1872 </span></a><span class="s3">// aten::arctan(Tensor self) -&gt; Tensor</span>
<a name="l1873"><span class="ln">1873 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arctan() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1874"><span class="ln">1874 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arctan::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1875"><span class="ln">1875 </span></a><span class="s0">}</span>
<a name="l1876"><span class="ln">1876 </span></a>
<a name="l1877"><span class="ln">1877 </span></a><span class="s3">// aten::arctan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1878"><span class="ln">1878 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arctan_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1879"><span class="ln">1879 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arctan_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1880"><span class="ln">1880 </span></a><span class="s0">}</span>
<a name="l1881"><span class="ln">1881 </span></a>
<a name="l1882"><span class="ln">1882 </span></a><span class="s3">// aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<a name="l1883"><span class="ln">1883 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::baddbmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1884"><span class="ln">1884 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::baddbmm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), batch1, batch2, beta, alpha);</span>
<a name="l1885"><span class="ln">1885 </span></a><span class="s0">}</span>
<a name="l1886"><span class="ln">1886 </span></a>
<a name="l1887"><span class="ln">1887 </span></a><span class="s3">// aten::baddbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l1888"><span class="ln">1888 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::baddbmm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1889"><span class="ln">1889 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::baddbmm_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), batch1, batch2, beta, alpha);</span>
<a name="l1890"><span class="ln">1890 </span></a><span class="s0">}</span>
<a name="l1891"><span class="ln">1891 </span></a>
<a name="l1892"><span class="ln">1892 </span></a><span class="s3">// aten::bernoulli(Tensor self, *, Generator? generator=None) -&gt; Tensor</span>
<a name="l1893"><span class="ln">1893 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bernoulli(::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1894"><span class="ln">1894 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bernoulli::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), generator);</span>
<a name="l1895"><span class="ln">1895 </span></a><span class="s0">}</span>
<a name="l1896"><span class="ln">1896 </span></a>
<a name="l1897"><span class="ln">1897 </span></a><span class="s3">// aten::bernoulli_.Tensor(Tensor(a!) self, Tensor p, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l1898"><span class="ln">1898 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bernoulli_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; p, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1899"><span class="ln">1899 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bernoulli__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, generator);</span>
<a name="l1900"><span class="ln">1900 </span></a><span class="s0">}</span>
<a name="l1901"><span class="ln">1901 </span></a>
<a name="l1902"><span class="ln">1902 </span></a><span class="s3">// aten::bernoulli_.float(Tensor(a!) self, float p=0.5, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l1903"><span class="ln">1903 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bernoulli_(</span><span class="s1">double </span><span class="s0">p, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1904"><span class="ln">1904 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bernoulli__float::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, generator);</span>
<a name="l1905"><span class="ln">1905 </span></a><span class="s0">}</span>
<a name="l1906"><span class="ln">1906 </span></a>
<a name="l1907"><span class="ln">1907 </span></a><span class="s3">// aten::bernoulli.p(Tensor self, float p, *, Generator? generator=None) -&gt; Tensor</span>
<a name="l1908"><span class="ln">1908 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bernoulli(</span><span class="s1">double </span><span class="s0">p, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1909"><span class="ln">1909 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bernoulli_p::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, generator);</span>
<a name="l1910"><span class="ln">1910 </span></a><span class="s0">}</span>
<a name="l1911"><span class="ln">1911 </span></a>
<a name="l1912"><span class="ln">1912 </span></a><span class="s3">// aten::bincount(Tensor self, Tensor? weights=None, SymInt minlength=0) -&gt; Tensor</span>
<a name="l1913"><span class="ln">1913 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bincount(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weights, int64_t minlength) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1914"><span class="ln">1914 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bincount::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), weights, minlength);</span>
<a name="l1915"><span class="ln">1915 </span></a><span class="s0">}</span>
<a name="l1916"><span class="ln">1916 </span></a>
<a name="l1917"><span class="ln">1917 </span></a><span class="s3">// aten::bincount(Tensor self, Tensor? weights=None, SymInt minlength=0) -&gt; Tensor</span>
<a name="l1918"><span class="ln">1918 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bincount_symint(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weights, c10::SymInt minlength) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1919"><span class="ln">1919 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bincount::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), weights, minlength);</span>
<a name="l1920"><span class="ln">1920 </span></a><span class="s0">}</span>
<a name="l1921"><span class="ln">1921 </span></a>
<a name="l1922"><span class="ln">1922 </span></a><span class="s3">// aten::bitwise_not(Tensor self) -&gt; Tensor</span>
<a name="l1923"><span class="ln">1923 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_not() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1924"><span class="ln">1924 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_not::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1925"><span class="ln">1925 </span></a><span class="s0">}</span>
<a name="l1926"><span class="ln">1926 </span></a>
<a name="l1927"><span class="ln">1927 </span></a><span class="s3">// aten::bitwise_not_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1928"><span class="ln">1928 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_not_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1929"><span class="ln">1929 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_not_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1930"><span class="ln">1930 </span></a><span class="s0">}</span>
<a name="l1931"><span class="ln">1931 </span></a>
<a name="l1932"><span class="ln">1932 </span></a><span class="s3">// aten::copysign.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l1933"><span class="ln">1933 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::copysign(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1934"><span class="ln">1934 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::copysign_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1935"><span class="ln">1935 </span></a><span class="s0">}</span>
<a name="l1936"><span class="ln">1936 </span></a>
<a name="l1937"><span class="ln">1937 </span></a><span class="s3">// aten::copysign_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l1938"><span class="ln">1938 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::copysign_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1939"><span class="ln">1939 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::copysign__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1940"><span class="ln">1940 </span></a><span class="s0">}</span>
<a name="l1941"><span class="ln">1941 </span></a>
<a name="l1942"><span class="ln">1942 </span></a><span class="s3">// aten::copysign.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l1943"><span class="ln">1943 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::copysign(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1944"><span class="ln">1944 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::copysign_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1945"><span class="ln">1945 </span></a><span class="s0">}</span>
<a name="l1946"><span class="ln">1946 </span></a>
<a name="l1947"><span class="ln">1947 </span></a><span class="s3">// aten::copysign_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l1948"><span class="ln">1948 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::copysign_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1949"><span class="ln">1949 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::copysign__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1950"><span class="ln">1950 </span></a><span class="s0">}</span>
<a name="l1951"><span class="ln">1951 </span></a>
<a name="l1952"><span class="ln">1952 </span></a><span class="s3">// aten::_lazy_clone(Tensor self) -&gt; Tensor</span>
<a name="l1953"><span class="ln">1953 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_lazy_clone() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1954"><span class="ln">1954 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_lazy_clone::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1955"><span class="ln">1955 </span></a><span class="s0">}</span>
<a name="l1956"><span class="ln">1956 </span></a>
<a name="l1957"><span class="ln">1957 </span></a><span class="s3">// aten::logical_not(Tensor self) -&gt; Tensor</span>
<a name="l1958"><span class="ln">1958 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logical_not() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1959"><span class="ln">1959 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_not::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1960"><span class="ln">1960 </span></a><span class="s0">}</span>
<a name="l1961"><span class="ln">1961 </span></a>
<a name="l1962"><span class="ln">1962 </span></a><span class="s3">// aten::logical_not_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l1963"><span class="ln">1963 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::logical_not_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1964"><span class="ln">1964 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_not_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l1965"><span class="ln">1965 </span></a><span class="s0">}</span>
<a name="l1966"><span class="ln">1966 </span></a>
<a name="l1967"><span class="ln">1967 </span></a><span class="s3">// aten::logical_xor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l1968"><span class="ln">1968 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logical_xor(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1969"><span class="ln">1969 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_xor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1970"><span class="ln">1970 </span></a><span class="s0">}</span>
<a name="l1971"><span class="ln">1971 </span></a>
<a name="l1972"><span class="ln">1972 </span></a><span class="s3">// aten::logical_xor_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l1973"><span class="ln">1973 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::logical_xor_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1974"><span class="ln">1974 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_xor_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1975"><span class="ln">1975 </span></a><span class="s0">}</span>
<a name="l1976"><span class="ln">1976 </span></a>
<a name="l1977"><span class="ln">1977 </span></a><span class="s3">// aten::logical_and(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l1978"><span class="ln">1978 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logical_and(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1979"><span class="ln">1979 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_and::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1980"><span class="ln">1980 </span></a><span class="s0">}</span>
<a name="l1981"><span class="ln">1981 </span></a>
<a name="l1982"><span class="ln">1982 </span></a><span class="s3">// aten::logical_and_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l1983"><span class="ln">1983 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::logical_and_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1984"><span class="ln">1984 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_and_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1985"><span class="ln">1985 </span></a><span class="s0">}</span>
<a name="l1986"><span class="ln">1986 </span></a>
<a name="l1987"><span class="ln">1987 </span></a><span class="s3">// aten::logical_or(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l1988"><span class="ln">1988 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logical_or(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1989"><span class="ln">1989 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_or::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1990"><span class="ln">1990 </span></a><span class="s0">}</span>
<a name="l1991"><span class="ln">1991 </span></a>
<a name="l1992"><span class="ln">1992 </span></a><span class="s3">// aten::logical_or_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l1993"><span class="ln">1993 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::logical_or_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1994"><span class="ln">1994 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logical_or_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l1995"><span class="ln">1995 </span></a><span class="s0">}</span>
<a name="l1996"><span class="ln">1996 </span></a>
<a name="l1997"><span class="ln">1997 </span></a><span class="s3">// aten::bmm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<a name="l1998"><span class="ln">1998 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l1999"><span class="ln">1999 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bmm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat2);</span>
<a name="l2000"><span class="ln">2000 </span></a><span class="s0">}</span>
<a name="l2001"><span class="ln">2001 </span></a>
<a name="l2002"><span class="ln">2002 </span></a><span class="s3">// aten::broadcast_to(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<a name="l2003"><span class="ln">2003 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::broadcast_to(at::IntArrayRef size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2004"><span class="ln">2004 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::broadcast_to::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size));</span>
<a name="l2005"><span class="ln">2005 </span></a><span class="s0">}</span>
<a name="l2006"><span class="ln">2006 </span></a>
<a name="l2007"><span class="ln">2007 </span></a><span class="s3">// aten::broadcast_to(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<a name="l2008"><span class="ln">2008 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::broadcast_to_symint(c10::SymIntArrayRef size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2009"><span class="ln">2009 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::broadcast_to::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size);</span>
<a name="l2010"><span class="ln">2010 </span></a><span class="s0">}</span>
<a name="l2011"><span class="ln">2011 </span></a>
<a name="l2012"><span class="ln">2012 </span></a><span class="s3">// aten::ceil(Tensor self) -&gt; Tensor</span>
<a name="l2013"><span class="ln">2013 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ceil() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2014"><span class="ln">2014 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ceil::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2015"><span class="ln">2015 </span></a><span class="s0">}</span>
<a name="l2016"><span class="ln">2016 </span></a>
<a name="l2017"><span class="ln">2017 </span></a><span class="s3">// aten::ceil_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2018"><span class="ln">2018 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::ceil_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2019"><span class="ln">2019 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ceil_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2020"><span class="ln">2020 </span></a><span class="s0">}</span>
<a name="l2021"><span class="ln">2021 </span></a>
<a name="l2022"><span class="ln">2022 </span></a><span class="s3">// aten::unsafe_chunk(Tensor self, int chunks, int dim=0) -&gt; Tensor[]</span>
<a name="l2023"><span class="ln">2023 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unsafe_chunk(int64_t chunks, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2024"><span class="ln">2024 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsafe_chunk::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), chunks, dim);</span>
<a name="l2025"><span class="ln">2025 </span></a><span class="s0">}</span>
<a name="l2026"><span class="ln">2026 </span></a>
<a name="l2027"><span class="ln">2027 </span></a><span class="s3">// aten::chunk(Tensor(a -&gt; *) self, int chunks, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l2028"><span class="ln">2028 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::chunk(int64_t chunks, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2029"><span class="ln">2029 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::chunk::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), chunks, dim);</span>
<a name="l2030"><span class="ln">2030 </span></a><span class="s0">}</span>
<a name="l2031"><span class="ln">2031 </span></a>
<a name="l2032"><span class="ln">2032 </span></a><span class="s3">// aten::tensor_split.sections(Tensor(a -&gt; *) self, SymInt sections, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l2033"><span class="ln">2033 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::tensor_split(int64_t sections, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2034"><span class="ln">2034 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tensor_split_sections::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sections, dim);</span>
<a name="l2035"><span class="ln">2035 </span></a><span class="s0">}</span>
<a name="l2036"><span class="ln">2036 </span></a>
<a name="l2037"><span class="ln">2037 </span></a><span class="s3">// aten::tensor_split.sections(Tensor(a -&gt; *) self, SymInt sections, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l2038"><span class="ln">2038 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::tensor_split_symint(c10::SymInt sections, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2039"><span class="ln">2039 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tensor_split_sections::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sections, dim);</span>
<a name="l2040"><span class="ln">2040 </span></a><span class="s0">}</span>
<a name="l2041"><span class="ln">2041 </span></a>
<a name="l2042"><span class="ln">2042 </span></a><span class="s3">// aten::tensor_split.indices(Tensor(a -&gt; *) self, SymInt[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l2043"><span class="ln">2043 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::tensor_split(at::IntArrayRef indices, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2044"><span class="ln">2044 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tensor_split_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(indices), dim);</span>
<a name="l2045"><span class="ln">2045 </span></a><span class="s0">}</span>
<a name="l2046"><span class="ln">2046 </span></a>
<a name="l2047"><span class="ln">2047 </span></a><span class="s3">// aten::tensor_split.indices(Tensor(a -&gt; *) self, SymInt[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l2048"><span class="ln">2048 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::tensor_split_symint(c10::SymIntArrayRef indices, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2049"><span class="ln">2049 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tensor_split_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices, dim);</span>
<a name="l2050"><span class="ln">2050 </span></a><span class="s0">}</span>
<a name="l2051"><span class="ln">2051 </span></a>
<a name="l2052"><span class="ln">2052 </span></a><span class="s3">// aten::tensor_split.tensor_indices_or_sections(Tensor(a -&gt; *) self, Tensor tensor_indices_or_sections, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l2053"><span class="ln">2053 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::tensor_split(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor_indices_or_sections, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2054"><span class="ln">2054 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tensor_split_tensor_indices_or_sections::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor_indices_or_sections, dim);</span>
<a name="l2055"><span class="ln">2055 </span></a><span class="s0">}</span>
<a name="l2056"><span class="ln">2056 </span></a>
<a name="l2057"><span class="ln">2057 </span></a><span class="s3">// aten::clamp(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<a name="l2058"><span class="ln">2058 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clamp(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2059"><span class="ln">2059 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2060"><span class="ln">2060 </span></a><span class="s0">}</span>
<a name="l2061"><span class="ln">2061 </span></a>
<a name="l2062"><span class="ln">2062 </span></a><span class="s3">// aten::clamp.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<a name="l2063"><span class="ln">2063 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clamp(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2064"><span class="ln">2064 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2065"><span class="ln">2065 </span></a><span class="s0">}</span>
<a name="l2066"><span class="ln">2066 </span></a>
<a name="l2067"><span class="ln">2067 </span></a><span class="s3">// aten::clamp_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<a name="l2068"><span class="ln">2068 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clamp_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2069"><span class="ln">2069 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2070"><span class="ln">2070 </span></a><span class="s0">}</span>
<a name="l2071"><span class="ln">2071 </span></a>
<a name="l2072"><span class="ln">2072 </span></a><span class="s3">// aten::clamp_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<a name="l2073"><span class="ln">2073 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clamp_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2074"><span class="ln">2074 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2075"><span class="ln">2075 </span></a><span class="s0">}</span>
<a name="l2076"><span class="ln">2076 </span></a>
<a name="l2077"><span class="ln">2077 </span></a><span class="s3">// aten::clamp_max(Tensor self, Scalar max) -&gt; Tensor</span>
<a name="l2078"><span class="ln">2078 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clamp_max(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2079"><span class="ln">2079 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_max::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), max);</span>
<a name="l2080"><span class="ln">2080 </span></a><span class="s0">}</span>
<a name="l2081"><span class="ln">2081 </span></a>
<a name="l2082"><span class="ln">2082 </span></a><span class="s3">// aten::clamp_max.Tensor(Tensor self, Tensor max) -&gt; Tensor</span>
<a name="l2083"><span class="ln">2083 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clamp_max(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2084"><span class="ln">2084 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_max_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), max);</span>
<a name="l2085"><span class="ln">2085 </span></a><span class="s0">}</span>
<a name="l2086"><span class="ln">2086 </span></a>
<a name="l2087"><span class="ln">2087 </span></a><span class="s3">// aten::clamp_max_(Tensor(a!) self, Scalar max) -&gt; Tensor(a!)</span>
<a name="l2088"><span class="ln">2088 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clamp_max_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2089"><span class="ln">2089 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_max_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), max);</span>
<a name="l2090"><span class="ln">2090 </span></a><span class="s0">}</span>
<a name="l2091"><span class="ln">2091 </span></a>
<a name="l2092"><span class="ln">2092 </span></a><span class="s3">// aten::clamp_max_.Tensor(Tensor(a!) self, Tensor max) -&gt; Tensor(a!)</span>
<a name="l2093"><span class="ln">2093 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clamp_max_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2094"><span class="ln">2094 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_max__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), max);</span>
<a name="l2095"><span class="ln">2095 </span></a><span class="s0">}</span>
<a name="l2096"><span class="ln">2096 </span></a>
<a name="l2097"><span class="ln">2097 </span></a><span class="s3">// aten::clamp_min(Tensor self, Scalar min) -&gt; Tensor</span>
<a name="l2098"><span class="ln">2098 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clamp_min(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; min) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2099"><span class="ln">2099 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_min::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min);</span>
<a name="l2100"><span class="ln">2100 </span></a><span class="s0">}</span>
<a name="l2101"><span class="ln">2101 </span></a>
<a name="l2102"><span class="ln">2102 </span></a><span class="s3">// aten::clamp_min.Tensor(Tensor self, Tensor min) -&gt; Tensor</span>
<a name="l2103"><span class="ln">2103 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clamp_min(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; min) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2104"><span class="ln">2104 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_min_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min);</span>
<a name="l2105"><span class="ln">2105 </span></a><span class="s0">}</span>
<a name="l2106"><span class="ln">2106 </span></a>
<a name="l2107"><span class="ln">2107 </span></a><span class="s3">// aten::clamp_min_(Tensor(a!) self, Scalar min) -&gt; Tensor(a!)</span>
<a name="l2108"><span class="ln">2108 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clamp_min_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; min) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2109"><span class="ln">2109 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_min_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min);</span>
<a name="l2110"><span class="ln">2110 </span></a><span class="s0">}</span>
<a name="l2111"><span class="ln">2111 </span></a>
<a name="l2112"><span class="ln">2112 </span></a><span class="s3">// aten::clamp_min_.Tensor(Tensor(a!) self, Tensor min) -&gt; Tensor(a!)</span>
<a name="l2113"><span class="ln">2113 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clamp_min_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; min) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2114"><span class="ln">2114 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clamp_min__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min);</span>
<a name="l2115"><span class="ln">2115 </span></a><span class="s0">}</span>
<a name="l2116"><span class="ln">2116 </span></a>
<a name="l2117"><span class="ln">2117 </span></a><span class="s3">// aten::clip(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<a name="l2118"><span class="ln">2118 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clip(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2119"><span class="ln">2119 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clip::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2120"><span class="ln">2120 </span></a><span class="s0">}</span>
<a name="l2121"><span class="ln">2121 </span></a>
<a name="l2122"><span class="ln">2122 </span></a><span class="s3">// aten::clip.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<a name="l2123"><span class="ln">2123 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clip(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2124"><span class="ln">2124 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clip_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2125"><span class="ln">2125 </span></a><span class="s0">}</span>
<a name="l2126"><span class="ln">2126 </span></a>
<a name="l2127"><span class="ln">2127 </span></a><span class="s3">// aten::clip_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<a name="l2128"><span class="ln">2128 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clip_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2129"><span class="ln">2129 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clip_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2130"><span class="ln">2130 </span></a><span class="s0">}</span>
<a name="l2131"><span class="ln">2131 </span></a>
<a name="l2132"><span class="ln">2132 </span></a><span class="s3">// aten::clip_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<a name="l2133"><span class="ln">2133 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::clip_(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; min, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2134"><span class="ln">2134 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clip__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), min, max);</span>
<a name="l2135"><span class="ln">2135 </span></a><span class="s0">}</span>
<a name="l2136"><span class="ln">2136 </span></a>
<a name="l2137"><span class="ln">2137 </span></a><span class="s3">// aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -&gt; Tensor(a)</span>
<a name="l2138"><span class="ln">2138 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__dispatch_contiguous(at::MemoryFormat memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2139"><span class="ln">2139 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::contiguous::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), memory_format);</span>
<a name="l2140"><span class="ln">2140 </span></a><span class="s0">}</span>
<a name="l2141"><span class="ln">2141 </span></a>
<a name="l2142"><span class="ln">2142 </span></a><span class="s3">// aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -&gt; Tensor(a!)</span>
<a name="l2143"><span class="ln">2143 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::copy_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, </span><span class="s1">bool </span><span class="s0">non_blocking) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2144"><span class="ln">2144 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::copy_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, non_blocking);</span>
<a name="l2145"><span class="ln">2145 </span></a><span class="s0">}</span>
<a name="l2146"><span class="ln">2146 </span></a>
<a name="l2147"><span class="ln">2147 </span></a><span class="s3">// aten::cos(Tensor self) -&gt; Tensor</span>
<a name="l2148"><span class="ln">2148 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cos() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2149"><span class="ln">2149 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cos::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2150"><span class="ln">2150 </span></a><span class="s0">}</span>
<a name="l2151"><span class="ln">2151 </span></a>
<a name="l2152"><span class="ln">2152 </span></a><span class="s3">// aten::cos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2153"><span class="ln">2153 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cos_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2154"><span class="ln">2154 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cos_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2155"><span class="ln">2155 </span></a><span class="s0">}</span>
<a name="l2156"><span class="ln">2156 </span></a>
<a name="l2157"><span class="ln">2157 </span></a><span class="s3">// aten::cosh(Tensor self) -&gt; Tensor</span>
<a name="l2158"><span class="ln">2158 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cosh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2159"><span class="ln">2159 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cosh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2160"><span class="ln">2160 </span></a><span class="s0">}</span>
<a name="l2161"><span class="ln">2161 </span></a>
<a name="l2162"><span class="ln">2162 </span></a><span class="s3">// aten::cosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2163"><span class="ln">2163 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cosh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2164"><span class="ln">2164 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cosh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2165"><span class="ln">2165 </span></a><span class="s0">}</span>
<a name="l2166"><span class="ln">2166 </span></a>
<a name="l2167"><span class="ln">2167 </span></a><span class="s3">// aten::count_nonzero.dim_IntList(Tensor self, int[] dim) -&gt; Tensor</span>
<a name="l2168"><span class="ln">2168 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::count_nonzero(at::IntArrayRef dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2169"><span class="ln">2169 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::count_nonzero_dim_IntList::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2170"><span class="ln">2170 </span></a><span class="s0">}</span>
<a name="l2171"><span class="ln">2171 </span></a>
<a name="l2172"><span class="ln">2172 </span></a><span class="s3">// aten::count_nonzero(Tensor self, int? dim=None) -&gt; Tensor</span>
<a name="l2173"><span class="ln">2173 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::count_nonzero(::std::optional&lt;int64_t&gt; dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2174"><span class="ln">2174 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::count_nonzero::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2175"><span class="ln">2175 </span></a><span class="s0">}</span>
<a name="l2176"><span class="ln">2176 </span></a>
<a name="l2177"><span class="ln">2177 </span></a><span class="s3">// aten::cov(Tensor self, *, int correction=1, Tensor? fweights=None, Tensor? aweights=None) -&gt; Tensor</span>
<a name="l2178"><span class="ln">2178 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cov(int64_t correction, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; fweights, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; aweights) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2179"><span class="ln">2179 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cov::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), correction, fweights, aweights);</span>
<a name="l2180"><span class="ln">2180 </span></a><span class="s0">}</span>
<a name="l2181"><span class="ln">2181 </span></a>
<a name="l2182"><span class="ln">2182 </span></a><span class="s3">// aten::corrcoef(Tensor self) -&gt; Tensor</span>
<a name="l2183"><span class="ln">2183 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::corrcoef() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2184"><span class="ln">2184 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::corrcoef::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2185"><span class="ln">2185 </span></a><span class="s0">}</span>
<a name="l2186"><span class="ln">2186 </span></a>
<a name="l2187"><span class="ln">2187 </span></a><span class="s3">// aten::cummax(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2188"><span class="ln">2188 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummax(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2189"><span class="ln">2189 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cummax::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2190"><span class="ln">2190 </span></a><span class="s0">}</span>
<a name="l2191"><span class="ln">2191 </span></a>
<a name="l2192"><span class="ln">2192 </span></a><span class="s3">// aten::cummax.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2193"><span class="ln">2193 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummax(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2194"><span class="ln">2194 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cummax_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2195"><span class="ln">2195 </span></a><span class="s0">}</span>
<a name="l2196"><span class="ln">2196 </span></a>
<a name="l2197"><span class="ln">2197 </span></a><span class="s3">// aten::cummin(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2198"><span class="ln">2198 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummin(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2199"><span class="ln">2199 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cummin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2200"><span class="ln">2200 </span></a><span class="s0">}</span>
<a name="l2201"><span class="ln">2201 </span></a>
<a name="l2202"><span class="ln">2202 </span></a><span class="s3">// aten::cummin.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2203"><span class="ln">2203 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummin(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2204"><span class="ln">2204 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cummin_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2205"><span class="ln">2205 </span></a><span class="s0">}</span>
<a name="l2206"><span class="ln">2206 </span></a>
<a name="l2207"><span class="ln">2207 </span></a><span class="s3">// aten::cumprod(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2208"><span class="ln">2208 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cumprod(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2209"><span class="ln">2209 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumprod::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2210"><span class="ln">2210 </span></a><span class="s0">}</span>
<a name="l2211"><span class="ln">2211 </span></a>
<a name="l2212"><span class="ln">2212 </span></a><span class="s3">// aten::cumprod_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<a name="l2213"><span class="ln">2213 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cumprod_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2214"><span class="ln">2214 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumprod_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2215"><span class="ln">2215 </span></a><span class="s0">}</span>
<a name="l2216"><span class="ln">2216 </span></a>
<a name="l2217"><span class="ln">2217 </span></a><span class="s3">// aten::cumprod.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2218"><span class="ln">2218 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cumprod(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2219"><span class="ln">2219 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumprod_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2220"><span class="ln">2220 </span></a><span class="s0">}</span>
<a name="l2221"><span class="ln">2221 </span></a>
<a name="l2222"><span class="ln">2222 </span></a><span class="s3">// aten::cumprod_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<a name="l2223"><span class="ln">2223 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cumprod_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2224"><span class="ln">2224 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumprod__dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2225"><span class="ln">2225 </span></a><span class="s0">}</span>
<a name="l2226"><span class="ln">2226 </span></a>
<a name="l2227"><span class="ln">2227 </span></a><span class="s3">// aten::cumsum(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2228"><span class="ln">2228 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cumsum(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2229"><span class="ln">2229 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumsum::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2230"><span class="ln">2230 </span></a><span class="s0">}</span>
<a name="l2231"><span class="ln">2231 </span></a>
<a name="l2232"><span class="ln">2232 </span></a><span class="s3">// aten::cumsum_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<a name="l2233"><span class="ln">2233 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cumsum_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2234"><span class="ln">2234 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumsum_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2235"><span class="ln">2235 </span></a><span class="s0">}</span>
<a name="l2236"><span class="ln">2236 </span></a>
<a name="l2237"><span class="ln">2237 </span></a><span class="s3">// aten::cumsum.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2238"><span class="ln">2238 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cumsum(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2239"><span class="ln">2239 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumsum_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2240"><span class="ln">2240 </span></a><span class="s0">}</span>
<a name="l2241"><span class="ln">2241 </span></a>
<a name="l2242"><span class="ln">2242 </span></a><span class="s3">// aten::cumsum_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<a name="l2243"><span class="ln">2243 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cumsum_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2244"><span class="ln">2244 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cumsum__dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2245"><span class="ln">2245 </span></a><span class="s0">}</span>
<a name="l2246"><span class="ln">2246 </span></a>
<a name="l2247"><span class="ln">2247 </span></a><span class="s3">// aten::diag_embed(Tensor self, int offset=0, int dim1=-2, int dim2=-1) -&gt; Tensor</span>
<a name="l2248"><span class="ln">2248 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diag_embed(int64_t offset, int64_t dim1, int64_t dim2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2249"><span class="ln">2249 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diag_embed::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), offset, dim1, dim2);</span>
<a name="l2250"><span class="ln">2250 </span></a><span class="s0">}</span>
<a name="l2251"><span class="ln">2251 </span></a>
<a name="l2252"><span class="ln">2252 </span></a><span class="s3">// aten::diagflat(Tensor self, int offset=0) -&gt; Tensor</span>
<a name="l2253"><span class="ln">2253 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diagflat(int64_t offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2254"><span class="ln">2254 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diagflat::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), offset);</span>
<a name="l2255"><span class="ln">2255 </span></a><span class="s0">}</span>
<a name="l2256"><span class="ln">2256 </span></a>
<a name="l2257"><span class="ln">2257 </span></a><span class="s3">// aten::diagonal(Tensor(a) self, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor(a)</span>
<a name="l2258"><span class="ln">2258 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diagonal(int64_t offset, int64_t dim1, int64_t dim2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2259"><span class="ln">2259 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diagonal::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), offset, dim1, dim2);</span>
<a name="l2260"><span class="ln">2260 </span></a><span class="s0">}</span>
<a name="l2261"><span class="ln">2261 </span></a>
<a name="l2262"><span class="ln">2262 </span></a><span class="s3">// aten::diagonal.Dimname(Tensor(a) self, *, Dimname outdim, Dimname dim1, Dimname dim2, int offset=0) -&gt; Tensor(a)</span>
<a name="l2263"><span class="ln">2263 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diagonal(at::Dimname outdim, at::Dimname dim1, at::Dimname dim2, int64_t offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2264"><span class="ln">2264 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diagonal_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), outdim, dim1, dim2, offset);</span>
<a name="l2265"><span class="ln">2265 </span></a><span class="s0">}</span>
<a name="l2266"><span class="ln">2266 </span></a>
<a name="l2267"><span class="ln">2267 </span></a><span class="s3">// aten::fill_diagonal_(Tensor(a!) self, Scalar fill_value, bool wrap=False) -&gt; Tensor(a!)</span>
<a name="l2268"><span class="ln">2268 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::fill_diagonal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, </span><span class="s1">bool </span><span class="s0">wrap) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2269"><span class="ln">2269 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fill_diagonal_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), fill_value, wrap);</span>
<a name="l2270"><span class="ln">2270 </span></a><span class="s0">}</span>
<a name="l2271"><span class="ln">2271 </span></a>
<a name="l2272"><span class="ln">2272 </span></a><span class="s3">// aten::diff(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None) -&gt; Tensor</span>
<a name="l2273"><span class="ln">2273 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diff(int64_t n, int64_t dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; prepend, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; append) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2274"><span class="ln">2274 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diff::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), n, dim, prepend, append);</span>
<a name="l2275"><span class="ln">2275 </span></a><span class="s0">}</span>
<a name="l2276"><span class="ln">2276 </span></a>
<a name="l2277"><span class="ln">2277 </span></a><span class="s3">// aten::div.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2278"><span class="ln">2278 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::div(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2279"><span class="ln">2279 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2280"><span class="ln">2280 </span></a><span class="s0">}</span>
<a name="l2281"><span class="ln">2281 </span></a>
<a name="l2282"><span class="ln">2282 </span></a><span class="s3">// aten::div_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2283"><span class="ln">2283 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::div_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2284"><span class="ln">2284 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2285"><span class="ln">2285 </span></a><span class="s0">}</span>
<a name="l2286"><span class="ln">2286 </span></a>
<a name="l2287"><span class="ln">2287 </span></a><span class="s3">// aten::div.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<a name="l2288"><span class="ln">2288 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::div(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2289"><span class="ln">2289 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div_Tensor_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2290"><span class="ln">2290 </span></a><span class="s0">}</span>
<a name="l2291"><span class="ln">2291 </span></a>
<a name="l2292"><span class="ln">2292 </span></a><span class="s3">// aten::div_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<a name="l2293"><span class="ln">2293 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::div_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2294"><span class="ln">2294 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div__Tensor_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2295"><span class="ln">2295 </span></a><span class="s0">}</span>
<a name="l2296"><span class="ln">2296 </span></a>
<a name="l2297"><span class="ln">2297 </span></a><span class="s3">// aten::div.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l2298"><span class="ln">2298 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::div(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2299"><span class="ln">2299 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2300"><span class="ln">2300 </span></a><span class="s0">}</span>
<a name="l2301"><span class="ln">2301 </span></a>
<a name="l2302"><span class="ln">2302 </span></a><span class="s3">// aten::div_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l2303"><span class="ln">2303 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::div_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2304"><span class="ln">2304 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2305"><span class="ln">2305 </span></a><span class="s0">}</span>
<a name="l2306"><span class="ln">2306 </span></a>
<a name="l2307"><span class="ln">2307 </span></a><span class="s3">// aten::div.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<a name="l2308"><span class="ln">2308 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::div(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2309"><span class="ln">2309 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div_Scalar_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2310"><span class="ln">2310 </span></a><span class="s0">}</span>
<a name="l2311"><span class="ln">2311 </span></a>
<a name="l2312"><span class="ln">2312 </span></a><span class="s3">// aten::div_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<a name="l2313"><span class="ln">2313 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::div_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2314"><span class="ln">2314 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::div__Scalar_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2315"><span class="ln">2315 </span></a><span class="s0">}</span>
<a name="l2316"><span class="ln">2316 </span></a>
<a name="l2317"><span class="ln">2317 </span></a><span class="s3">// aten::divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2318"><span class="ln">2318 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2319"><span class="ln">2319 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2320"><span class="ln">2320 </span></a><span class="s0">}</span>
<a name="l2321"><span class="ln">2321 </span></a>
<a name="l2322"><span class="ln">2322 </span></a><span class="s3">// aten::divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2323"><span class="ln">2323 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2324"><span class="ln">2324 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2325"><span class="ln">2325 </span></a><span class="s0">}</span>
<a name="l2326"><span class="ln">2326 </span></a>
<a name="l2327"><span class="ln">2327 </span></a><span class="s3">// aten::divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l2328"><span class="ln">2328 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2329"><span class="ln">2329 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2330"><span class="ln">2330 </span></a><span class="s0">}</span>
<a name="l2331"><span class="ln">2331 </span></a>
<a name="l2332"><span class="ln">2332 </span></a><span class="s3">// aten::divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l2333"><span class="ln">2333 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2334"><span class="ln">2334 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2335"><span class="ln">2335 </span></a><span class="s0">}</span>
<a name="l2336"><span class="ln">2336 </span></a>
<a name="l2337"><span class="ln">2337 </span></a><span class="s3">// aten::divide.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<a name="l2338"><span class="ln">2338 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2339"><span class="ln">2339 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide_Tensor_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2340"><span class="ln">2340 </span></a><span class="s0">}</span>
<a name="l2341"><span class="ln">2341 </span></a>
<a name="l2342"><span class="ln">2342 </span></a><span class="s3">// aten::divide_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<a name="l2343"><span class="ln">2343 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2344"><span class="ln">2344 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide__Tensor_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2345"><span class="ln">2345 </span></a><span class="s0">}</span>
<a name="l2346"><span class="ln">2346 </span></a>
<a name="l2347"><span class="ln">2347 </span></a><span class="s3">// aten::divide.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<a name="l2348"><span class="ln">2348 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2349"><span class="ln">2349 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide_Scalar_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2350"><span class="ln">2350 </span></a><span class="s0">}</span>
<a name="l2351"><span class="ln">2351 </span></a>
<a name="l2352"><span class="ln">2352 </span></a><span class="s3">// aten::divide_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<a name="l2353"><span class="ln">2353 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2354"><span class="ln">2354 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::divide__Scalar_mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rounding_mode);</span>
<a name="l2355"><span class="ln">2355 </span></a><span class="s0">}</span>
<a name="l2356"><span class="ln">2356 </span></a>
<a name="l2357"><span class="ln">2357 </span></a><span class="s3">// aten::true_divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2358"><span class="ln">2358 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::true_divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2359"><span class="ln">2359 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::true_divide_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2360"><span class="ln">2360 </span></a><span class="s0">}</span>
<a name="l2361"><span class="ln">2361 </span></a>
<a name="l2362"><span class="ln">2362 </span></a><span class="s3">// aten::true_divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2363"><span class="ln">2363 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::true_divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2364"><span class="ln">2364 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::true_divide__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2365"><span class="ln">2365 </span></a><span class="s0">}</span>
<a name="l2366"><span class="ln">2366 </span></a>
<a name="l2367"><span class="ln">2367 </span></a><span class="s3">// aten::true_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l2368"><span class="ln">2368 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::true_divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2369"><span class="ln">2369 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::true_divide_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2370"><span class="ln">2370 </span></a><span class="s0">}</span>
<a name="l2371"><span class="ln">2371 </span></a>
<a name="l2372"><span class="ln">2372 </span></a><span class="s3">// aten::true_divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l2373"><span class="ln">2373 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::true_divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2374"><span class="ln">2374 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::true_divide__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2375"><span class="ln">2375 </span></a><span class="s0">}</span>
<a name="l2376"><span class="ln">2376 </span></a>
<a name="l2377"><span class="ln">2377 </span></a><span class="s3">// aten::dot(Tensor self, Tensor tensor) -&gt; Tensor</span>
<a name="l2378"><span class="ln">2378 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::dot(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2379"><span class="ln">2379 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::dot::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor);</span>
<a name="l2380"><span class="ln">2380 </span></a><span class="s0">}</span>
<a name="l2381"><span class="ln">2381 </span></a>
<a name="l2382"><span class="ln">2382 </span></a><span class="s3">// aten::vdot(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2383"><span class="ln">2383 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::vdot(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2384"><span class="ln">2384 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::vdot::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2385"><span class="ln">2385 </span></a><span class="s0">}</span>
<a name="l2386"><span class="ln">2386 </span></a>
<a name="l2387"><span class="ln">2387 </span></a><span class="s3">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2388"><span class="ln">2388 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty(at::IntArrayRef size, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2389"><span class="ln">2389 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2390"><span class="ln">2390 </span></a><span class="s0">}</span>
<a name="l2391"><span class="ln">2391 </span></a>
<a name="l2392"><span class="ln">2392 </span></a><span class="s3">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2393"><span class="ln">2393 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2394"><span class="ln">2394 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory);</span>
<a name="l2395"><span class="ln">2395 </span></a><span class="s0">}</span>
<a name="l2396"><span class="ln">2396 </span></a>
<a name="l2397"><span class="ln">2397 </span></a><span class="s3">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2398"><span class="ln">2398 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty_symint(c10::SymIntArrayRef size, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2399"><span class="ln">2399 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2400"><span class="ln">2400 </span></a><span class="s0">}</span>
<a name="l2401"><span class="ln">2401 </span></a>
<a name="l2402"><span class="ln">2402 </span></a><span class="s3">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2403"><span class="ln">2403 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2404"><span class="ln">2404 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, dtype, layout, device, pin_memory);</span>
<a name="l2405"><span class="ln">2405 </span></a><span class="s0">}</span>
<a name="l2406"><span class="ln">2406 </span></a>
<a name="l2407"><span class="ln">2407 </span></a><span class="s3">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2408"><span class="ln">2408 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2409"><span class="ln">2409 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty_strided::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2410"><span class="ln">2410 </span></a><span class="s0">}</span>
<a name="l2411"><span class="ln">2411 </span></a>
<a name="l2412"><span class="ln">2412 </span></a><span class="s3">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2413"><span class="ln">2413 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2414"><span class="ln">2414 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty_strided::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), dtype, layout, device, pin_memory);</span>
<a name="l2415"><span class="ln">2415 </span></a><span class="s0">}</span>
<a name="l2416"><span class="ln">2416 </span></a>
<a name="l2417"><span class="ln">2417 </span></a><span class="s3">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2418"><span class="ln">2418 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2419"><span class="ln">2419 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty_strided::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, stride, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2420"><span class="ln">2420 </span></a><span class="s0">}</span>
<a name="l2421"><span class="ln">2421 </span></a>
<a name="l2422"><span class="ln">2422 </span></a><span class="s3">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2423"><span class="ln">2423 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2424"><span class="ln">2424 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_empty_strided::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, stride, dtype, layout, device, pin_memory);</span>
<a name="l2425"><span class="ln">2425 </span></a><span class="s0">}</span>
<a name="l2426"><span class="ln">2426 </span></a>
<a name="l2427"><span class="ln">2427 </span></a><span class="s3">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2428"><span class="ln">2428 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_full(at::IntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2429"><span class="ln">2429 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_full::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), fill_value, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2430"><span class="ln">2430 </span></a><span class="s0">}</span>
<a name="l2431"><span class="ln">2431 </span></a>
<a name="l2432"><span class="ln">2432 </span></a><span class="s3">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2433"><span class="ln">2433 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_full(at::IntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2434"><span class="ln">2434 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_full::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), fill_value, dtype, layout, device, pin_memory);</span>
<a name="l2435"><span class="ln">2435 </span></a><span class="s0">}</span>
<a name="l2436"><span class="ln">2436 </span></a>
<a name="l2437"><span class="ln">2437 </span></a><span class="s3">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2438"><span class="ln">2438 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_full_symint(c10::SymIntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2439"><span class="ln">2439 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_full::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, fill_value, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2440"><span class="ln">2440 </span></a><span class="s0">}</span>
<a name="l2441"><span class="ln">2441 </span></a>
<a name="l2442"><span class="ln">2442 </span></a><span class="s3">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2443"><span class="ln">2443 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_full_symint(c10::SymIntArrayRef size, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2444"><span class="ln">2444 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_full::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, fill_value, dtype, layout, device, pin_memory);</span>
<a name="l2445"><span class="ln">2445 </span></a><span class="s0">}</span>
<a name="l2446"><span class="ln">2446 </span></a>
<a name="l2447"><span class="ln">2447 </span></a><span class="s3">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2448"><span class="ln">2448 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_zeros(at::IntArrayRef size, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2449"><span class="ln">2449 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_zeros::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2450"><span class="ln">2450 </span></a><span class="s0">}</span>
<a name="l2451"><span class="ln">2451 </span></a>
<a name="l2452"><span class="ln">2452 </span></a><span class="s3">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2453"><span class="ln">2453 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_zeros(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2454"><span class="ln">2454 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_zeros::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory);</span>
<a name="l2455"><span class="ln">2455 </span></a><span class="s0">}</span>
<a name="l2456"><span class="ln">2456 </span></a>
<a name="l2457"><span class="ln">2457 </span></a><span class="s3">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2458"><span class="ln">2458 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_zeros_symint(c10::SymIntArrayRef size, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2459"><span class="ln">2459 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_zeros::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2460"><span class="ln">2460 </span></a><span class="s0">}</span>
<a name="l2461"><span class="ln">2461 </span></a>
<a name="l2462"><span class="ln">2462 </span></a><span class="s3">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2463"><span class="ln">2463 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_zeros_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2464"><span class="ln">2464 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_zeros::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, dtype, layout, device, pin_memory);</span>
<a name="l2465"><span class="ln">2465 </span></a><span class="s0">}</span>
<a name="l2466"><span class="ln">2466 </span></a>
<a name="l2467"><span class="ln">2467 </span></a><span class="s3">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2468"><span class="ln">2468 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_ones(at::IntArrayRef size, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2469"><span class="ln">2469 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_ones::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2470"><span class="ln">2470 </span></a><span class="s0">}</span>
<a name="l2471"><span class="ln">2471 </span></a>
<a name="l2472"><span class="ln">2472 </span></a><span class="s3">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2473"><span class="ln">2473 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_ones(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2474"><span class="ln">2474 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_ones::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory);</span>
<a name="l2475"><span class="ln">2475 </span></a><span class="s0">}</span>
<a name="l2476"><span class="ln">2476 </span></a>
<a name="l2477"><span class="ln">2477 </span></a><span class="s3">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2478"><span class="ln">2478 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_ones_symint(c10::SymIntArrayRef size, at::TensorOptions options) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2479"><span class="ln">2479 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_ones::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<a name="l2480"><span class="ln">2480 </span></a><span class="s0">}</span>
<a name="l2481"><span class="ln">2481 </span></a>
<a name="l2482"><span class="ln">2482 </span></a><span class="s3">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<a name="l2483"><span class="ln">2483 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::new_ones_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2484"><span class="ln">2484 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::new_ones::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, dtype, layout, device, pin_memory);</span>
<a name="l2485"><span class="ln">2485 </span></a><span class="s0">}</span>
<a name="l2486"><span class="ln">2486 </span></a>
<a name="l2487"><span class="ln">2487 </span></a><span class="s3">// aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<a name="l2488"><span class="ln">2488 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::resize_(at::IntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2489"><span class="ln">2489 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::resize_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), memory_format);</span>
<a name="l2490"><span class="ln">2490 </span></a><span class="s0">}</span>
<a name="l2491"><span class="ln">2491 </span></a>
<a name="l2492"><span class="ln">2492 </span></a><span class="s3">// aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<a name="l2493"><span class="ln">2493 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::resize__symint(c10::SymIntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2494"><span class="ln">2494 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::resize_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, memory_format);</span>
<a name="l2495"><span class="ln">2495 </span></a><span class="s0">}</span>
<a name="l2496"><span class="ln">2496 </span></a>
<a name="l2497"><span class="ln">2497 </span></a><span class="s3">// aten::erf(Tensor self) -&gt; Tensor</span>
<a name="l2498"><span class="ln">2498 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::erf() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2499"><span class="ln">2499 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::erf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2500"><span class="ln">2500 </span></a><span class="s0">}</span>
<a name="l2501"><span class="ln">2501 </span></a>
<a name="l2502"><span class="ln">2502 </span></a><span class="s3">// aten::erf_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2503"><span class="ln">2503 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::erf_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2504"><span class="ln">2504 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::erf_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2505"><span class="ln">2505 </span></a><span class="s0">}</span>
<a name="l2506"><span class="ln">2506 </span></a>
<a name="l2507"><span class="ln">2507 </span></a><span class="s3">// aten::erfc(Tensor self) -&gt; Tensor</span>
<a name="l2508"><span class="ln">2508 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::erfc() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2509"><span class="ln">2509 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::erfc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2510"><span class="ln">2510 </span></a><span class="s0">}</span>
<a name="l2511"><span class="ln">2511 </span></a>
<a name="l2512"><span class="ln">2512 </span></a><span class="s3">// aten::erfc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2513"><span class="ln">2513 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::erfc_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2514"><span class="ln">2514 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::erfc_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2515"><span class="ln">2515 </span></a><span class="s0">}</span>
<a name="l2516"><span class="ln">2516 </span></a>
<a name="l2517"><span class="ln">2517 </span></a><span class="s3">// aten::exp(Tensor self) -&gt; Tensor</span>
<a name="l2518"><span class="ln">2518 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::exp() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2519"><span class="ln">2519 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::exp::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2520"><span class="ln">2520 </span></a><span class="s0">}</span>
<a name="l2521"><span class="ln">2521 </span></a>
<a name="l2522"><span class="ln">2522 </span></a><span class="s3">// aten::exp_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2523"><span class="ln">2523 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::exp_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2524"><span class="ln">2524 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::exp_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2525"><span class="ln">2525 </span></a><span class="s0">}</span>
<a name="l2526"><span class="ln">2526 </span></a>
<a name="l2527"><span class="ln">2527 </span></a><span class="s3">// aten::exp2(Tensor self) -&gt; Tensor</span>
<a name="l2528"><span class="ln">2528 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::exp2() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2529"><span class="ln">2529 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::exp2::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2530"><span class="ln">2530 </span></a><span class="s0">}</span>
<a name="l2531"><span class="ln">2531 </span></a>
<a name="l2532"><span class="ln">2532 </span></a><span class="s3">// aten::exp2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2533"><span class="ln">2533 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::exp2_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2534"><span class="ln">2534 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::exp2_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2535"><span class="ln">2535 </span></a><span class="s0">}</span>
<a name="l2536"><span class="ln">2536 </span></a>
<a name="l2537"><span class="ln">2537 </span></a><span class="s3">// aten::expm1(Tensor self) -&gt; Tensor</span>
<a name="l2538"><span class="ln">2538 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::expm1() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2539"><span class="ln">2539 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::expm1::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2540"><span class="ln">2540 </span></a><span class="s0">}</span>
<a name="l2541"><span class="ln">2541 </span></a>
<a name="l2542"><span class="ln">2542 </span></a><span class="s3">// aten::expm1_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2543"><span class="ln">2543 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::expm1_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2544"><span class="ln">2544 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::expm1_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2545"><span class="ln">2545 </span></a><span class="s0">}</span>
<a name="l2546"><span class="ln">2546 </span></a>
<a name="l2547"><span class="ln">2547 </span></a><span class="s3">// aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -&gt; Tensor(a)</span>
<a name="l2548"><span class="ln">2548 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::expand(at::IntArrayRef size, </span><span class="s1">bool </span><span class="s0">implicit) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2549"><span class="ln">2549 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::expand::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), implicit);</span>
<a name="l2550"><span class="ln">2550 </span></a><span class="s0">}</span>
<a name="l2551"><span class="ln">2551 </span></a>
<a name="l2552"><span class="ln">2552 </span></a><span class="s3">// aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -&gt; Tensor(a)</span>
<a name="l2553"><span class="ln">2553 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::expand_symint(c10::SymIntArrayRef size, </span><span class="s1">bool </span><span class="s0">implicit) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2554"><span class="ln">2554 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::expand::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, implicit);</span>
<a name="l2555"><span class="ln">2555 </span></a><span class="s0">}</span>
<a name="l2556"><span class="ln">2556 </span></a>
<a name="l2557"><span class="ln">2557 </span></a><span class="s3">// aten::expand_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<a name="l2558"><span class="ln">2558 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::expand_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2559"><span class="ln">2559 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::expand_as::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2560"><span class="ln">2560 </span></a><span class="s0">}</span>
<a name="l2561"><span class="ln">2561 </span></a>
<a name="l2562"><span class="ln">2562 </span></a><span class="s3">// aten::flatten.using_ints(Tensor(a) self, int start_dim=0, int end_dim=-1) -&gt; Tensor(a)</span>
<a name="l2563"><span class="ln">2563 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::flatten(int64_t start_dim, int64_t end_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2564"><span class="ln">2564 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::flatten_using_ints::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), start_dim, end_dim);</span>
<a name="l2565"><span class="ln">2565 </span></a><span class="s0">}</span>
<a name="l2566"><span class="ln">2566 </span></a>
<a name="l2567"><span class="ln">2567 </span></a><span class="s3">// aten::flatten.named_out_dim(Tensor(a) self, int start_dim, int end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<a name="l2568"><span class="ln">2568 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::flatten(int64_t start_dim, int64_t end_dim, at::Dimname out_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2569"><span class="ln">2569 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::flatten_named_out_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), start_dim, end_dim, out_dim);</span>
<a name="l2570"><span class="ln">2570 </span></a><span class="s0">}</span>
<a name="l2571"><span class="ln">2571 </span></a>
<a name="l2572"><span class="ln">2572 </span></a><span class="s3">// aten::flatten.using_names(Tensor(a) self, Dimname start_dim, Dimname end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<a name="l2573"><span class="ln">2573 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::flatten(at::Dimname start_dim, at::Dimname end_dim, at::Dimname out_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2574"><span class="ln">2574 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::flatten_using_names::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), start_dim, end_dim, out_dim);</span>
<a name="l2575"><span class="ln">2575 </span></a><span class="s0">}</span>
<a name="l2576"><span class="ln">2576 </span></a>
<a name="l2577"><span class="ln">2577 </span></a><span class="s3">// aten::flatten.DimnameList(Tensor(a) self, Dimname[] dims, Dimname out_dim) -&gt; Tensor(a)</span>
<a name="l2578"><span class="ln">2578 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::flatten(at::DimnameList dims, at::Dimname out_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2579"><span class="ln">2579 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::flatten_DimnameList::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dims, out_dim);</span>
<a name="l2580"><span class="ln">2580 </span></a><span class="s0">}</span>
<a name="l2581"><span class="ln">2581 </span></a>
<a name="l2582"><span class="ln">2582 </span></a><span class="s3">// aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -&gt; Tensor(a)</span>
<a name="l2583"><span class="ln">2583 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::unflatten(int64_t dim, at::IntArrayRef sizes) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2584"><span class="ln">2584 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unflatten_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, c10::fromIntArrayRefSlow(sizes));</span>
<a name="l2585"><span class="ln">2585 </span></a><span class="s0">}</span>
<a name="l2586"><span class="ln">2586 </span></a>
<a name="l2587"><span class="ln">2587 </span></a><span class="s3">// aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -&gt; Tensor(a)</span>
<a name="l2588"><span class="ln">2588 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::unflatten_symint(int64_t dim, c10::SymIntArrayRef sizes) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2589"><span class="ln">2589 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unflatten_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, sizes);</span>
<a name="l2590"><span class="ln">2590 </span></a><span class="s0">}</span>
<a name="l2591"><span class="ln">2591 </span></a>
<a name="l2592"><span class="ln">2592 </span></a><span class="s3">// aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -&gt; Tensor(a)</span>
<a name="l2593"><span class="ln">2593 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::unflatten(at::Dimname dim, at::IntArrayRef sizes, at::DimnameList names) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2594"><span class="ln">2594 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unflatten_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, c10::fromIntArrayRefSlow(sizes), names);</span>
<a name="l2595"><span class="ln">2595 </span></a><span class="s0">}</span>
<a name="l2596"><span class="ln">2596 </span></a>
<a name="l2597"><span class="ln">2597 </span></a><span class="s3">// aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -&gt; Tensor(a)</span>
<a name="l2598"><span class="ln">2598 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::unflatten_symint(at::Dimname dim, c10::SymIntArrayRef sizes, at::DimnameList names) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2599"><span class="ln">2599 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unflatten_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, sizes, names);</span>
<a name="l2600"><span class="ln">2600 </span></a><span class="s0">}</span>
<a name="l2601"><span class="ln">2601 </span></a>
<a name="l2602"><span class="ln">2602 </span></a><span class="s3">// aten::fill_.Scalar(Tensor(a!) self, Scalar value) -&gt; Tensor(a!)</span>
<a name="l2603"><span class="ln">2603 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::fill_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2604"><span class="ln">2604 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fill__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), value);</span>
<a name="l2605"><span class="ln">2605 </span></a><span class="s0">}</span>
<a name="l2606"><span class="ln">2606 </span></a>
<a name="l2607"><span class="ln">2607 </span></a><span class="s3">// aten::fill_.Tensor(Tensor(a!) self, Tensor value) -&gt; Tensor(a!)</span>
<a name="l2608"><span class="ln">2608 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::fill_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2609"><span class="ln">2609 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fill__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), value);</span>
<a name="l2610"><span class="ln">2610 </span></a><span class="s0">}</span>
<a name="l2611"><span class="ln">2611 </span></a>
<a name="l2612"><span class="ln">2612 </span></a><span class="s3">// aten::floor(Tensor self) -&gt; Tensor</span>
<a name="l2613"><span class="ln">2613 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::floor() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2614"><span class="ln">2614 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::floor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2615"><span class="ln">2615 </span></a><span class="s0">}</span>
<a name="l2616"><span class="ln">2616 </span></a>
<a name="l2617"><span class="ln">2617 </span></a><span class="s3">// aten::floor_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2618"><span class="ln">2618 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::floor_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2619"><span class="ln">2619 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::floor_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2620"><span class="ln">2620 </span></a><span class="s0">}</span>
<a name="l2621"><span class="ln">2621 </span></a>
<a name="l2622"><span class="ln">2622 </span></a><span class="s3">// aten::floor_divide(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2623"><span class="ln">2623 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::floor_divide(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2624"><span class="ln">2624 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::floor_divide::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2625"><span class="ln">2625 </span></a><span class="s0">}</span>
<a name="l2626"><span class="ln">2626 </span></a>
<a name="l2627"><span class="ln">2627 </span></a><span class="s3">// aten::floor_divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2628"><span class="ln">2628 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::floor_divide_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2629"><span class="ln">2629 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::floor_divide__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2630"><span class="ln">2630 </span></a><span class="s0">}</span>
<a name="l2631"><span class="ln">2631 </span></a>
<a name="l2632"><span class="ln">2632 </span></a><span class="s3">// aten::floor_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l2633"><span class="ln">2633 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::floor_divide(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2634"><span class="ln">2634 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::floor_divide_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2635"><span class="ln">2635 </span></a><span class="s0">}</span>
<a name="l2636"><span class="ln">2636 </span></a>
<a name="l2637"><span class="ln">2637 </span></a><span class="s3">// aten::floor_divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l2638"><span class="ln">2638 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::floor_divide_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2639"><span class="ln">2639 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::floor_divide__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2640"><span class="ln">2640 </span></a><span class="s0">}</span>
<a name="l2641"><span class="ln">2641 </span></a>
<a name="l2642"><span class="ln">2642 </span></a><span class="s3">// aten::frac(Tensor self) -&gt; Tensor</span>
<a name="l2643"><span class="ln">2643 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::frac() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2644"><span class="ln">2644 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::frac::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2645"><span class="ln">2645 </span></a><span class="s0">}</span>
<a name="l2646"><span class="ln">2646 </span></a>
<a name="l2647"><span class="ln">2647 </span></a><span class="s3">// aten::frac_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2648"><span class="ln">2648 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::frac_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2649"><span class="ln">2649 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::frac_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2650"><span class="ln">2650 </span></a><span class="s0">}</span>
<a name="l2651"><span class="ln">2651 </span></a>
<a name="l2652"><span class="ln">2652 </span></a><span class="s3">// aten::gcd(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2653"><span class="ln">2653 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::gcd(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2654"><span class="ln">2654 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gcd::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2655"><span class="ln">2655 </span></a><span class="s0">}</span>
<a name="l2656"><span class="ln">2656 </span></a>
<a name="l2657"><span class="ln">2657 </span></a><span class="s3">// aten::gcd_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2658"><span class="ln">2658 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::gcd_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2659"><span class="ln">2659 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gcd_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2660"><span class="ln">2660 </span></a><span class="s0">}</span>
<a name="l2661"><span class="ln">2661 </span></a>
<a name="l2662"><span class="ln">2662 </span></a><span class="s3">// aten::lcm(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2663"><span class="ln">2663 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lcm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2664"><span class="ln">2664 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lcm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2665"><span class="ln">2665 </span></a><span class="s0">}</span>
<a name="l2666"><span class="ln">2666 </span></a>
<a name="l2667"><span class="ln">2667 </span></a><span class="s3">// aten::lcm_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2668"><span class="ln">2668 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::lcm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2669"><span class="ln">2669 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lcm_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2670"><span class="ln">2670 </span></a><span class="s0">}</span>
<a name="l2671"><span class="ln">2671 </span></a>
<a name="l2672"><span class="ln">2672 </span></a><span class="s3">// aten::index.Tensor(Tensor self, Tensor?[] indices) -&gt; Tensor</span>
<a name="l2673"><span class="ln">2673 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index(</span><span class="s1">const </span><span class="s0">c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2674"><span class="ln">2674 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices);</span>
<a name="l2675"><span class="ln">2675 </span></a><span class="s0">}</span>
<a name="l2676"><span class="ln">2676 </span></a>
<a name="l2677"><span class="ln">2677 </span></a><span class="s3">// aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<a name="l2678"><span class="ln">2678 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_copy_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2679"><span class="ln">2679 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_copy_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source);</span>
<a name="l2680"><span class="ln">2680 </span></a><span class="s0">}</span>
<a name="l2681"><span class="ln">2681 </span></a>
<a name="l2682"><span class="ln">2682 </span></a><span class="s3">// aten::index_copy(Tensor self, int dim, Tensor index, Tensor source) -&gt; Tensor</span>
<a name="l2683"><span class="ln">2683 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_copy(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2684"><span class="ln">2684 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_copy::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source);</span>
<a name="l2685"><span class="ln">2685 </span></a><span class="s0">}</span>
<a name="l2686"><span class="ln">2686 </span></a>
<a name="l2687"><span class="ln">2687 </span></a><span class="s3">// aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<a name="l2688"><span class="ln">2688 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_copy_(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2689"><span class="ln">2689 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_copy__dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source);</span>
<a name="l2690"><span class="ln">2690 </span></a><span class="s0">}</span>
<a name="l2691"><span class="ln">2691 </span></a>
<a name="l2692"><span class="ln">2692 </span></a><span class="s3">// aten::index_copy.dimname(Tensor self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor</span>
<a name="l2693"><span class="ln">2693 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_copy(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2694"><span class="ln">2694 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_copy_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source);</span>
<a name="l2695"><span class="ln">2695 </span></a><span class="s0">}</span>
<a name="l2696"><span class="ln">2696 </span></a>
<a name="l2697"><span class="ln">2697 </span></a><span class="s3">// aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor(a!)</span>
<a name="l2698"><span class="ln">2698 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_put_(</span><span class="s1">const </span><span class="s0">c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; values, </span><span class="s1">bool </span><span class="s0">accumulate) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2699"><span class="ln">2699 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_put_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices, values, accumulate);</span>
<a name="l2700"><span class="ln">2700 </span></a><span class="s0">}</span>
<a name="l2701"><span class="ln">2701 </span></a>
<a name="l2702"><span class="ln">2702 </span></a><span class="s3">// aten::index_put(Tensor self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor</span>
<a name="l2703"><span class="ln">2703 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_put(</span><span class="s1">const </span><span class="s0">c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; values, </span><span class="s1">bool </span><span class="s0">accumulate) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2704"><span class="ln">2704 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_put::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices, values, accumulate);</span>
<a name="l2705"><span class="ln">2705 </span></a><span class="s0">}</span>
<a name="l2706"><span class="ln">2706 </span></a>
<a name="l2707"><span class="ln">2707 </span></a><span class="s3">// aten::isclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; Tensor</span>
<a name="l2708"><span class="ln">2708 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isclose(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">double </span><span class="s0">rtol, </span><span class="s1">double </span><span class="s0">atol, </span><span class="s1">bool </span><span class="s0">equal_nan) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2709"><span class="ln">2709 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isclose::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, rtol, atol, equal_nan);</span>
<a name="l2710"><span class="ln">2710 </span></a><span class="s0">}</span>
<a name="l2711"><span class="ln">2711 </span></a>
<a name="l2712"><span class="ln">2712 </span></a><span class="s3">// aten::isnan(Tensor self) -&gt; Tensor</span>
<a name="l2713"><span class="ln">2713 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isnan() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2714"><span class="ln">2714 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isnan::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2715"><span class="ln">2715 </span></a><span class="s0">}</span>
<a name="l2716"><span class="ln">2716 </span></a>
<a name="l2717"><span class="ln">2717 </span></a><span class="s3">// aten::is_distributed(Tensor self) -&gt; bool</span>
<a name="l2718"><span class="ln">2718 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::is_distributed() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2719"><span class="ln">2719 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_distributed::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2720"><span class="ln">2720 </span></a><span class="s0">}</span>
<a name="l2721"><span class="ln">2721 </span></a>
<a name="l2722"><span class="ln">2722 </span></a><span class="s3">// aten::is_floating_point(Tensor self) -&gt; bool</span>
<a name="l2723"><span class="ln">2723 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_floating_point() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2724"><span class="ln">2724 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_floating_point::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2725"><span class="ln">2725 </span></a><span class="s0">}</span>
<a name="l2726"><span class="ln">2726 </span></a>
<a name="l2727"><span class="ln">2727 </span></a><span class="s3">// aten::is_complex(Tensor self) -&gt; bool</span>
<a name="l2728"><span class="ln">2728 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_complex() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2729"><span class="ln">2729 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_complex::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2730"><span class="ln">2730 </span></a><span class="s0">}</span>
<a name="l2731"><span class="ln">2731 </span></a>
<a name="l2732"><span class="ln">2732 </span></a><span class="s3">// aten::is_conj(Tensor self) -&gt; bool</span>
<a name="l2733"><span class="ln">2733 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_conj() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2734"><span class="ln">2734 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_conj::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2735"><span class="ln">2735 </span></a><span class="s0">}</span>
<a name="l2736"><span class="ln">2736 </span></a>
<a name="l2737"><span class="ln">2737 </span></a><span class="s3">// aten::_is_zerotensor(Tensor self) -&gt; bool</span>
<a name="l2738"><span class="ln">2738 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch__is_zerotensor() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2739"><span class="ln">2739 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_is_zerotensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2740"><span class="ln">2740 </span></a><span class="s0">}</span>
<a name="l2741"><span class="ln">2741 </span></a>
<a name="l2742"><span class="ln">2742 </span></a><span class="s3">// aten::is_neg(Tensor self) -&gt; bool</span>
<a name="l2743"><span class="ln">2743 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_neg() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2744"><span class="ln">2744 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_neg::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2745"><span class="ln">2745 </span></a><span class="s0">}</span>
<a name="l2746"><span class="ln">2746 </span></a>
<a name="l2747"><span class="ln">2747 </span></a><span class="s3">// aten::isreal(Tensor self) -&gt; Tensor</span>
<a name="l2748"><span class="ln">2748 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isreal() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2749"><span class="ln">2749 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isreal::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2750"><span class="ln">2750 </span></a><span class="s0">}</span>
<a name="l2751"><span class="ln">2751 </span></a>
<a name="l2752"><span class="ln">2752 </span></a><span class="s3">// aten::is_nonzero(Tensor self) -&gt; bool</span>
<a name="l2753"><span class="ln">2753 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::is_nonzero() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2754"><span class="ln">2754 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_nonzero::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2755"><span class="ln">2755 </span></a><span class="s0">}</span>
<a name="l2756"><span class="ln">2756 </span></a>
<a name="l2757"><span class="ln">2757 </span></a><span class="s3">// aten::is_same_size(Tensor self, Tensor other) -&gt; bool</span>
<a name="l2758"><span class="ln">2758 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::is_same_size(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2759"><span class="ln">2759 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_same_size::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2760"><span class="ln">2760 </span></a><span class="s0">}</span>
<a name="l2761"><span class="ln">2761 </span></a>
<a name="l2762"><span class="ln">2762 </span></a><span class="s3">// aten::is_signed(Tensor self) -&gt; bool</span>
<a name="l2763"><span class="ln">2763 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_signed() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2764"><span class="ln">2764 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_signed::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2765"><span class="ln">2765 </span></a><span class="s0">}</span>
<a name="l2766"><span class="ln">2766 </span></a>
<a name="l2767"><span class="ln">2767 </span></a><span class="s3">// aten::is_inference(Tensor self) -&gt; bool</span>
<a name="l2768"><span class="ln">2768 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::__dispatch_is_inference() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2769"><span class="ln">2769 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_inference::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2770"><span class="ln">2770 </span></a><span class="s0">}</span>
<a name="l2771"><span class="ln">2771 </span></a>
<a name="l2772"><span class="ln">2772 </span></a><span class="s3">// aten::kron(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2773"><span class="ln">2773 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::kron(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2774"><span class="ln">2774 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::kron::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2775"><span class="ln">2775 </span></a><span class="s0">}</span>
<a name="l2776"><span class="ln">2776 </span></a>
<a name="l2777"><span class="ln">2777 </span></a><span class="s3">// aten::kthvalue(Tensor self, SymInt k, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2778"><span class="ln">2778 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::kthvalue(int64_t k, int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2779"><span class="ln">2779 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::kthvalue::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dim, keepdim);</span>
<a name="l2780"><span class="ln">2780 </span></a><span class="s0">}</span>
<a name="l2781"><span class="ln">2781 </span></a>
<a name="l2782"><span class="ln">2782 </span></a><span class="s3">// aten::kthvalue(Tensor self, SymInt k, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2783"><span class="ln">2783 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::kthvalue_symint(c10::SymInt k, int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2784"><span class="ln">2784 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::kthvalue::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dim, keepdim);</span>
<a name="l2785"><span class="ln">2785 </span></a><span class="s0">}</span>
<a name="l2786"><span class="ln">2786 </span></a>
<a name="l2787"><span class="ln">2787 </span></a><span class="s3">// aten::kthvalue.dimname(Tensor self, SymInt k, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2788"><span class="ln">2788 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::kthvalue(int64_t k, at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2789"><span class="ln">2789 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::kthvalue_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dim, keepdim);</span>
<a name="l2790"><span class="ln">2790 </span></a><span class="s0">}</span>
<a name="l2791"><span class="ln">2791 </span></a>
<a name="l2792"><span class="ln">2792 </span></a><span class="s3">// aten::kthvalue.dimname(Tensor self, SymInt k, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2793"><span class="ln">2793 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::kthvalue_symint(c10::SymInt k, at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2794"><span class="ln">2794 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::kthvalue_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dim, keepdim);</span>
<a name="l2795"><span class="ln">2795 </span></a><span class="s0">}</span>
<a name="l2796"><span class="ln">2796 </span></a>
<a name="l2797"><span class="ln">2797 </span></a><span class="s3">// aten::nan_to_num(Tensor self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor</span>
<a name="l2798"><span class="ln">2798 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nan_to_num(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; nan, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; posinf, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; neginf) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2799"><span class="ln">2799 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nan_to_num::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), nan, posinf, neginf);</span>
<a name="l2800"><span class="ln">2800 </span></a><span class="s0">}</span>
<a name="l2801"><span class="ln">2801 </span></a>
<a name="l2802"><span class="ln">2802 </span></a><span class="s3">// aten::nan_to_num_(Tensor(a!) self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor(a!)</span>
<a name="l2803"><span class="ln">2803 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::nan_to_num_(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; nan, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; posinf, ::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; neginf) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2804"><span class="ln">2804 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nan_to_num_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), nan, posinf, neginf);</span>
<a name="l2805"><span class="ln">2805 </span></a><span class="s0">}</span>
<a name="l2806"><span class="ln">2806 </span></a>
<a name="l2807"><span class="ln">2807 </span></a><span class="s3">// aten::ldexp.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2808"><span class="ln">2808 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ldexp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2809"><span class="ln">2809 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ldexp_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2810"><span class="ln">2810 </span></a><span class="s0">}</span>
<a name="l2811"><span class="ln">2811 </span></a>
<a name="l2812"><span class="ln">2812 </span></a><span class="s3">// aten::ldexp_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2813"><span class="ln">2813 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::ldexp_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2814"><span class="ln">2814 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ldexp_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2815"><span class="ln">2815 </span></a><span class="s0">}</span>
<a name="l2816"><span class="ln">2816 </span></a>
<a name="l2817"><span class="ln">2817 </span></a><span class="s3">// aten::log(Tensor self) -&gt; Tensor</span>
<a name="l2818"><span class="ln">2818 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::log() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2819"><span class="ln">2819 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2820"><span class="ln">2820 </span></a><span class="s0">}</span>
<a name="l2821"><span class="ln">2821 </span></a>
<a name="l2822"><span class="ln">2822 </span></a><span class="s3">// aten::log_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2823"><span class="ln">2823 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::log_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2824"><span class="ln">2824 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2825"><span class="ln">2825 </span></a><span class="s0">}</span>
<a name="l2826"><span class="ln">2826 </span></a>
<a name="l2827"><span class="ln">2827 </span></a><span class="s3">// aten::log10(Tensor self) -&gt; Tensor</span>
<a name="l2828"><span class="ln">2828 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::log10() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2829"><span class="ln">2829 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log10::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2830"><span class="ln">2830 </span></a><span class="s0">}</span>
<a name="l2831"><span class="ln">2831 </span></a>
<a name="l2832"><span class="ln">2832 </span></a><span class="s3">// aten::log10_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2833"><span class="ln">2833 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::log10_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2834"><span class="ln">2834 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log10_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2835"><span class="ln">2835 </span></a><span class="s0">}</span>
<a name="l2836"><span class="ln">2836 </span></a>
<a name="l2837"><span class="ln">2837 </span></a><span class="s3">// aten::log1p(Tensor self) -&gt; Tensor</span>
<a name="l2838"><span class="ln">2838 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::log1p() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2839"><span class="ln">2839 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log1p::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2840"><span class="ln">2840 </span></a><span class="s0">}</span>
<a name="l2841"><span class="ln">2841 </span></a>
<a name="l2842"><span class="ln">2842 </span></a><span class="s3">// aten::log1p_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2843"><span class="ln">2843 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::log1p_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2844"><span class="ln">2844 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log1p_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2845"><span class="ln">2845 </span></a><span class="s0">}</span>
<a name="l2846"><span class="ln">2846 </span></a>
<a name="l2847"><span class="ln">2847 </span></a><span class="s3">// aten::log2(Tensor self) -&gt; Tensor</span>
<a name="l2848"><span class="ln">2848 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::log2() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2849"><span class="ln">2849 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log2::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2850"><span class="ln">2850 </span></a><span class="s0">}</span>
<a name="l2851"><span class="ln">2851 </span></a>
<a name="l2852"><span class="ln">2852 </span></a><span class="s3">// aten::log2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l2853"><span class="ln">2853 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::log2_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2854"><span class="ln">2854 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log2_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2855"><span class="ln">2855 </span></a><span class="s0">}</span>
<a name="l2856"><span class="ln">2856 </span></a>
<a name="l2857"><span class="ln">2857 </span></a><span class="s3">// aten::logaddexp(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2858"><span class="ln">2858 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logaddexp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2859"><span class="ln">2859 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logaddexp::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2860"><span class="ln">2860 </span></a><span class="s0">}</span>
<a name="l2861"><span class="ln">2861 </span></a>
<a name="l2862"><span class="ln">2862 </span></a><span class="s3">// aten::logaddexp2(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2863"><span class="ln">2863 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logaddexp2(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2864"><span class="ln">2864 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logaddexp2::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2865"><span class="ln">2865 </span></a><span class="s0">}</span>
<a name="l2866"><span class="ln">2866 </span></a>
<a name="l2867"><span class="ln">2867 </span></a><span class="s3">// aten::xlogy.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2868"><span class="ln">2868 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::xlogy(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2869"><span class="ln">2869 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::xlogy_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2870"><span class="ln">2870 </span></a><span class="s0">}</span>
<a name="l2871"><span class="ln">2871 </span></a>
<a name="l2872"><span class="ln">2872 </span></a><span class="s3">// aten::xlogy.Scalar_Other(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l2873"><span class="ln">2873 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::xlogy(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2874"><span class="ln">2874 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::xlogy_Scalar_Other::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2875"><span class="ln">2875 </span></a><span class="s0">}</span>
<a name="l2876"><span class="ln">2876 </span></a>
<a name="l2877"><span class="ln">2877 </span></a><span class="s3">// aten::xlogy_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l2878"><span class="ln">2878 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::xlogy_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2879"><span class="ln">2879 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::xlogy__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2880"><span class="ln">2880 </span></a><span class="s0">}</span>
<a name="l2881"><span class="ln">2881 </span></a>
<a name="l2882"><span class="ln">2882 </span></a><span class="s3">// aten::xlogy_.Scalar_Other(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l2883"><span class="ln">2883 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::xlogy_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2884"><span class="ln">2884 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::xlogy__Scalar_Other::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2885"><span class="ln">2885 </span></a><span class="s0">}</span>
<a name="l2886"><span class="ln">2886 </span></a>
<a name="l2887"><span class="ln">2887 </span></a><span class="s3">// aten::log_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2888"><span class="ln">2888 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::log_softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2889"><span class="ln">2889 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log_softmax_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2890"><span class="ln">2890 </span></a><span class="s0">}</span>
<a name="l2891"><span class="ln">2891 </span></a>
<a name="l2892"><span class="ln">2892 </span></a><span class="s3">// aten::log_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2893"><span class="ln">2893 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::log_softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2894"><span class="ln">2894 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log_softmax_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l2895"><span class="ln">2895 </span></a><span class="s0">}</span>
<a name="l2896"><span class="ln">2896 </span></a>
<a name="l2897"><span class="ln">2897 </span></a><span class="s3">// aten::logcumsumexp(Tensor self, int dim) -&gt; Tensor</span>
<a name="l2898"><span class="ln">2898 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logcumsumexp(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2899"><span class="ln">2899 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logcumsumexp::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2900"><span class="ln">2900 </span></a><span class="s0">}</span>
<a name="l2901"><span class="ln">2901 </span></a>
<a name="l2902"><span class="ln">2902 </span></a><span class="s3">// aten::logcumsumexp.dimname(Tensor self, Dimname dim) -&gt; Tensor</span>
<a name="l2903"><span class="ln">2903 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logcumsumexp(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2904"><span class="ln">2904 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logcumsumexp_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l2905"><span class="ln">2905 </span></a><span class="s0">}</span>
<a name="l2906"><span class="ln">2906 </span></a>
<a name="l2907"><span class="ln">2907 </span></a><span class="s3">// aten::logsumexp(Tensor self, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l2908"><span class="ln">2908 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logsumexp(at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2909"><span class="ln">2909 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logsumexp::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2910"><span class="ln">2910 </span></a><span class="s0">}</span>
<a name="l2911"><span class="ln">2911 </span></a>
<a name="l2912"><span class="ln">2912 </span></a><span class="s3">// aten::logsumexp.names(Tensor self, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l2913"><span class="ln">2913 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logsumexp(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2914"><span class="ln">2914 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logsumexp_names::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2915"><span class="ln">2915 </span></a><span class="s0">}</span>
<a name="l2916"><span class="ln">2916 </span></a>
<a name="l2917"><span class="ln">2917 </span></a><span class="s3">// aten::matmul(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l2918"><span class="ln">2918 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::matmul(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2919"><span class="ln">2919 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::matmul::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l2920"><span class="ln">2920 </span></a><span class="s0">}</span>
<a name="l2921"><span class="ln">2921 </span></a>
<a name="l2922"><span class="ln">2922 </span></a><span class="s3">// aten::matrix_power(Tensor self, int n) -&gt; Tensor</span>
<a name="l2923"><span class="ln">2923 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::matrix_power(int64_t n) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2924"><span class="ln">2924 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::matrix_power::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), n);</span>
<a name="l2925"><span class="ln">2925 </span></a><span class="s0">}</span>
<a name="l2926"><span class="ln">2926 </span></a>
<a name="l2927"><span class="ln">2927 </span></a><span class="s3">// aten::matrix_exp(Tensor self) -&gt; Tensor</span>
<a name="l2928"><span class="ln">2928 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::matrix_exp() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2929"><span class="ln">2929 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::matrix_exp::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2930"><span class="ln">2930 </span></a><span class="s0">}</span>
<a name="l2931"><span class="ln">2931 </span></a>
<a name="l2932"><span class="ln">2932 </span></a><span class="s3">// aten::aminmax(Tensor self, *, int? dim=None, bool keepdim=False) -&gt; (Tensor min, Tensor max)</span>
<a name="l2933"><span class="ln">2933 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::aminmax(::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2934"><span class="ln">2934 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::aminmax::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2935"><span class="ln">2935 </span></a><span class="s0">}</span>
<a name="l2936"><span class="ln">2936 </span></a>
<a name="l2937"><span class="ln">2937 </span></a><span class="s3">// aten::max.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2938"><span class="ln">2938 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::max(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2939"><span class="ln">2939 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::max_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2940"><span class="ln">2940 </span></a><span class="s0">}</span>
<a name="l2941"><span class="ln">2941 </span></a>
<a name="l2942"><span class="ln">2942 </span></a><span class="s3">// aten::max.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2943"><span class="ln">2943 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::max(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2944"><span class="ln">2944 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::max_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2945"><span class="ln">2945 </span></a><span class="s0">}</span>
<a name="l2946"><span class="ln">2946 </span></a>
<a name="l2947"><span class="ln">2947 </span></a><span class="s3">// aten::amax(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<a name="l2948"><span class="ln">2948 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::amax(at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2949"><span class="ln">2949 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::amax::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2950"><span class="ln">2950 </span></a><span class="s0">}</span>
<a name="l2951"><span class="ln">2951 </span></a>
<a name="l2952"><span class="ln">2952 </span></a><span class="s3">// aten::mean(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2953"><span class="ln">2953 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mean(::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2954"><span class="ln">2954 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mean::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype);</span>
<a name="l2955"><span class="ln">2955 </span></a><span class="s0">}</span>
<a name="l2956"><span class="ln">2956 </span></a>
<a name="l2957"><span class="ln">2957 </span></a><span class="s3">// aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2958"><span class="ln">2958 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mean(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2959"><span class="ln">2959 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mean_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l2960"><span class="ln">2960 </span></a><span class="s0">}</span>
<a name="l2961"><span class="ln">2961 </span></a>
<a name="l2962"><span class="ln">2962 </span></a><span class="s3">// aten::mean.names_dim(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2963"><span class="ln">2963 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mean(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2964"><span class="ln">2964 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mean_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l2965"><span class="ln">2965 </span></a><span class="s0">}</span>
<a name="l2966"><span class="ln">2966 </span></a>
<a name="l2967"><span class="ln">2967 </span></a><span class="s3">// aten::nanmean(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l2968"><span class="ln">2968 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nanmean(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2969"><span class="ln">2969 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nanmean::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l2970"><span class="ln">2970 </span></a><span class="s0">}</span>
<a name="l2971"><span class="ln">2971 </span></a>
<a name="l2972"><span class="ln">2972 </span></a><span class="s3">// aten::median(Tensor self) -&gt; Tensor</span>
<a name="l2973"><span class="ln">2973 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::median() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2974"><span class="ln">2974 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::median::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2975"><span class="ln">2975 </span></a><span class="s0">}</span>
<a name="l2976"><span class="ln">2976 </span></a>
<a name="l2977"><span class="ln">2977 </span></a><span class="s3">// aten::median.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2978"><span class="ln">2978 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::median(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2979"><span class="ln">2979 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::median_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2980"><span class="ln">2980 </span></a><span class="s0">}</span>
<a name="l2981"><span class="ln">2981 </span></a>
<a name="l2982"><span class="ln">2982 </span></a><span class="s3">// aten::median.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2983"><span class="ln">2983 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::median(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2984"><span class="ln">2984 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::median_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2985"><span class="ln">2985 </span></a><span class="s0">}</span>
<a name="l2986"><span class="ln">2986 </span></a>
<a name="l2987"><span class="ln">2987 </span></a><span class="s3">// aten::nanmedian(Tensor self) -&gt; Tensor</span>
<a name="l2988"><span class="ln">2988 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nanmedian() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2989"><span class="ln">2989 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nanmedian::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l2990"><span class="ln">2990 </span></a><span class="s0">}</span>
<a name="l2991"><span class="ln">2991 </span></a>
<a name="l2992"><span class="ln">2992 </span></a><span class="s3">// aten::nanmedian.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2993"><span class="ln">2993 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::nanmedian(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2994"><span class="ln">2994 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nanmedian_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l2995"><span class="ln">2995 </span></a><span class="s0">}</span>
<a name="l2996"><span class="ln">2996 </span></a>
<a name="l2997"><span class="ln">2997 </span></a><span class="s3">// aten::nanmedian.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l2998"><span class="ln">2998 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::nanmedian(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l2999"><span class="ln">2999 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nanmedian_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l3000"><span class="ln">3000 </span></a><span class="s0">}</span>
<a name="l3001"><span class="ln">3001 </span></a>
<a name="l3002"><span class="ln">3002 </span></a><span class="s3">// aten::min.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l3003"><span class="ln">3003 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::min(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3004"><span class="ln">3004 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::min_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l3005"><span class="ln">3005 </span></a><span class="s0">}</span>
<a name="l3006"><span class="ln">3006 </span></a>
<a name="l3007"><span class="ln">3007 </span></a><span class="s3">// aten::min.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l3008"><span class="ln">3008 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::min(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3009"><span class="ln">3009 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::min_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l3010"><span class="ln">3010 </span></a><span class="s0">}</span>
<a name="l3011"><span class="ln">3011 </span></a>
<a name="l3012"><span class="ln">3012 </span></a><span class="s3">// aten::amin(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<a name="l3013"><span class="ln">3013 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::amin(at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3014"><span class="ln">3014 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::amin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l3015"><span class="ln">3015 </span></a><span class="s0">}</span>
<a name="l3016"><span class="ln">3016 </span></a>
<a name="l3017"><span class="ln">3017 </span></a><span class="s3">// aten::mm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<a name="l3018"><span class="ln">3018 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3019"><span class="ln">3019 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat2);</span>
<a name="l3020"><span class="ln">3020 </span></a><span class="s0">}</span>
<a name="l3021"><span class="ln">3021 </span></a>
<a name="l3022"><span class="ln">3022 </span></a><span class="s3">// aten::mode(Tensor self, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l3023"><span class="ln">3023 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::mode(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3024"><span class="ln">3024 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mode::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l3025"><span class="ln">3025 </span></a><span class="s0">}</span>
<a name="l3026"><span class="ln">3026 </span></a>
<a name="l3027"><span class="ln">3027 </span></a><span class="s3">// aten::mode.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l3028"><span class="ln">3028 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::mode(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3029"><span class="ln">3029 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mode_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim);</span>
<a name="l3030"><span class="ln">3030 </span></a><span class="s0">}</span>
<a name="l3031"><span class="ln">3031 </span></a>
<a name="l3032"><span class="ln">3032 </span></a><span class="s3">// aten::mul.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l3033"><span class="ln">3033 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mul(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3034"><span class="ln">3034 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mul_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3035"><span class="ln">3035 </span></a><span class="s0">}</span>
<a name="l3036"><span class="ln">3036 </span></a>
<a name="l3037"><span class="ln">3037 </span></a><span class="s3">// aten::mul_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l3038"><span class="ln">3038 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::mul_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3039"><span class="ln">3039 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mul__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3040"><span class="ln">3040 </span></a><span class="s0">}</span>
<a name="l3041"><span class="ln">3041 </span></a>
<a name="l3042"><span class="ln">3042 </span></a><span class="s3">// aten::mul.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l3043"><span class="ln">3043 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mul(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3044"><span class="ln">3044 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mul_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3045"><span class="ln">3045 </span></a><span class="s0">}</span>
<a name="l3046"><span class="ln">3046 </span></a>
<a name="l3047"><span class="ln">3047 </span></a><span class="s3">// aten::mul_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l3048"><span class="ln">3048 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::mul_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3049"><span class="ln">3049 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mul__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3050"><span class="ln">3050 </span></a><span class="s0">}</span>
<a name="l3051"><span class="ln">3051 </span></a>
<a name="l3052"><span class="ln">3052 </span></a><span class="s3">// aten::multiply.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l3053"><span class="ln">3053 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::multiply(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3054"><span class="ln">3054 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::multiply_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3055"><span class="ln">3055 </span></a><span class="s0">}</span>
<a name="l3056"><span class="ln">3056 </span></a>
<a name="l3057"><span class="ln">3057 </span></a><span class="s3">// aten::multiply_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l3058"><span class="ln">3058 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::multiply_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3059"><span class="ln">3059 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::multiply__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3060"><span class="ln">3060 </span></a><span class="s0">}</span>
<a name="l3061"><span class="ln">3061 </span></a>
<a name="l3062"><span class="ln">3062 </span></a><span class="s3">// aten::multiply.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l3063"><span class="ln">3063 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::multiply(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3064"><span class="ln">3064 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::multiply_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3065"><span class="ln">3065 </span></a><span class="s0">}</span>
<a name="l3066"><span class="ln">3066 </span></a>
<a name="l3067"><span class="ln">3067 </span></a><span class="s3">// aten::multiply_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l3068"><span class="ln">3068 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::multiply_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3069"><span class="ln">3069 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::multiply__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3070"><span class="ln">3070 </span></a><span class="s0">}</span>
<a name="l3071"><span class="ln">3071 </span></a>
<a name="l3072"><span class="ln">3072 </span></a><span class="s3">// aten::mv(Tensor self, Tensor vec) -&gt; Tensor</span>
<a name="l3073"><span class="ln">3073 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mv(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3074"><span class="ln">3074 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mv::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), vec);</span>
<a name="l3075"><span class="ln">3075 </span></a><span class="s0">}</span>
<a name="l3076"><span class="ln">3076 </span></a>
<a name="l3077"><span class="ln">3077 </span></a><span class="s3">// aten::mvlgamma(Tensor self, int p) -&gt; Tensor</span>
<a name="l3078"><span class="ln">3078 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mvlgamma(int64_t p) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3079"><span class="ln">3079 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mvlgamma::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p);</span>
<a name="l3080"><span class="ln">3080 </span></a><span class="s0">}</span>
<a name="l3081"><span class="ln">3081 </span></a>
<a name="l3082"><span class="ln">3082 </span></a><span class="s3">// aten::mvlgamma_(Tensor(a!) self, int p) -&gt; Tensor(a!)</span>
<a name="l3083"><span class="ln">3083 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::mvlgamma_(int64_t p) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3084"><span class="ln">3084 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mvlgamma_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p);</span>
<a name="l3085"><span class="ln">3085 </span></a><span class="s0">}</span>
<a name="l3086"><span class="ln">3086 </span></a>
<a name="l3087"><span class="ln">3087 </span></a><span class="s3">// aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -&gt; Tensor</span>
<a name="l3088"><span class="ln">3088 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::narrow_copy(int64_t dim, int64_t start, int64_t length) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3089"><span class="ln">3089 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::narrow_copy::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, length);</span>
<a name="l3090"><span class="ln">3090 </span></a><span class="s0">}</span>
<a name="l3091"><span class="ln">3091 </span></a>
<a name="l3092"><span class="ln">3092 </span></a><span class="s3">// aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -&gt; Tensor</span>
<a name="l3093"><span class="ln">3093 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3094"><span class="ln">3094 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::narrow_copy::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, length);</span>
<a name="l3095"><span class="ln">3095 </span></a><span class="s0">}</span>
<a name="l3096"><span class="ln">3096 </span></a>
<a name="l3097"><span class="ln">3097 </span></a><span class="s3">// aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -&gt; Tensor(a)</span>
<a name="l3098"><span class="ln">3098 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::narrow(int64_t dim, int64_t start, int64_t length) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3099"><span class="ln">3099 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::narrow::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, length);</span>
<a name="l3100"><span class="ln">3100 </span></a><span class="s0">}</span>
<a name="l3101"><span class="ln">3101 </span></a>
<a name="l3102"><span class="ln">3102 </span></a><span class="s3">// aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -&gt; Tensor(a)</span>
<a name="l3103"><span class="ln">3103 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::narrow_symint(int64_t dim, c10::SymInt start, c10::SymInt length) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3104"><span class="ln">3104 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::narrow::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, length);</span>
<a name="l3105"><span class="ln">3105 </span></a><span class="s0">}</span>
<a name="l3106"><span class="ln">3106 </span></a>
<a name="l3107"><span class="ln">3107 </span></a><span class="s3">// aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -&gt; Tensor(a)</span>
<a name="l3108"><span class="ln">3108 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::narrow(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; start, int64_t length) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3109"><span class="ln">3109 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::narrow_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, length);</span>
<a name="l3110"><span class="ln">3110 </span></a><span class="s0">}</span>
<a name="l3111"><span class="ln">3111 </span></a>
<a name="l3112"><span class="ln">3112 </span></a><span class="s3">// aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -&gt; Tensor(a)</span>
<a name="l3113"><span class="ln">3113 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::narrow_symint(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; start, c10::SymInt length) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3114"><span class="ln">3114 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::narrow_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, length);</span>
<a name="l3115"><span class="ln">3115 </span></a><span class="s0">}</span>
<a name="l3116"><span class="ln">3116 </span></a>
<a name="l3117"><span class="ln">3117 </span></a><span class="s3">// aten::permute(Tensor(a) self, int[] dims) -&gt; Tensor(a)</span>
<a name="l3118"><span class="ln">3118 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::permute(at::IntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3119"><span class="ln">3119 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::permute::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dims);</span>
<a name="l3120"><span class="ln">3120 </span></a><span class="s0">}</span>
<a name="l3121"><span class="ln">3121 </span></a>
<a name="l3122"><span class="ln">3122 </span></a><span class="s3">// aten::movedim.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<a name="l3123"><span class="ln">3123 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::movedim(at::IntArrayRef source, at::IntArrayRef destination) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3124"><span class="ln">3124 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::movedim_intlist::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, destination);</span>
<a name="l3125"><span class="ln">3125 </span></a><span class="s0">}</span>
<a name="l3126"><span class="ln">3126 </span></a>
<a name="l3127"><span class="ln">3127 </span></a><span class="s3">// aten::movedim.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<a name="l3128"><span class="ln">3128 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::movedim(int64_t source, int64_t destination) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3129"><span class="ln">3129 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::movedim_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, destination);</span>
<a name="l3130"><span class="ln">3130 </span></a><span class="s0">}</span>
<a name="l3131"><span class="ln">3131 </span></a>
<a name="l3132"><span class="ln">3132 </span></a><span class="s3">// aten::moveaxis.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<a name="l3133"><span class="ln">3133 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::moveaxis(at::IntArrayRef source, at::IntArrayRef destination) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3134"><span class="ln">3134 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::moveaxis_intlist::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, destination);</span>
<a name="l3135"><span class="ln">3135 </span></a><span class="s0">}</span>
<a name="l3136"><span class="ln">3136 </span></a>
<a name="l3137"><span class="ln">3137 </span></a><span class="s3">// aten::moveaxis.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<a name="l3138"><span class="ln">3138 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::moveaxis(int64_t source, int64_t destination) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3139"><span class="ln">3139 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::moveaxis_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, destination);</span>
<a name="l3140"><span class="ln">3140 </span></a><span class="s0">}</span>
<a name="l3141"><span class="ln">3141 </span></a>
<a name="l3142"><span class="ln">3142 </span></a><span class="s3">// aten::numpy_T(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3143"><span class="ln">3143 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::numpy_T() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3144"><span class="ln">3144 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::numpy_T::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3145"><span class="ln">3145 </span></a><span class="s0">}</span>
<a name="l3146"><span class="ln">3146 </span></a>
<a name="l3147"><span class="ln">3147 </span></a><span class="s3">// aten::matrix_H(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3148"><span class="ln">3148 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::matrix_H() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3149"><span class="ln">3149 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::matrix_H::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3150"><span class="ln">3150 </span></a><span class="s0">}</span>
<a name="l3151"><span class="ln">3151 </span></a>
<a name="l3152"><span class="ln">3152 </span></a><span class="s3">// aten::mT(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3153"><span class="ln">3153 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mT() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3154"><span class="ln">3154 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mT::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3155"><span class="ln">3155 </span></a><span class="s0">}</span>
<a name="l3156"><span class="ln">3156 </span></a>
<a name="l3157"><span class="ln">3157 </span></a><span class="s3">// aten::mH(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3158"><span class="ln">3158 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::mH() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3159"><span class="ln">3159 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::mH::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3160"><span class="ln">3160 </span></a><span class="s0">}</span>
<a name="l3161"><span class="ln">3161 </span></a>
<a name="l3162"><span class="ln">3162 </span></a><span class="s3">// aten::adjoint(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3163"><span class="ln">3163 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::adjoint() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3164"><span class="ln">3164 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::adjoint::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3165"><span class="ln">3165 </span></a><span class="s0">}</span>
<a name="l3166"><span class="ln">3166 </span></a>
<a name="l3167"><span class="ln">3167 </span></a><span class="s3">// aten::is_pinned(Tensor self, Device? device=None) -&gt; bool</span>
<a name="l3168"><span class="ln">3168 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::is_pinned(::std::optional&lt;at::Device&gt; device) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3169"><span class="ln">3169 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_pinned::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), device);</span>
<a name="l3170"><span class="ln">3170 </span></a><span class="s0">}</span>
<a name="l3171"><span class="ln">3171 </span></a>
<a name="l3172"><span class="ln">3172 </span></a><span class="s3">// aten::pin_memory(Tensor(a) self, Device? device=None) -&gt; Tensor(a)</span>
<a name="l3173"><span class="ln">3173 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::pin_memory(::std::optional&lt;at::Device&gt; device) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3174"><span class="ln">3174 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::pin_memory::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), device);</span>
<a name="l3175"><span class="ln">3175 </span></a><span class="s0">}</span>
<a name="l3176"><span class="ln">3176 </span></a>
<a name="l3177"><span class="ln">3177 </span></a><span class="s3">// aten::pinverse(Tensor self, float rcond=1e-15) -&gt; Tensor</span>
<a name="l3178"><span class="ln">3178 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::pinverse(</span><span class="s1">double </span><span class="s0">rcond) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3179"><span class="ln">3179 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::pinverse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), rcond);</span>
<a name="l3180"><span class="ln">3180 </span></a><span class="s0">}</span>
<a name="l3181"><span class="ln">3181 </span></a>
<a name="l3182"><span class="ln">3182 </span></a><span class="s3">// aten::rad2deg(Tensor self) -&gt; Tensor</span>
<a name="l3183"><span class="ln">3183 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::rad2deg() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3184"><span class="ln">3184 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rad2deg::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3185"><span class="ln">3185 </span></a><span class="s0">}</span>
<a name="l3186"><span class="ln">3186 </span></a>
<a name="l3187"><span class="ln">3187 </span></a><span class="s3">// aten::rad2deg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3188"><span class="ln">3188 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::rad2deg_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3189"><span class="ln">3189 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rad2deg_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3190"><span class="ln">3190 </span></a><span class="s0">}</span>
<a name="l3191"><span class="ln">3191 </span></a>
<a name="l3192"><span class="ln">3192 </span></a><span class="s3">// aten::deg2rad(Tensor self) -&gt; Tensor</span>
<a name="l3193"><span class="ln">3193 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::deg2rad() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3194"><span class="ln">3194 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::deg2rad::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3195"><span class="ln">3195 </span></a><span class="s0">}</span>
<a name="l3196"><span class="ln">3196 </span></a>
<a name="l3197"><span class="ln">3197 </span></a><span class="s3">// aten::deg2rad_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3198"><span class="ln">3198 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::deg2rad_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3199"><span class="ln">3199 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::deg2rad_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3200"><span class="ln">3200 </span></a><span class="s0">}</span>
<a name="l3201"><span class="ln">3201 </span></a>
<a name="l3202"><span class="ln">3202 </span></a><span class="s3">// aten::ravel(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3203"><span class="ln">3203 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ravel() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3204"><span class="ln">3204 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ravel::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3205"><span class="ln">3205 </span></a><span class="s0">}</span>
<a name="l3206"><span class="ln">3206 </span></a>
<a name="l3207"><span class="ln">3207 </span></a><span class="s3">// aten::reciprocal(Tensor self) -&gt; Tensor</span>
<a name="l3208"><span class="ln">3208 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::reciprocal() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3209"><span class="ln">3209 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::reciprocal::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3210"><span class="ln">3210 </span></a><span class="s0">}</span>
<a name="l3211"><span class="ln">3211 </span></a>
<a name="l3212"><span class="ln">3212 </span></a><span class="s3">// aten::reciprocal_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3213"><span class="ln">3213 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::reciprocal_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3214"><span class="ln">3214 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::reciprocal_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3215"><span class="ln">3215 </span></a><span class="s0">}</span>
<a name="l3216"><span class="ln">3216 </span></a>
<a name="l3217"><span class="ln">3217 </span></a><span class="s3">// aten::neg(Tensor self) -&gt; Tensor</span>
<a name="l3218"><span class="ln">3218 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::neg() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3219"><span class="ln">3219 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::neg::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3220"><span class="ln">3220 </span></a><span class="s0">}</span>
<a name="l3221"><span class="ln">3221 </span></a>
<a name="l3222"><span class="ln">3222 </span></a><span class="s3">// aten::neg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3223"><span class="ln">3223 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::neg_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3224"><span class="ln">3224 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::neg_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3225"><span class="ln">3225 </span></a><span class="s0">}</span>
<a name="l3226"><span class="ln">3226 </span></a>
<a name="l3227"><span class="ln">3227 </span></a><span class="s3">// aten::negative(Tensor self) -&gt; Tensor</span>
<a name="l3228"><span class="ln">3228 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::negative() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3229"><span class="ln">3229 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::negative::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3230"><span class="ln">3230 </span></a><span class="s0">}</span>
<a name="l3231"><span class="ln">3231 </span></a>
<a name="l3232"><span class="ln">3232 </span></a><span class="s3">// aten::negative_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3233"><span class="ln">3233 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::negative_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3234"><span class="ln">3234 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::negative_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3235"><span class="ln">3235 </span></a><span class="s0">}</span>
<a name="l3236"><span class="ln">3236 </span></a>
<a name="l3237"><span class="ln">3237 </span></a><span class="s3">// aten::repeat(Tensor self, SymInt[] repeats) -&gt; Tensor</span>
<a name="l3238"><span class="ln">3238 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::repeat(at::IntArrayRef repeats) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3239"><span class="ln">3239 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::repeat::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(repeats));</span>
<a name="l3240"><span class="ln">3240 </span></a><span class="s0">}</span>
<a name="l3241"><span class="ln">3241 </span></a>
<a name="l3242"><span class="ln">3242 </span></a><span class="s3">// aten::repeat(Tensor self, SymInt[] repeats) -&gt; Tensor</span>
<a name="l3243"><span class="ln">3243 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::repeat_symint(c10::SymIntArrayRef repeats) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3244"><span class="ln">3244 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::repeat::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), repeats);</span>
<a name="l3245"><span class="ln">3245 </span></a><span class="s0">}</span>
<a name="l3246"><span class="ln">3246 </span></a>
<a name="l3247"><span class="ln">3247 </span></a><span class="s3">// aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<a name="l3248"><span class="ln">3248 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::repeat_interleave(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;int64_t&gt; output_size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3249"><span class="ln">3249 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::repeat_interleave_self_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), repeats, dim, output_size.has_value() ? ::std::make_optional(c10::SymInt(*output_size)) : ::std::nullopt);</span>
<a name="l3250"><span class="ln">3250 </span></a><span class="s0">}</span>
<a name="l3251"><span class="ln">3251 </span></a>
<a name="l3252"><span class="ln">3252 </span></a><span class="s3">// aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<a name="l3253"><span class="ln">3253 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::repeat_interleave_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;c10::SymInt&gt; output_size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3254"><span class="ln">3254 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::repeat_interleave_self_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), repeats, dim, output_size);</span>
<a name="l3255"><span class="ln">3255 </span></a><span class="s0">}</span>
<a name="l3256"><span class="ln">3256 </span></a>
<a name="l3257"><span class="ln">3257 </span></a><span class="s3">// aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<a name="l3258"><span class="ln">3258 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::repeat_interleave(int64_t repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;int64_t&gt; output_size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3259"><span class="ln">3259 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::repeat_interleave_self_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), repeats, dim, output_size.has_value() ? ::std::make_optional(c10::SymInt(*output_size)) : ::std::nullopt);</span>
<a name="l3260"><span class="ln">3260 </span></a><span class="s0">}</span>
<a name="l3261"><span class="ln">3261 </span></a>
<a name="l3262"><span class="ln">3262 </span></a><span class="s3">// aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<a name="l3263"><span class="ln">3263 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::repeat_interleave_symint(c10::SymInt repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;c10::SymInt&gt; output_size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3264"><span class="ln">3264 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::repeat_interleave_self_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), repeats, dim, output_size);</span>
<a name="l3265"><span class="ln">3265 </span></a><span class="s0">}</span>
<a name="l3266"><span class="ln">3266 </span></a>
<a name="l3267"><span class="ln">3267 </span></a><span class="s3">// aten::reshape(Tensor(a) self, SymInt[] shape) -&gt; Tensor(a)</span>
<a name="l3268"><span class="ln">3268 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::reshape(at::IntArrayRef shape) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3269"><span class="ln">3269 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::reshape::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(shape));</span>
<a name="l3270"><span class="ln">3270 </span></a><span class="s0">}</span>
<a name="l3271"><span class="ln">3271 </span></a>
<a name="l3272"><span class="ln">3272 </span></a><span class="s3">// aten::reshape(Tensor(a) self, SymInt[] shape) -&gt; Tensor(a)</span>
<a name="l3273"><span class="ln">3273 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::reshape_symint(c10::SymIntArrayRef shape) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3274"><span class="ln">3274 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::reshape::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), shape);</span>
<a name="l3275"><span class="ln">3275 </span></a><span class="s0">}</span>
<a name="l3276"><span class="ln">3276 </span></a>
<a name="l3277"><span class="ln">3277 </span></a><span class="s3">// aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -&gt; Tensor(a)</span>
<a name="l3278"><span class="ln">3278 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_reshape_alias(at::IntArrayRef size, at::IntArrayRef stride) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3279"><span class="ln">3279 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_reshape_alias::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride));</span>
<a name="l3280"><span class="ln">3280 </span></a><span class="s0">}</span>
<a name="l3281"><span class="ln">3281 </span></a>
<a name="l3282"><span class="ln">3282 </span></a><span class="s3">// aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -&gt; Tensor(a)</span>
<a name="l3283"><span class="ln">3283 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_reshape_alias_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3284"><span class="ln">3284 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_reshape_alias::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, stride);</span>
<a name="l3285"><span class="ln">3285 </span></a><span class="s0">}</span>
<a name="l3286"><span class="ln">3286 </span></a>
<a name="l3287"><span class="ln">3287 </span></a><span class="s3">// aten::reshape_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<a name="l3288"><span class="ln">3288 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::reshape_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3289"><span class="ln">3289 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::reshape_as::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3290"><span class="ln">3290 </span></a><span class="s0">}</span>
<a name="l3291"><span class="ln">3291 </span></a>
<a name="l3292"><span class="ln">3292 </span></a><span class="s3">// aten::round(Tensor self) -&gt; Tensor</span>
<a name="l3293"><span class="ln">3293 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::round() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3294"><span class="ln">3294 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::round::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3295"><span class="ln">3295 </span></a><span class="s0">}</span>
<a name="l3296"><span class="ln">3296 </span></a>
<a name="l3297"><span class="ln">3297 </span></a><span class="s3">// aten::round_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3298"><span class="ln">3298 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::round_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3299"><span class="ln">3299 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::round_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3300"><span class="ln">3300 </span></a><span class="s0">}</span>
<a name="l3301"><span class="ln">3301 </span></a>
<a name="l3302"><span class="ln">3302 </span></a><span class="s3">// aten::round.decimals(Tensor self, *, int decimals) -&gt; Tensor</span>
<a name="l3303"><span class="ln">3303 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::round(int64_t decimals) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3304"><span class="ln">3304 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::round_decimals::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), decimals);</span>
<a name="l3305"><span class="ln">3305 </span></a><span class="s0">}</span>
<a name="l3306"><span class="ln">3306 </span></a>
<a name="l3307"><span class="ln">3307 </span></a><span class="s3">// aten::round_.decimals(Tensor(a!) self, *, int decimals) -&gt; Tensor(a!)</span>
<a name="l3308"><span class="ln">3308 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::round_(int64_t decimals) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3309"><span class="ln">3309 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::round__decimals::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), decimals);</span>
<a name="l3310"><span class="ln">3310 </span></a><span class="s0">}</span>
<a name="l3311"><span class="ln">3311 </span></a>
<a name="l3312"><span class="ln">3312 </span></a><span class="s3">// aten::relu(Tensor self) -&gt; Tensor</span>
<a name="l3313"><span class="ln">3313 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::relu() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3314"><span class="ln">3314 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::relu::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3315"><span class="ln">3315 </span></a><span class="s0">}</span>
<a name="l3316"><span class="ln">3316 </span></a>
<a name="l3317"><span class="ln">3317 </span></a><span class="s3">// aten::relu_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3318"><span class="ln">3318 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::relu_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3319"><span class="ln">3319 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::relu_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3320"><span class="ln">3320 </span></a><span class="s0">}</span>
<a name="l3321"><span class="ln">3321 </span></a>
<a name="l3322"><span class="ln">3322 </span></a><span class="s3">// aten::prelu(Tensor self, Tensor weight) -&gt; Tensor</span>
<a name="l3323"><span class="ln">3323 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::prelu(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; weight) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3324"><span class="ln">3324 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::prelu::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), weight);</span>
<a name="l3325"><span class="ln">3325 </span></a><span class="s0">}</span>
<a name="l3326"><span class="ln">3326 </span></a>
<a name="l3327"><span class="ln">3327 </span></a><span class="s3">// aten::hardshrink(Tensor self, Scalar lambd=0.5) -&gt; Tensor</span>
<a name="l3328"><span class="ln">3328 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::hardshrink(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; lambd) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3329"><span class="ln">3329 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::hardshrink::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), lambd);</span>
<a name="l3330"><span class="ln">3330 </span></a><span class="s0">}</span>
<a name="l3331"><span class="ln">3331 </span></a>
<a name="l3332"><span class="ln">3332 </span></a><span class="s3">// aten::hardshrink_backward(Tensor grad_out, Tensor self, Scalar lambd) -&gt; Tensor</span>
<a name="l3333"><span class="ln">3333 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::hardshrink_backward(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; grad_out, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; lambd) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3334"><span class="ln">3334 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::hardshrink_backward::call(grad_out, </span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), lambd);</span>
<a name="l3335"><span class="ln">3335 </span></a><span class="s0">}</span>
<a name="l3336"><span class="ln">3336 </span></a>
<a name="l3337"><span class="ln">3337 </span></a><span class="s3">// aten::rsqrt(Tensor self) -&gt; Tensor</span>
<a name="l3338"><span class="ln">3338 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::rsqrt() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3339"><span class="ln">3339 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rsqrt::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3340"><span class="ln">3340 </span></a><span class="s0">}</span>
<a name="l3341"><span class="ln">3341 </span></a>
<a name="l3342"><span class="ln">3342 </span></a><span class="s3">// aten::rsqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3343"><span class="ln">3343 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::rsqrt_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3344"><span class="ln">3344 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rsqrt_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3345"><span class="ln">3345 </span></a><span class="s0">}</span>
<a name="l3346"><span class="ln">3346 </span></a>
<a name="l3347"><span class="ln">3347 </span></a><span class="s3">// aten::select.Dimname(Tensor(a) self, Dimname dim, int index) -&gt; Tensor(a)</span>
<a name="l3348"><span class="ln">3348 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::select(at::Dimname dim, int64_t index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3349"><span class="ln">3349 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::select_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index);</span>
<a name="l3350"><span class="ln">3350 </span></a><span class="s0">}</span>
<a name="l3351"><span class="ln">3351 </span></a>
<a name="l3352"><span class="ln">3352 </span></a><span class="s3">// aten::select.int(Tensor(a) self, int dim, SymInt index) -&gt; Tensor(a)</span>
<a name="l3353"><span class="ln">3353 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::select(int64_t dim, int64_t index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3354"><span class="ln">3354 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::select_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index);</span>
<a name="l3355"><span class="ln">3355 </span></a><span class="s0">}</span>
<a name="l3356"><span class="ln">3356 </span></a>
<a name="l3357"><span class="ln">3357 </span></a><span class="s3">// aten::select.int(Tensor(a) self, int dim, SymInt index) -&gt; Tensor(a)</span>
<a name="l3358"><span class="ln">3358 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::select_symint(int64_t dim, c10::SymInt index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3359"><span class="ln">3359 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::select_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index);</span>
<a name="l3360"><span class="ln">3360 </span></a><span class="s0">}</span>
<a name="l3361"><span class="ln">3361 </span></a>
<a name="l3362"><span class="ln">3362 </span></a><span class="s3">// aten::sigmoid(Tensor self) -&gt; Tensor</span>
<a name="l3363"><span class="ln">3363 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sigmoid() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3364"><span class="ln">3364 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sigmoid::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3365"><span class="ln">3365 </span></a><span class="s0">}</span>
<a name="l3366"><span class="ln">3366 </span></a>
<a name="l3367"><span class="ln">3367 </span></a><span class="s3">// aten::sigmoid_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3368"><span class="ln">3368 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sigmoid_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3369"><span class="ln">3369 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sigmoid_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3370"><span class="ln">3370 </span></a><span class="s0">}</span>
<a name="l3371"><span class="ln">3371 </span></a>
<a name="l3372"><span class="ln">3372 </span></a><span class="s3">// aten::logit(Tensor self, float? eps=None) -&gt; Tensor</span>
<a name="l3373"><span class="ln">3373 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logit(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; eps) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3374"><span class="ln">3374 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logit::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), eps);</span>
<a name="l3375"><span class="ln">3375 </span></a><span class="s0">}</span>
<a name="l3376"><span class="ln">3376 </span></a>
<a name="l3377"><span class="ln">3377 </span></a><span class="s3">// aten::logit_(Tensor(a!) self, float? eps=None) -&gt; Tensor(a!)</span>
<a name="l3378"><span class="ln">3378 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::logit_(::std::optional&lt;</span><span class="s1">double</span><span class="s0">&gt; eps) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3379"><span class="ln">3379 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logit_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), eps);</span>
<a name="l3380"><span class="ln">3380 </span></a><span class="s0">}</span>
<a name="l3381"><span class="ln">3381 </span></a>
<a name="l3382"><span class="ln">3382 </span></a><span class="s3">// aten::sin(Tensor self) -&gt; Tensor</span>
<a name="l3383"><span class="ln">3383 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sin() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3384"><span class="ln">3384 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3385"><span class="ln">3385 </span></a><span class="s0">}</span>
<a name="l3386"><span class="ln">3386 </span></a>
<a name="l3387"><span class="ln">3387 </span></a><span class="s3">// aten::sin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3388"><span class="ln">3388 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sin_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3389"><span class="ln">3389 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sin_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3390"><span class="ln">3390 </span></a><span class="s0">}</span>
<a name="l3391"><span class="ln">3391 </span></a>
<a name="l3392"><span class="ln">3392 </span></a><span class="s3">// aten::sinc(Tensor self) -&gt; Tensor</span>
<a name="l3393"><span class="ln">3393 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sinc() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3394"><span class="ln">3394 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sinc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3395"><span class="ln">3395 </span></a><span class="s0">}</span>
<a name="l3396"><span class="ln">3396 </span></a>
<a name="l3397"><span class="ln">3397 </span></a><span class="s3">// aten::sinc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3398"><span class="ln">3398 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sinc_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3399"><span class="ln">3399 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sinc_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3400"><span class="ln">3400 </span></a><span class="s0">}</span>
<a name="l3401"><span class="ln">3401 </span></a>
<a name="l3402"><span class="ln">3402 </span></a><span class="s3">// aten::sinh(Tensor self) -&gt; Tensor</span>
<a name="l3403"><span class="ln">3403 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sinh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3404"><span class="ln">3404 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sinh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3405"><span class="ln">3405 </span></a><span class="s0">}</span>
<a name="l3406"><span class="ln">3406 </span></a>
<a name="l3407"><span class="ln">3407 </span></a><span class="s3">// aten::sinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3408"><span class="ln">3408 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sinh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3409"><span class="ln">3409 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sinh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3410"><span class="ln">3410 </span></a><span class="s0">}</span>
<a name="l3411"><span class="ln">3411 </span></a>
<a name="l3412"><span class="ln">3412 </span></a><span class="s3">// aten::detach(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3413"><span class="ln">3413 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::detach() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3414"><span class="ln">3414 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::detach::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3415"><span class="ln">3415 </span></a><span class="s0">}</span>
<a name="l3416"><span class="ln">3416 </span></a>
<a name="l3417"><span class="ln">3417 </span></a><span class="s3">// aten::detach_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3418"><span class="ln">3418 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::detach_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3419"><span class="ln">3419 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::detach_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3420"><span class="ln">3420 </span></a><span class="s0">}</span>
<a name="l3421"><span class="ln">3421 </span></a>
<a name="l3422"><span class="ln">3422 </span></a><span class="s3">// aten::size.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<a name="l3423"><span class="ln">3423 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::size(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3424"><span class="ln">3424 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::size_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3425"><span class="ln">3425 </span></a><span class="s0">}</span>
<a name="l3426"><span class="ln">3426 </span></a>
<a name="l3427"><span class="ln">3427 </span></a><span class="s3">// aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<a name="l3428"><span class="ln">3428 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::slice(int64_t dim, ::std::optional&lt;int64_t&gt; start, ::std::optional&lt;int64_t&gt; end, int64_t step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3429"><span class="ln">3429 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slice_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step);</span>
<a name="l3430"><span class="ln">3430 </span></a><span class="s0">}</span>
<a name="l3431"><span class="ln">3431 </span></a>
<a name="l3432"><span class="ln">3432 </span></a><span class="s3">// aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<a name="l3433"><span class="ln">3433 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::slice_symint(int64_t dim, ::std::optional&lt;c10::SymInt&gt; start, ::std::optional&lt;c10::SymInt&gt; end, c10::SymInt step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3434"><span class="ln">3434 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slice_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, start, end, step);</span>
<a name="l3435"><span class="ln">3435 </span></a><span class="s0">}</span>
<a name="l3436"><span class="ln">3436 </span></a>
<a name="l3437"><span class="ln">3437 </span></a><span class="s3">// aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<a name="l3438"><span class="ln">3438 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::slice_inverse(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, ::std::optional&lt;int64_t&gt; start, ::std::optional&lt;int64_t&gt; end, int64_t step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3439"><span class="ln">3439 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slice_inverse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step);</span>
<a name="l3440"><span class="ln">3440 </span></a><span class="s0">}</span>
<a name="l3441"><span class="ln">3441 </span></a>
<a name="l3442"><span class="ln">3442 </span></a><span class="s3">// aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<a name="l3443"><span class="ln">3443 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::slice_inverse_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, ::std::optional&lt;c10::SymInt&gt; start, ::std::optional&lt;c10::SymInt&gt; end, c10::SymInt step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3444"><span class="ln">3444 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slice_inverse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, dim, start, end, step);</span>
<a name="l3445"><span class="ln">3445 </span></a><span class="s0">}</span>
<a name="l3446"><span class="ln">3446 </span></a>
<a name="l3447"><span class="ln">3447 </span></a><span class="s3">// aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor</span>
<a name="l3448"><span class="ln">3448 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::slice_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, ::std::optional&lt;int64_t&gt; start, ::std::optional&lt;int64_t&gt; end, int64_t step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3449"><span class="ln">3449 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slice_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step);</span>
<a name="l3450"><span class="ln">3450 </span></a><span class="s0">}</span>
<a name="l3451"><span class="ln">3451 </span></a>
<a name="l3452"><span class="ln">3452 </span></a><span class="s3">// aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor</span>
<a name="l3453"><span class="ln">3453 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::slice_scatter_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, ::std::optional&lt;c10::SymInt&gt; start, ::std::optional&lt;c10::SymInt&gt; end, c10::SymInt step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3454"><span class="ln">3454 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slice_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, dim, start, end, step);</span>
<a name="l3455"><span class="ln">3455 </span></a><span class="s0">}</span>
<a name="l3456"><span class="ln">3456 </span></a>
<a name="l3457"><span class="ln">3457 </span></a><span class="s3">// aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -&gt; Tensor</span>
<a name="l3458"><span class="ln">3458 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::select_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, int64_t index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3459"><span class="ln">3459 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::select_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, dim, index);</span>
<a name="l3460"><span class="ln">3460 </span></a><span class="s0">}</span>
<a name="l3461"><span class="ln">3461 </span></a>
<a name="l3462"><span class="ln">3462 </span></a><span class="s3">// aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -&gt; Tensor</span>
<a name="l3463"><span class="ln">3463 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::select_scatter_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t dim, c10::SymInt index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3464"><span class="ln">3464 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::select_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, dim, index);</span>
<a name="l3465"><span class="ln">3465 </span></a><span class="s0">}</span>
<a name="l3466"><span class="ln">3466 </span></a>
<a name="l3467"><span class="ln">3467 </span></a><span class="s3">// aten::diagonal_scatter(Tensor self, Tensor src, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor</span>
<a name="l3468"><span class="ln">3468 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diagonal_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, int64_t offset, int64_t dim1, int64_t dim2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3469"><span class="ln">3469 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diagonal_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, offset, dim1, dim2);</span>
<a name="l3470"><span class="ln">3470 </span></a><span class="s0">}</span>
<a name="l3471"><span class="ln">3471 </span></a>
<a name="l3472"><span class="ln">3472 </span></a><span class="s3">// aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor</span>
<a name="l3473"><span class="ln">3473 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::as_strided_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3474"><span class="ln">3474 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::as_strided_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt);</span>
<a name="l3475"><span class="ln">3475 </span></a><span class="s0">}</span>
<a name="l3476"><span class="ln">3476 </span></a>
<a name="l3477"><span class="ln">3477 </span></a><span class="s3">// aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor</span>
<a name="l3478"><span class="ln">3478 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::as_strided_scatter_symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3479"><span class="ln">3479 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::as_strided_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), src, size, stride, storage_offset);</span>
<a name="l3480"><span class="ln">3480 </span></a><span class="s0">}</span>
<a name="l3481"><span class="ln">3481 </span></a>
<a name="l3482"><span class="ln">3482 </span></a><span class="s3">// aten::smm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<a name="l3483"><span class="ln">3483 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::smm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3484"><span class="ln">3484 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::smm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat2);</span>
<a name="l3485"><span class="ln">3485 </span></a><span class="s0">}</span>
<a name="l3486"><span class="ln">3486 </span></a>
<a name="l3487"><span class="ln">3487 </span></a><span class="s3">// aten::softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3488"><span class="ln">3488 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3489"><span class="ln">3489 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::softmax_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l3490"><span class="ln">3490 </span></a><span class="s0">}</span>
<a name="l3491"><span class="ln">3491 </span></a>
<a name="l3492"><span class="ln">3492 </span></a><span class="s3">// aten::softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3493"><span class="ln">3493 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3494"><span class="ln">3494 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::softmax_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, dtype);</span>
<a name="l3495"><span class="ln">3495 </span></a><span class="s0">}</span>
<a name="l3496"><span class="ln">3496 </span></a>
<a name="l3497"><span class="ln">3497 </span></a><span class="s3">// aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -&gt; Tensor[]</span>
<a name="l3498"><span class="ln">3498 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split(int64_t split_size, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3499"><span class="ln">3499 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsafe_split_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_size, dim);</span>
<a name="l3500"><span class="ln">3500 </span></a><span class="s0">}</span>
<a name="l3501"><span class="ln">3501 </span></a>
<a name="l3502"><span class="ln">3502 </span></a><span class="s3">// aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -&gt; Tensor[]</span>
<a name="l3503"><span class="ln">3503 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split_symint(c10::SymInt split_size, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3504"><span class="ln">3504 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsafe_split_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_size, dim);</span>
<a name="l3505"><span class="ln">3505 </span></a><span class="s0">}</span>
<a name="l3506"><span class="ln">3506 </span></a>
<a name="l3507"><span class="ln">3507 </span></a><span class="s3">// aten::split.Tensor(Tensor(a -&gt; *) self, SymInt split_size, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l3508"><span class="ln">3508 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::split(int64_t split_size, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3509"><span class="ln">3509 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::split_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_size, dim);</span>
<a name="l3510"><span class="ln">3510 </span></a><span class="s0">}</span>
<a name="l3511"><span class="ln">3511 </span></a>
<a name="l3512"><span class="ln">3512 </span></a><span class="s3">// aten::split.Tensor(Tensor(a -&gt; *) self, SymInt split_size, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l3513"><span class="ln">3513 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::split_symint(c10::SymInt split_size, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3514"><span class="ln">3514 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::split_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_size, dim);</span>
<a name="l3515"><span class="ln">3515 </span></a><span class="s0">}</span>
<a name="l3516"><span class="ln">3516 </span></a>
<a name="l3517"><span class="ln">3517 </span></a><span class="s3">// aten::split.sizes(Tensor(a -&gt; *) self, SymInt[] split_size, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l3518"><span class="ln">3518 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::split(at::IntArrayRef split_size, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3519"><span class="ln">3519 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::split_sizes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(split_size), dim);</span>
<a name="l3520"><span class="ln">3520 </span></a><span class="s0">}</span>
<a name="l3521"><span class="ln">3521 </span></a>
<a name="l3522"><span class="ln">3522 </span></a><span class="s3">// aten::split.sizes(Tensor(a -&gt; *) self, SymInt[] split_size, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l3523"><span class="ln">3523 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::split_symint(c10::SymIntArrayRef split_size, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3524"><span class="ln">3524 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::split_sizes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_size, dim);</span>
<a name="l3525"><span class="ln">3525 </span></a><span class="s0">}</span>
<a name="l3526"><span class="ln">3526 </span></a>
<a name="l3527"><span class="ln">3527 </span></a><span class="s3">// aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<a name="l3528"><span class="ln">3528 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split_with_sizes(at::IntArrayRef split_sizes, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3529"><span class="ln">3529 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsafe_split_with_sizes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(split_sizes), dim);</span>
<a name="l3530"><span class="ln">3530 </span></a><span class="s0">}</span>
<a name="l3531"><span class="ln">3531 </span></a>
<a name="l3532"><span class="ln">3532 </span></a><span class="s3">// aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<a name="l3533"><span class="ln">3533 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3534"><span class="ln">3534 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsafe_split_with_sizes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_sizes, dim);</span>
<a name="l3535"><span class="ln">3535 </span></a><span class="s0">}</span>
<a name="l3536"><span class="ln">3536 </span></a>
<a name="l3537"><span class="ln">3537 </span></a><span class="s3">// aten::split_with_sizes(Tensor(a -&gt; *) self, SymInt[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l3538"><span class="ln">3538 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::split_with_sizes(at::IntArrayRef split_sizes, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3539"><span class="ln">3539 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::split_with_sizes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(split_sizes), dim);</span>
<a name="l3540"><span class="ln">3540 </span></a><span class="s0">}</span>
<a name="l3541"><span class="ln">3541 </span></a>
<a name="l3542"><span class="ln">3542 </span></a><span class="s3">// aten::split_with_sizes(Tensor(a -&gt; *) self, SymInt[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l3543"><span class="ln">3543 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3544"><span class="ln">3544 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::split_with_sizes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), split_sizes, dim);</span>
<a name="l3545"><span class="ln">3545 </span></a><span class="s0">}</span>
<a name="l3546"><span class="ln">3546 </span></a>
<a name="l3547"><span class="ln">3547 </span></a><span class="s3">// aten::hsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<a name="l3548"><span class="ln">3548 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::hsplit(int64_t sections) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3549"><span class="ln">3549 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::hsplit_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sections);</span>
<a name="l3550"><span class="ln">3550 </span></a><span class="s0">}</span>
<a name="l3551"><span class="ln">3551 </span></a>
<a name="l3552"><span class="ln">3552 </span></a><span class="s3">// aten::hsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<a name="l3553"><span class="ln">3553 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::hsplit(at::IntArrayRef indices) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3554"><span class="ln">3554 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::hsplit_array::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices);</span>
<a name="l3555"><span class="ln">3555 </span></a><span class="s0">}</span>
<a name="l3556"><span class="ln">3556 </span></a>
<a name="l3557"><span class="ln">3557 </span></a><span class="s3">// aten::vsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<a name="l3558"><span class="ln">3558 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::vsplit(int64_t sections) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3559"><span class="ln">3559 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::vsplit_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sections);</span>
<a name="l3560"><span class="ln">3560 </span></a><span class="s0">}</span>
<a name="l3561"><span class="ln">3561 </span></a>
<a name="l3562"><span class="ln">3562 </span></a><span class="s3">// aten::vsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<a name="l3563"><span class="ln">3563 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::vsplit(at::IntArrayRef indices) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3564"><span class="ln">3564 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::vsplit_array::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices);</span>
<a name="l3565"><span class="ln">3565 </span></a><span class="s0">}</span>
<a name="l3566"><span class="ln">3566 </span></a>
<a name="l3567"><span class="ln">3567 </span></a><span class="s3">// aten::dsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<a name="l3568"><span class="ln">3568 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::dsplit(int64_t sections) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3569"><span class="ln">3569 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::dsplit_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sections);</span>
<a name="l3570"><span class="ln">3570 </span></a><span class="s0">}</span>
<a name="l3571"><span class="ln">3571 </span></a>
<a name="l3572"><span class="ln">3572 </span></a><span class="s3">// aten::dsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<a name="l3573"><span class="ln">3573 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::dsplit(at::IntArrayRef indices) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3574"><span class="ln">3574 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::dsplit_array::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices);</span>
<a name="l3575"><span class="ln">3575 </span></a><span class="s0">}</span>
<a name="l3576"><span class="ln">3576 </span></a>
<a name="l3577"><span class="ln">3577 </span></a><span class="s3">// aten::squeeze(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3578"><span class="ln">3578 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::squeeze() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3579"><span class="ln">3579 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3580"><span class="ln">3580 </span></a><span class="s0">}</span>
<a name="l3581"><span class="ln">3581 </span></a>
<a name="l3582"><span class="ln">3582 </span></a><span class="s3">// aten::squeeze.dim(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<a name="l3583"><span class="ln">3583 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::squeeze(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3584"><span class="ln">3584 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3585"><span class="ln">3585 </span></a><span class="s0">}</span>
<a name="l3586"><span class="ln">3586 </span></a>
<a name="l3587"><span class="ln">3587 </span></a><span class="s3">// aten::squeeze.dimname(Tensor(a) self, Dimname dim) -&gt; Tensor(a)</span>
<a name="l3588"><span class="ln">3588 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::squeeze(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3589"><span class="ln">3589 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3590"><span class="ln">3590 </span></a><span class="s0">}</span>
<a name="l3591"><span class="ln">3591 </span></a>
<a name="l3592"><span class="ln">3592 </span></a><span class="s3">// aten::squeeze.dims(Tensor(a) self, int[] dim) -&gt; Tensor(a)</span>
<a name="l3593"><span class="ln">3593 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::squeeze(at::IntArrayRef dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3594"><span class="ln">3594 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze_dims::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3595"><span class="ln">3595 </span></a><span class="s0">}</span>
<a name="l3596"><span class="ln">3596 </span></a>
<a name="l3597"><span class="ln">3597 </span></a><span class="s3">// aten::squeeze_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3598"><span class="ln">3598 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::squeeze_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3599"><span class="ln">3599 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3600"><span class="ln">3600 </span></a><span class="s0">}</span>
<a name="l3601"><span class="ln">3601 </span></a>
<a name="l3602"><span class="ln">3602 </span></a><span class="s3">// aten::squeeze_.dim(Tensor(a!) self, int dim) -&gt; Tensor(a!)</span>
<a name="l3603"><span class="ln">3603 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::squeeze_(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3604"><span class="ln">3604 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze__dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3605"><span class="ln">3605 </span></a><span class="s0">}</span>
<a name="l3606"><span class="ln">3606 </span></a>
<a name="l3607"><span class="ln">3607 </span></a><span class="s3">// aten::squeeze_.dims(Tensor(a!) self, int[] dim) -&gt; Tensor(a!)</span>
<a name="l3608"><span class="ln">3608 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::squeeze_(at::IntArrayRef dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3609"><span class="ln">3609 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze__dims::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3610"><span class="ln">3610 </span></a><span class="s0">}</span>
<a name="l3611"><span class="ln">3611 </span></a>
<a name="l3612"><span class="ln">3612 </span></a><span class="s3">// aten::squeeze_.dimname(Tensor(a!) self, Dimname dim) -&gt; Tensor(a!)</span>
<a name="l3613"><span class="ln">3613 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::squeeze_(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3614"><span class="ln">3614 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::squeeze__dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3615"><span class="ln">3615 </span></a><span class="s0">}</span>
<a name="l3616"><span class="ln">3616 </span></a>
<a name="l3617"><span class="ln">3617 </span></a><span class="s3">// aten::sspaddmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<a name="l3618"><span class="ln">3618 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sspaddmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3619"><span class="ln">3619 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sspaddmm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat1, mat2, beta, alpha);</span>
<a name="l3620"><span class="ln">3620 </span></a><span class="s0">}</span>
<a name="l3621"><span class="ln">3621 </span></a>
<a name="l3622"><span class="ln">3622 </span></a><span class="s3">// aten::stft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool normalized=False, bool? onesided=None, bool? return_complex=None, bool? align_to_window=None) -&gt; Tensor</span>
<a name="l3623"><span class="ln">3623 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; window, </span><span class="s1">bool </span><span class="s0">normalized, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; onesided, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; return_complex, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; align_to_window) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3624"><span class="ln">3624 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::stft::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), n_fft, hop_length, win_length, window, normalized, onesided, return_complex, align_to_window);</span>
<a name="l3625"><span class="ln">3625 </span></a><span class="s0">}</span>
<a name="l3626"><span class="ln">3626 </span></a>
<a name="l3627"><span class="ln">3627 </span></a><span class="s3">// aten::stft.center(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, str pad_mode=&quot;reflect&quot;, bool normalized=False, bool? onesided=None, bool? return_complex=None, bool? align_to_window=None) -&gt; Tensor</span>
<a name="l3628"><span class="ln">3628 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; window, </span><span class="s1">bool </span><span class="s0">center, c10::string_view pad_mode, </span><span class="s1">bool </span><span class="s0">normalized, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; onesided, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; return_complex, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; align_to_window) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3629"><span class="ln">3629 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::stft_center::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex, align_to_window);</span>
<a name="l3630"><span class="ln">3630 </span></a><span class="s0">}</span>
<a name="l3631"><span class="ln">3631 </span></a>
<a name="l3632"><span class="ln">3632 </span></a><span class="s3">// aten::istft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, bool normalized=False, bool? onesided=None, int? length=None, bool return_complex=False) -&gt; Tensor</span>
<a name="l3633"><span class="ln">3633 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::istft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; window, </span><span class="s1">bool </span><span class="s0">center, </span><span class="s1">bool </span><span class="s0">normalized, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; onesided, ::std::optional&lt;int64_t&gt; length, </span><span class="s1">bool </span><span class="s0">return_complex) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3634"><span class="ln">3634 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::istft::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), n_fft, hop_length, win_length, window, center, normalized, onesided, length, return_complex);</span>
<a name="l3635"><span class="ln">3635 </span></a><span class="s0">}</span>
<a name="l3636"><span class="ln">3636 </span></a>
<a name="l3637"><span class="ln">3637 </span></a><span class="s3">// aten::stride.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<a name="l3638"><span class="ln">3638 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::stride(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3639"><span class="ln">3639 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::stride_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3640"><span class="ln">3640 </span></a><span class="s0">}</span>
<a name="l3641"><span class="ln">3641 </span></a>
<a name="l3642"><span class="ln">3642 </span></a><span class="s3">// aten::sum(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3643"><span class="ln">3643 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sum(::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3644"><span class="ln">3644 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sum::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype);</span>
<a name="l3645"><span class="ln">3645 </span></a><span class="s0">}</span>
<a name="l3646"><span class="ln">3646 </span></a>
<a name="l3647"><span class="ln">3647 </span></a><span class="s3">// aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3648"><span class="ln">3648 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sum(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3649"><span class="ln">3649 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sum_dim_IntList::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l3650"><span class="ln">3650 </span></a><span class="s0">}</span>
<a name="l3651"><span class="ln">3651 </span></a>
<a name="l3652"><span class="ln">3652 </span></a><span class="s3">// aten::sum.dim_DimnameList(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3653"><span class="ln">3653 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sum(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3654"><span class="ln">3654 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sum_dim_DimnameList::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l3655"><span class="ln">3655 </span></a><span class="s0">}</span>
<a name="l3656"><span class="ln">3656 </span></a>
<a name="l3657"><span class="ln">3657 </span></a><span class="s3">// aten::nansum(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3658"><span class="ln">3658 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nansum(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3659"><span class="ln">3659 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nansum::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l3660"><span class="ln">3660 </span></a><span class="s0">}</span>
<a name="l3661"><span class="ln">3661 </span></a>
<a name="l3662"><span class="ln">3662 </span></a><span class="s3">// aten::sum_to_size(Tensor self, SymInt[] size) -&gt; Tensor</span>
<a name="l3663"><span class="ln">3663 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sum_to_size(at::IntArrayRef size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3664"><span class="ln">3664 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sum_to_size::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size));</span>
<a name="l3665"><span class="ln">3665 </span></a><span class="s0">}</span>
<a name="l3666"><span class="ln">3666 </span></a>
<a name="l3667"><span class="ln">3667 </span></a><span class="s3">// aten::sum_to_size(Tensor self, SymInt[] size) -&gt; Tensor</span>
<a name="l3668"><span class="ln">3668 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sum_to_size_symint(c10::SymIntArrayRef size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3669"><span class="ln">3669 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sum_to_size::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size);</span>
<a name="l3670"><span class="ln">3670 </span></a><span class="s0">}</span>
<a name="l3671"><span class="ln">3671 </span></a>
<a name="l3672"><span class="ln">3672 </span></a><span class="s3">// aten::sqrt(Tensor self) -&gt; Tensor</span>
<a name="l3673"><span class="ln">3673 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sqrt() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3674"><span class="ln">3674 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sqrt::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3675"><span class="ln">3675 </span></a><span class="s0">}</span>
<a name="l3676"><span class="ln">3676 </span></a>
<a name="l3677"><span class="ln">3677 </span></a><span class="s3">// aten::sqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3678"><span class="ln">3678 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sqrt_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3679"><span class="ln">3679 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sqrt_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3680"><span class="ln">3680 </span></a><span class="s0">}</span>
<a name="l3681"><span class="ln">3681 </span></a>
<a name="l3682"><span class="ln">3682 </span></a><span class="s3">// aten::square(Tensor self) -&gt; Tensor</span>
<a name="l3683"><span class="ln">3683 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::square() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3684"><span class="ln">3684 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::square::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3685"><span class="ln">3685 </span></a><span class="s0">}</span>
<a name="l3686"><span class="ln">3686 </span></a>
<a name="l3687"><span class="ln">3687 </span></a><span class="s3">// aten::square_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3688"><span class="ln">3688 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::square_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3689"><span class="ln">3689 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::square_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3690"><span class="ln">3690 </span></a><span class="s0">}</span>
<a name="l3691"><span class="ln">3691 </span></a>
<a name="l3692"><span class="ln">3692 </span></a><span class="s3">// aten::std(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<a name="l3693"><span class="ln">3693 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::std(</span><span class="s1">bool </span><span class="s0">unbiased) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3694"><span class="ln">3694 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::std::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), unbiased);</span>
<a name="l3695"><span class="ln">3695 </span></a><span class="s0">}</span>
<a name="l3696"><span class="ln">3696 </span></a>
<a name="l3697"><span class="ln">3697 </span></a><span class="s3">// aten::std.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<a name="l3698"><span class="ln">3698 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::std(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3699"><span class="ln">3699 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::std_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, unbiased, keepdim);</span>
<a name="l3700"><span class="ln">3700 </span></a><span class="s0">}</span>
<a name="l3701"><span class="ln">3701 </span></a>
<a name="l3702"><span class="ln">3702 </span></a><span class="s3">// aten::std.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l3703"><span class="ln">3703 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::std(at::OptionalIntArrayRef dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3704"><span class="ln">3704 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::std_correction::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, correction, keepdim);</span>
<a name="l3705"><span class="ln">3705 </span></a><span class="s0">}</span>
<a name="l3706"><span class="ln">3706 </span></a>
<a name="l3707"><span class="ln">3707 </span></a><span class="s3">// aten::std.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<a name="l3708"><span class="ln">3708 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::std(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3709"><span class="ln">3709 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::std_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, unbiased, keepdim);</span>
<a name="l3710"><span class="ln">3710 </span></a><span class="s0">}</span>
<a name="l3711"><span class="ln">3711 </span></a>
<a name="l3712"><span class="ln">3712 </span></a><span class="s3">// aten::std.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l3713"><span class="ln">3713 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::std(at::DimnameList dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3714"><span class="ln">3714 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::std_correction_names::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, correction, keepdim);</span>
<a name="l3715"><span class="ln">3715 </span></a><span class="s0">}</span>
<a name="l3716"><span class="ln">3716 </span></a>
<a name="l3717"><span class="ln">3717 </span></a><span class="s3">// aten::prod(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3718"><span class="ln">3718 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::prod(::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3719"><span class="ln">3719 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::prod::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype);</span>
<a name="l3720"><span class="ln">3720 </span></a><span class="s0">}</span>
<a name="l3721"><span class="ln">3721 </span></a>
<a name="l3722"><span class="ln">3722 </span></a><span class="s3">// aten::prod.dim_int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3723"><span class="ln">3723 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::prod(int64_t dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3724"><span class="ln">3724 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::prod_dim_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l3725"><span class="ln">3725 </span></a><span class="s0">}</span>
<a name="l3726"><span class="ln">3726 </span></a>
<a name="l3727"><span class="ln">3727 </span></a><span class="s3">// aten::prod.dim_Dimname(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l3728"><span class="ln">3728 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::prod(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3729"><span class="ln">3729 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::prod_dim_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, keepdim, dtype);</span>
<a name="l3730"><span class="ln">3730 </span></a><span class="s0">}</span>
<a name="l3731"><span class="ln">3731 </span></a>
<a name="l3732"><span class="ln">3732 </span></a><span class="s3">// aten::t(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3733"><span class="ln">3733 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::t() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3734"><span class="ln">3734 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::t::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3735"><span class="ln">3735 </span></a><span class="s0">}</span>
<a name="l3736"><span class="ln">3736 </span></a>
<a name="l3737"><span class="ln">3737 </span></a><span class="s3">// aten::t_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3738"><span class="ln">3738 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::t_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3739"><span class="ln">3739 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::t_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3740"><span class="ln">3740 </span></a><span class="s0">}</span>
<a name="l3741"><span class="ln">3741 </span></a>
<a name="l3742"><span class="ln">3742 </span></a><span class="s3">// aten::tan(Tensor self) -&gt; Tensor</span>
<a name="l3743"><span class="ln">3743 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::tan() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3744"><span class="ln">3744 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tan::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3745"><span class="ln">3745 </span></a><span class="s0">}</span>
<a name="l3746"><span class="ln">3746 </span></a>
<a name="l3747"><span class="ln">3747 </span></a><span class="s3">// aten::tan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3748"><span class="ln">3748 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::tan_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3749"><span class="ln">3749 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tan_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3750"><span class="ln">3750 </span></a><span class="s0">}</span>
<a name="l3751"><span class="ln">3751 </span></a>
<a name="l3752"><span class="ln">3752 </span></a><span class="s3">// aten::tanh(Tensor self) -&gt; Tensor</span>
<a name="l3753"><span class="ln">3753 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::tanh() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3754"><span class="ln">3754 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tanh::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3755"><span class="ln">3755 </span></a><span class="s0">}</span>
<a name="l3756"><span class="ln">3756 </span></a>
<a name="l3757"><span class="ln">3757 </span></a><span class="s3">// aten::tanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3758"><span class="ln">3758 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::tanh_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3759"><span class="ln">3759 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tanh_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3760"><span class="ln">3760 </span></a><span class="s0">}</span>
<a name="l3761"><span class="ln">3761 </span></a>
<a name="l3762"><span class="ln">3762 </span></a><span class="s3">// aten::tile(Tensor self, SymInt[] dims) -&gt; Tensor</span>
<a name="l3763"><span class="ln">3763 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::tile(at::IntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3764"><span class="ln">3764 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tile::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(dims));</span>
<a name="l3765"><span class="ln">3765 </span></a><span class="s0">}</span>
<a name="l3766"><span class="ln">3766 </span></a>
<a name="l3767"><span class="ln">3767 </span></a><span class="s3">// aten::tile(Tensor self, SymInt[] dims) -&gt; Tensor</span>
<a name="l3768"><span class="ln">3768 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::tile_symint(c10::SymIntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3769"><span class="ln">3769 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tile::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dims);</span>
<a name="l3770"><span class="ln">3770 </span></a><span class="s0">}</span>
<a name="l3771"><span class="ln">3771 </span></a>
<a name="l3772"><span class="ln">3772 </span></a><span class="s3">// aten::transpose.int(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<a name="l3773"><span class="ln">3773 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::transpose(int64_t dim0, int64_t dim1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3774"><span class="ln">3774 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::transpose_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim0, dim1);</span>
<a name="l3775"><span class="ln">3775 </span></a><span class="s0">}</span>
<a name="l3776"><span class="ln">3776 </span></a>
<a name="l3777"><span class="ln">3777 </span></a><span class="s3">// aten::transpose.Dimname(Tensor(a) self, Dimname dim0, Dimname dim1) -&gt; Tensor(a)</span>
<a name="l3778"><span class="ln">3778 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::transpose(at::Dimname dim0, at::Dimname dim1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3779"><span class="ln">3779 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::transpose_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim0, dim1);</span>
<a name="l3780"><span class="ln">3780 </span></a><span class="s0">}</span>
<a name="l3781"><span class="ln">3781 </span></a>
<a name="l3782"><span class="ln">3782 </span></a><span class="s3">// aten::transpose_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<a name="l3783"><span class="ln">3783 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::transpose_(int64_t dim0, int64_t dim1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3784"><span class="ln">3784 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::transpose_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim0, dim1);</span>
<a name="l3785"><span class="ln">3785 </span></a><span class="s0">}</span>
<a name="l3786"><span class="ln">3786 </span></a>
<a name="l3787"><span class="ln">3787 </span></a><span class="s3">// aten::flip(Tensor self, int[] dims) -&gt; Tensor</span>
<a name="l3788"><span class="ln">3788 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::flip(at::IntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3789"><span class="ln">3789 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::flip::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dims);</span>
<a name="l3790"><span class="ln">3790 </span></a><span class="s0">}</span>
<a name="l3791"><span class="ln">3791 </span></a>
<a name="l3792"><span class="ln">3792 </span></a><span class="s3">// aten::fliplr(Tensor self) -&gt; Tensor</span>
<a name="l3793"><span class="ln">3793 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::fliplr() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3794"><span class="ln">3794 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fliplr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3795"><span class="ln">3795 </span></a><span class="s0">}</span>
<a name="l3796"><span class="ln">3796 </span></a>
<a name="l3797"><span class="ln">3797 </span></a><span class="s3">// aten::flipud(Tensor self) -&gt; Tensor</span>
<a name="l3798"><span class="ln">3798 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::flipud() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3799"><span class="ln">3799 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::flipud::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3800"><span class="ln">3800 </span></a><span class="s0">}</span>
<a name="l3801"><span class="ln">3801 </span></a>
<a name="l3802"><span class="ln">3802 </span></a><span class="s3">// aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<a name="l3803"><span class="ln">3803 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::roll(at::IntArrayRef shifts, at::IntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3804"><span class="ln">3804 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::roll::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(shifts), dims);</span>
<a name="l3805"><span class="ln">3805 </span></a><span class="s0">}</span>
<a name="l3806"><span class="ln">3806 </span></a>
<a name="l3807"><span class="ln">3807 </span></a><span class="s3">// aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<a name="l3808"><span class="ln">3808 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::roll_symint(c10::SymIntArrayRef shifts, at::IntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3809"><span class="ln">3809 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::roll::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), shifts, dims);</span>
<a name="l3810"><span class="ln">3810 </span></a><span class="s0">}</span>
<a name="l3811"><span class="ln">3811 </span></a>
<a name="l3812"><span class="ln">3812 </span></a><span class="s3">// aten::rot90(Tensor self, int k=1, int[] dims=[0,1]) -&gt; Tensor</span>
<a name="l3813"><span class="ln">3813 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::rot90(int64_t k, at::IntArrayRef dims) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3814"><span class="ln">3814 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::rot90::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dims);</span>
<a name="l3815"><span class="ln">3815 </span></a><span class="s0">}</span>
<a name="l3816"><span class="ln">3816 </span></a>
<a name="l3817"><span class="ln">3817 </span></a><span class="s3">// aten::_nested_tensor_size(Tensor self) -&gt; Tensor</span>
<a name="l3818"><span class="ln">3818 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_nested_tensor_size() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3819"><span class="ln">3819 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_nested_tensor_size::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3820"><span class="ln">3820 </span></a><span class="s0">}</span>
<a name="l3821"><span class="ln">3821 </span></a>
<a name="l3822"><span class="ln">3822 </span></a><span class="s3">// aten::_nested_tensor_strides(Tensor self) -&gt; Tensor</span>
<a name="l3823"><span class="ln">3823 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_nested_tensor_strides() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3824"><span class="ln">3824 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_nested_tensor_strides::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3825"><span class="ln">3825 </span></a><span class="s0">}</span>
<a name="l3826"><span class="ln">3826 </span></a>
<a name="l3827"><span class="ln">3827 </span></a><span class="s3">// aten::_nested_tensor_storage_offsets(Tensor self) -&gt; Tensor</span>
<a name="l3828"><span class="ln">3828 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_nested_tensor_storage_offsets() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3829"><span class="ln">3829 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_nested_tensor_storage_offsets::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3830"><span class="ln">3830 </span></a><span class="s0">}</span>
<a name="l3831"><span class="ln">3831 </span></a>
<a name="l3832"><span class="ln">3832 </span></a><span class="s3">// aten::trunc(Tensor self) -&gt; Tensor</span>
<a name="l3833"><span class="ln">3833 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::trunc() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3834"><span class="ln">3834 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::trunc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3835"><span class="ln">3835 </span></a><span class="s0">}</span>
<a name="l3836"><span class="ln">3836 </span></a>
<a name="l3837"><span class="ln">3837 </span></a><span class="s3">// aten::trunc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3838"><span class="ln">3838 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::trunc_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3839"><span class="ln">3839 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::trunc_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3840"><span class="ln">3840 </span></a><span class="s0">}</span>
<a name="l3841"><span class="ln">3841 </span></a>
<a name="l3842"><span class="ln">3842 </span></a><span class="s3">// aten::fix(Tensor self) -&gt; Tensor</span>
<a name="l3843"><span class="ln">3843 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::fix() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3844"><span class="ln">3844 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fix::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3845"><span class="ln">3845 </span></a><span class="s0">}</span>
<a name="l3846"><span class="ln">3846 </span></a>
<a name="l3847"><span class="ln">3847 </span></a><span class="s3">// aten::fix_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3848"><span class="ln">3848 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::fix_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3849"><span class="ln">3849 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fix_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3850"><span class="ln">3850 </span></a><span class="s0">}</span>
<a name="l3851"><span class="ln">3851 </span></a>
<a name="l3852"><span class="ln">3852 </span></a><span class="s3">// aten::type_as(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l3853"><span class="ln">3853 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::type_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3854"><span class="ln">3854 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::type_as::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3855"><span class="ln">3855 </span></a><span class="s0">}</span>
<a name="l3856"><span class="ln">3856 </span></a>
<a name="l3857"><span class="ln">3857 </span></a><span class="s3">// aten::unsqueeze(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<a name="l3858"><span class="ln">3858 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::unsqueeze(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3859"><span class="ln">3859 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsqueeze::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3860"><span class="ln">3860 </span></a><span class="s0">}</span>
<a name="l3861"><span class="ln">3861 </span></a>
<a name="l3862"><span class="ln">3862 </span></a><span class="s3">// aten::unsqueeze_(Tensor(a!) self, int dim) -&gt; Tensor(a!)</span>
<a name="l3863"><span class="ln">3863 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::unsqueeze_(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3864"><span class="ln">3864 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unsqueeze_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l3865"><span class="ln">3865 </span></a><span class="s0">}</span>
<a name="l3866"><span class="ln">3866 </span></a>
<a name="l3867"><span class="ln">3867 </span></a><span class="s3">// aten::var(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<a name="l3868"><span class="ln">3868 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::var(</span><span class="s1">bool </span><span class="s0">unbiased) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3869"><span class="ln">3869 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::var::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), unbiased);</span>
<a name="l3870"><span class="ln">3870 </span></a><span class="s0">}</span>
<a name="l3871"><span class="ln">3871 </span></a>
<a name="l3872"><span class="ln">3872 </span></a><span class="s3">// aten::var.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<a name="l3873"><span class="ln">3873 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::var(at::OptionalIntArrayRef dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3874"><span class="ln">3874 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::var_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, unbiased, keepdim);</span>
<a name="l3875"><span class="ln">3875 </span></a><span class="s0">}</span>
<a name="l3876"><span class="ln">3876 </span></a>
<a name="l3877"><span class="ln">3877 </span></a><span class="s3">// aten::var.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l3878"><span class="ln">3878 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::var(at::OptionalIntArrayRef dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3879"><span class="ln">3879 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::var_correction::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, correction, keepdim);</span>
<a name="l3880"><span class="ln">3880 </span></a><span class="s0">}</span>
<a name="l3881"><span class="ln">3881 </span></a>
<a name="l3882"><span class="ln">3882 </span></a><span class="s3">// aten::var.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<a name="l3883"><span class="ln">3883 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::var(at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">unbiased, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3884"><span class="ln">3884 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::var_names_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, unbiased, keepdim);</span>
<a name="l3885"><span class="ln">3885 </span></a><span class="s0">}</span>
<a name="l3886"><span class="ln">3886 </span></a>
<a name="l3887"><span class="ln">3887 </span></a><span class="s3">// aten::var.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<a name="l3888"><span class="ln">3888 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::var(at::DimnameList dim, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; correction, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3889"><span class="ln">3889 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::var_correction_names::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, correction, keepdim);</span>
<a name="l3890"><span class="ln">3890 </span></a><span class="s0">}</span>
<a name="l3891"><span class="ln">3891 </span></a>
<a name="l3892"><span class="ln">3892 </span></a><span class="s3">// aten::view_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<a name="l3893"><span class="ln">3893 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::view_as(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3894"><span class="ln">3894 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::view_as::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3895"><span class="ln">3895 </span></a><span class="s0">}</span>
<a name="l3896"><span class="ln">3896 </span></a>
<a name="l3897"><span class="ln">3897 </span></a><span class="s3">// aten::where.self(Tensor condition, Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l3898"><span class="ln">3898 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::where(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; condition, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3899"><span class="ln">3899 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::where_self::call(condition, </span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3900"><span class="ln">3900 </span></a><span class="s0">}</span>
<a name="l3901"><span class="ln">3901 </span></a>
<a name="l3902"><span class="ln">3902 </span></a><span class="s3">// aten::where.ScalarOther(Tensor condition, Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l3903"><span class="ln">3903 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::where(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; condition, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3904"><span class="ln">3904 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::where_ScalarOther::call(condition, </span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l3905"><span class="ln">3905 </span></a><span class="s0">}</span>
<a name="l3906"><span class="ln">3906 </span></a>
<a name="l3907"><span class="ln">3907 </span></a><span class="s3">// aten::norm.ScalarOpt_dtype(Tensor self, Scalar? p, *, ScalarType dtype) -&gt; Tensor</span>
<a name="l3908"><span class="ln">3908 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::ScalarType dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3909"><span class="ln">3909 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::norm_ScalarOpt_dtype::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dtype);</span>
<a name="l3910"><span class="ln">3910 </span></a><span class="s0">}</span>
<a name="l3911"><span class="ln">3911 </span></a>
<a name="l3912"><span class="ln">3912 </span></a><span class="s3">// aten::norm.Scalar(Tensor self, Scalar p=2) -&gt; Tensor</span>
<a name="l3913"><span class="ln">3913 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::norm(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; p) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3914"><span class="ln">3914 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::norm_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p);</span>
<a name="l3915"><span class="ln">3915 </span></a><span class="s0">}</span>
<a name="l3916"><span class="ln">3916 </span></a>
<a name="l3917"><span class="ln">3917 </span></a><span class="s3">// aten::norm.ScalarOpt_dim_dtype(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<a name="l3918"><span class="ln">3918 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim, at::ScalarType dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3919"><span class="ln">3919 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::norm_ScalarOpt_dim_dtype::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dim, keepdim, dtype);</span>
<a name="l3920"><span class="ln">3920 </span></a><span class="s0">}</span>
<a name="l3921"><span class="ln">3921 </span></a>
<a name="l3922"><span class="ln">3922 </span></a><span class="s3">// aten::norm.ScalarOpt_dim(Tensor self, Scalar? p, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l3923"><span class="ln">3923 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3924"><span class="ln">3924 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::norm_ScalarOpt_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dim, keepdim);</span>
<a name="l3925"><span class="ln">3925 </span></a><span class="s0">}</span>
<a name="l3926"><span class="ln">3926 </span></a>
<a name="l3927"><span class="ln">3927 </span></a><span class="s3">// aten::norm.names_ScalarOpt_dim_dtype(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<a name="l3928"><span class="ln">3928 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim, at::ScalarType dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3929"><span class="ln">3929 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::norm_names_ScalarOpt_dim_dtype::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dim, keepdim, dtype);</span>
<a name="l3930"><span class="ln">3930 </span></a><span class="s0">}</span>
<a name="l3931"><span class="ln">3931 </span></a>
<a name="l3932"><span class="ln">3932 </span></a><span class="s3">// aten::norm.names_ScalarOpt_dim(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<a name="l3933"><span class="ln">3933 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::norm(</span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, </span><span class="s1">bool </span><span class="s0">keepdim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3934"><span class="ln">3934 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::norm_names_ScalarOpt_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dim, keepdim);</span>
<a name="l3935"><span class="ln">3935 </span></a><span class="s0">}</span>
<a name="l3936"><span class="ln">3936 </span></a>
<a name="l3937"><span class="ln">3937 </span></a><span class="s3">// aten::frexp.Tensor(Tensor self) -&gt; (Tensor mantissa, Tensor exponent)</span>
<a name="l3938"><span class="ln">3938 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::frexp() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3939"><span class="ln">3939 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::frexp_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3940"><span class="ln">3940 </span></a><span class="s0">}</span>
<a name="l3941"><span class="ln">3941 </span></a>
<a name="l3942"><span class="ln">3942 </span></a><span class="s3">// aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<a name="l3943"><span class="ln">3943 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::clone(::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3944"><span class="ln">3944 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::clone::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), memory_format);</span>
<a name="l3945"><span class="ln">3945 </span></a><span class="s0">}</span>
<a name="l3946"><span class="ln">3946 </span></a>
<a name="l3947"><span class="ln">3947 </span></a><span class="s3">// aten::positive(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l3948"><span class="ln">3948 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::positive() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3949"><span class="ln">3949 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::positive::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3950"><span class="ln">3950 </span></a><span class="s0">}</span>
<a name="l3951"><span class="ln">3951 </span></a>
<a name="l3952"><span class="ln">3952 </span></a><span class="s3">// aten::resize_as_(Tensor(a!) self, Tensor the_template, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<a name="l3953"><span class="ln">3953 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::resize_as_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; the_template, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3954"><span class="ln">3954 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::resize_as_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), the_template, memory_format);</span>
<a name="l3955"><span class="ln">3955 </span></a><span class="s0">}</span>
<a name="l3956"><span class="ln">3956 </span></a>
<a name="l3957"><span class="ln">3957 </span></a><span class="s3">// aten::resize_as_sparse_(Tensor(a!) self, Tensor the_template) -&gt; Tensor(a!)</span>
<a name="l3958"><span class="ln">3958 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::resize_as_sparse_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; the_template) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3959"><span class="ln">3959 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::resize_as_sparse_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), the_template);</span>
<a name="l3960"><span class="ln">3960 </span></a><span class="s0">}</span>
<a name="l3961"><span class="ln">3961 </span></a>
<a name="l3962"><span class="ln">3962 </span></a><span class="s3">// aten::zero_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l3963"><span class="ln">3963 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::zero_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3964"><span class="ln">3964 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::zero_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l3965"><span class="ln">3965 </span></a><span class="s0">}</span>
<a name="l3966"><span class="ln">3966 </span></a>
<a name="l3967"><span class="ln">3967 </span></a><span class="s3">// aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<a name="l3968"><span class="ln">3968 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sub(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3969"><span class="ln">3969 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sub_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l3970"><span class="ln">3970 </span></a><span class="s0">}</span>
<a name="l3971"><span class="ln">3971 </span></a>
<a name="l3972"><span class="ln">3972 </span></a><span class="s3">// aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l3973"><span class="ln">3973 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sub_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3974"><span class="ln">3974 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sub__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l3975"><span class="ln">3975 </span></a><span class="s0">}</span>
<a name="l3976"><span class="ln">3976 </span></a>
<a name="l3977"><span class="ln">3977 </span></a><span class="s3">// aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<a name="l3978"><span class="ln">3978 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sub(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3979"><span class="ln">3979 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sub_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l3980"><span class="ln">3980 </span></a><span class="s0">}</span>
<a name="l3981"><span class="ln">3981 </span></a>
<a name="l3982"><span class="ln">3982 </span></a><span class="s3">// aten::sub_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l3983"><span class="ln">3983 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sub_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3984"><span class="ln">3984 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sub__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l3985"><span class="ln">3985 </span></a><span class="s0">}</span>
<a name="l3986"><span class="ln">3986 </span></a>
<a name="l3987"><span class="ln">3987 </span></a><span class="s3">// aten::subtract.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<a name="l3988"><span class="ln">3988 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::subtract(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3989"><span class="ln">3989 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::subtract_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l3990"><span class="ln">3990 </span></a><span class="s0">}</span>
<a name="l3991"><span class="ln">3991 </span></a>
<a name="l3992"><span class="ln">3992 </span></a><span class="s3">// aten::subtract_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l3993"><span class="ln">3993 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::subtract_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3994"><span class="ln">3994 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::subtract__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l3995"><span class="ln">3995 </span></a><span class="s0">}</span>
<a name="l3996"><span class="ln">3996 </span></a>
<a name="l3997"><span class="ln">3997 </span></a><span class="s3">// aten::subtract.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<a name="l3998"><span class="ln">3998 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::subtract(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l3999"><span class="ln">3999 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::subtract_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l4000"><span class="ln">4000 </span></a><span class="s0">}</span>
<a name="l4001"><span class="ln">4001 </span></a>
<a name="l4002"><span class="ln">4002 </span></a><span class="s3">// aten::subtract_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l4003"><span class="ln">4003 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::subtract_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4004"><span class="ln">4004 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::subtract__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, alpha);</span>
<a name="l4005"><span class="ln">4005 </span></a><span class="s0">}</span>
<a name="l4006"><span class="ln">4006 </span></a>
<a name="l4007"><span class="ln">4007 </span></a><span class="s3">// aten::heaviside(Tensor self, Tensor values) -&gt; Tensor</span>
<a name="l4008"><span class="ln">4008 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::heaviside(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; values) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4009"><span class="ln">4009 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::heaviside::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), values);</span>
<a name="l4010"><span class="ln">4010 </span></a><span class="s0">}</span>
<a name="l4011"><span class="ln">4011 </span></a>
<a name="l4012"><span class="ln">4012 </span></a><span class="s3">// aten::heaviside_(Tensor(a!) self, Tensor values) -&gt; Tensor(a!)</span>
<a name="l4013"><span class="ln">4013 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::heaviside_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; values) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4014"><span class="ln">4014 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::heaviside_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), values);</span>
<a name="l4015"><span class="ln">4015 </span></a><span class="s0">}</span>
<a name="l4016"><span class="ln">4016 </span></a>
<a name="l4017"><span class="ln">4017 </span></a><span class="s3">// aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<a name="l4018"><span class="ln">4018 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::addmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4019"><span class="ln">4019 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addmm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat1, mat2, beta, alpha);</span>
<a name="l4020"><span class="ln">4020 </span></a><span class="s0">}</span>
<a name="l4021"><span class="ln">4021 </span></a>
<a name="l4022"><span class="ln">4022 </span></a><span class="s3">// aten::addmm_(Tensor(a!) self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l4023"><span class="ln">4023 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::addmm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4024"><span class="ln">4024 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addmm_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat1, mat2, beta, alpha);</span>
<a name="l4025"><span class="ln">4025 </span></a><span class="s0">}</span>
<a name="l4026"><span class="ln">4026 </span></a>
<a name="l4027"><span class="ln">4027 </span></a><span class="s3">// aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -&gt; Tensor</span>
<a name="l4028"><span class="ln">4028 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_addmm_activation(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; mat2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha, </span><span class="s1">bool </span><span class="s0">use_gelu) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4029"><span class="ln">4029 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_addmm_activation::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mat1, mat2, beta, alpha, use_gelu);</span>
<a name="l4030"><span class="ln">4030 </span></a><span class="s0">}</span>
<a name="l4031"><span class="ln">4031 </span></a>
<a name="l4032"><span class="ln">4032 </span></a><span class="s3">// aten::sparse_resize_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -&gt; Tensor(a!)</span>
<a name="l4033"><span class="ln">4033 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::sparse_resize_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4034"><span class="ln">4034 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sparse_resize_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, sparse_dim, dense_dim);</span>
<a name="l4035"><span class="ln">4035 </span></a><span class="s0">}</span>
<a name="l4036"><span class="ln">4036 </span></a>
<a name="l4037"><span class="ln">4037 </span></a><span class="s3">// aten::sparse_resize_and_clear_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -&gt; Tensor(a!)</span>
<a name="l4038"><span class="ln">4038 </span></a><span class="s2">inline </span><span class="s1">const </span><span class="s0">at::Tensor &amp; Tensor::sparse_resize_and_clear_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4039"><span class="ln">4039 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sparse_resize_and_clear_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, sparse_dim, dense_dim);</span>
<a name="l4040"><span class="ln">4040 </span></a><span class="s0">}</span>
<a name="l4041"><span class="ln">4041 </span></a>
<a name="l4042"><span class="ln">4042 </span></a><span class="s3">// aten::sparse_mask(Tensor self, Tensor mask) -&gt; Tensor</span>
<a name="l4043"><span class="ln">4043 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sparse_mask(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4044"><span class="ln">4044 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sparse_mask::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask);</span>
<a name="l4045"><span class="ln">4045 </span></a><span class="s0">}</span>
<a name="l4046"><span class="ln">4046 </span></a>
<a name="l4047"><span class="ln">4047 </span></a><span class="s3">// aten::_sparse_mask_projection(Tensor self, Tensor mask, bool accumulate_matches=False) -&gt; Tensor</span>
<a name="l4048"><span class="ln">4048 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_sparse_mask_projection(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">bool </span><span class="s0">accumulate_matches) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4049"><span class="ln">4049 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_sparse_mask_projection::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, accumulate_matches);</span>
<a name="l4050"><span class="ln">4050 </span></a><span class="s0">}</span>
<a name="l4051"><span class="ln">4051 </span></a>
<a name="l4052"><span class="ln">4052 </span></a><span class="s3">// aten::to_dense(Tensor self, ScalarType? dtype=None, *, bool? masked_grad=None) -&gt; Tensor</span>
<a name="l4053"><span class="ln">4053 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_dense(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; masked_grad) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4054"><span class="ln">4054 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_dense::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype, masked_grad);</span>
<a name="l4055"><span class="ln">4055 </span></a><span class="s0">}</span>
<a name="l4056"><span class="ln">4056 </span></a>
<a name="l4057"><span class="ln">4057 </span></a><span class="s3">// aten::_to_dense(Tensor self, ScalarType? dtype=None, bool? masked_grad=None) -&gt; Tensor</span>
<a name="l4058"><span class="ln">4058 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_dense(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; masked_grad) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4059"><span class="ln">4059 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_dense::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype, masked_grad);</span>
<a name="l4060"><span class="ln">4060 </span></a><span class="s0">}</span>
<a name="l4061"><span class="ln">4061 </span></a>
<a name="l4062"><span class="ln">4062 </span></a><span class="s3">// aten::sparse_dim(Tensor self) -&gt; int</span>
<a name="l4063"><span class="ln">4063 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::sparse_dim() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4064"><span class="ln">4064 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sparse_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4065"><span class="ln">4065 </span></a><span class="s0">}</span>
<a name="l4066"><span class="ln">4066 </span></a>
<a name="l4067"><span class="ln">4067 </span></a><span class="s3">// aten::_dimI(Tensor self) -&gt; int</span>
<a name="l4068"><span class="ln">4068 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::_dimI() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4069"><span class="ln">4069 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_dimI::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4070"><span class="ln">4070 </span></a><span class="s0">}</span>
<a name="l4071"><span class="ln">4071 </span></a>
<a name="l4072"><span class="ln">4072 </span></a><span class="s3">// aten::dense_dim(Tensor self) -&gt; int</span>
<a name="l4073"><span class="ln">4073 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::dense_dim() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4074"><span class="ln">4074 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::dense_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4075"><span class="ln">4075 </span></a><span class="s0">}</span>
<a name="l4076"><span class="ln">4076 </span></a>
<a name="l4077"><span class="ln">4077 </span></a><span class="s3">// aten::_dimV(Tensor self) -&gt; int</span>
<a name="l4078"><span class="ln">4078 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::_dimV() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4079"><span class="ln">4079 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_dimV::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4080"><span class="ln">4080 </span></a><span class="s0">}</span>
<a name="l4081"><span class="ln">4081 </span></a>
<a name="l4082"><span class="ln">4082 </span></a><span class="s3">// aten::_nnz(Tensor self) -&gt; int</span>
<a name="l4083"><span class="ln">4083 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::_nnz() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4084"><span class="ln">4084 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_nnz::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4085"><span class="ln">4085 </span></a><span class="s0">}</span>
<a name="l4086"><span class="ln">4086 </span></a>
<a name="l4087"><span class="ln">4087 </span></a><span class="s3">// aten::coalesce(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4088"><span class="ln">4088 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::coalesce() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4089"><span class="ln">4089 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::coalesce::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4090"><span class="ln">4090 </span></a><span class="s0">}</span>
<a name="l4091"><span class="ln">4091 </span></a>
<a name="l4092"><span class="ln">4092 </span></a><span class="s3">// aten::is_coalesced(Tensor self) -&gt; bool</span>
<a name="l4093"><span class="ln">4093 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::is_coalesced() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4094"><span class="ln">4094 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_coalesced::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4095"><span class="ln">4095 </span></a><span class="s0">}</span>
<a name="l4096"><span class="ln">4096 </span></a>
<a name="l4097"><span class="ln">4097 </span></a><span class="s3">// aten::_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4098"><span class="ln">4098 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_indices() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4099"><span class="ln">4099 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4100"><span class="ln">4100 </span></a><span class="s0">}</span>
<a name="l4101"><span class="ln">4101 </span></a>
<a name="l4102"><span class="ln">4102 </span></a><span class="s3">// aten::_values(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4103"><span class="ln">4103 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_values() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4104"><span class="ln">4104 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_values::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4105"><span class="ln">4105 </span></a><span class="s0">}</span>
<a name="l4106"><span class="ln">4106 </span></a>
<a name="l4107"><span class="ln">4107 </span></a><span class="s3">// aten::_coalesced_(Tensor(a!) self, bool coalesced) -&gt; Tensor(a!)</span>
<a name="l4108"><span class="ln">4108 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::_coalesced_(</span><span class="s1">bool </span><span class="s0">coalesced) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4109"><span class="ln">4109 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_coalesced_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), coalesced);</span>
<a name="l4110"><span class="ln">4110 </span></a><span class="s0">}</span>
<a name="l4111"><span class="ln">4111 </span></a>
<a name="l4112"><span class="ln">4112 </span></a><span class="s3">// aten::indices(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4113"><span class="ln">4113 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::indices() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4114"><span class="ln">4114 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4115"><span class="ln">4115 </span></a><span class="s0">}</span>
<a name="l4116"><span class="ln">4116 </span></a>
<a name="l4117"><span class="ln">4117 </span></a><span class="s3">// aten::values(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4118"><span class="ln">4118 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::values() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4119"><span class="ln">4119 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::values::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4120"><span class="ln">4120 </span></a><span class="s0">}</span>
<a name="l4121"><span class="ln">4121 </span></a>
<a name="l4122"><span class="ln">4122 </span></a><span class="s3">// aten::crow_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4123"><span class="ln">4123 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::crow_indices() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4124"><span class="ln">4124 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::crow_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4125"><span class="ln">4125 </span></a><span class="s0">}</span>
<a name="l4126"><span class="ln">4126 </span></a>
<a name="l4127"><span class="ln">4127 </span></a><span class="s3">// aten::col_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4128"><span class="ln">4128 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::col_indices() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4129"><span class="ln">4129 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::col_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4130"><span class="ln">4130 </span></a><span class="s0">}</span>
<a name="l4131"><span class="ln">4131 </span></a>
<a name="l4132"><span class="ln">4132 </span></a><span class="s3">// aten::ccol_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4133"><span class="ln">4133 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ccol_indices() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4134"><span class="ln">4134 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ccol_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4135"><span class="ln">4135 </span></a><span class="s0">}</span>
<a name="l4136"><span class="ln">4136 </span></a>
<a name="l4137"><span class="ln">4137 </span></a><span class="s3">// aten::row_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l4138"><span class="ln">4138 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::row_indices() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4139"><span class="ln">4139 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::row_indices::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4140"><span class="ln">4140 </span></a><span class="s0">}</span>
<a name="l4141"><span class="ln">4141 </span></a>
<a name="l4142"><span class="ln">4142 </span></a><span class="s3">// aten::unbind.int(Tensor(a -&gt; *) self, int dim=0) -&gt; Tensor(a)[]</span>
<a name="l4143"><span class="ln">4143 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unbind(int64_t dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4144"><span class="ln">4144 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unbind_int::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l4145"><span class="ln">4145 </span></a><span class="s0">}</span>
<a name="l4146"><span class="ln">4146 </span></a>
<a name="l4147"><span class="ln">4147 </span></a><span class="s3">// aten::unbind.Dimname(Tensor(a -&gt; *) self, Dimname dim) -&gt; Tensor(a)[]</span>
<a name="l4148"><span class="ln">4148 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::unbind(at::Dimname dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4149"><span class="ln">4149 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unbind_Dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim);</span>
<a name="l4150"><span class="ln">4150 </span></a><span class="s0">}</span>
<a name="l4151"><span class="ln">4151 </span></a>
<a name="l4152"><span class="ln">4152 </span></a><span class="s3">// aten::to_sparse.sparse_dim(Tensor self, int sparse_dim) -&gt; Tensor</span>
<a name="l4153"><span class="ln">4153 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_sparse(int64_t sparse_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4154"><span class="ln">4154 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_sparse_sparse_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sparse_dim);</span>
<a name="l4155"><span class="ln">4155 </span></a><span class="s0">}</span>
<a name="l4156"><span class="ln">4156 </span></a>
<a name="l4157"><span class="ln">4157 </span></a><span class="s3">// aten::_to_sparse.sparse_dim(Tensor self, int sparse_dim) -&gt; Tensor</span>
<a name="l4158"><span class="ln">4158 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_sparse(int64_t sparse_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4159"><span class="ln">4159 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_sparse_sparse_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), sparse_dim);</span>
<a name="l4160"><span class="ln">4160 </span></a><span class="s0">}</span>
<a name="l4161"><span class="ln">4161 </span></a>
<a name="l4162"><span class="ln">4162 </span></a><span class="s3">// aten::to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4163"><span class="ln">4163 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_sparse(::std::optional&lt;at::Layout&gt; layout, at::OptionalIntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4164"><span class="ln">4164 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_sparse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), layout, blocksize, dense_dim);</span>
<a name="l4165"><span class="ln">4165 </span></a><span class="s0">}</span>
<a name="l4166"><span class="ln">4166 </span></a>
<a name="l4167"><span class="ln">4167 </span></a><span class="s3">// aten::_to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4168"><span class="ln">4168 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_sparse(::std::optional&lt;at::Layout&gt; layout, at::OptionalIntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4169"><span class="ln">4169 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_sparse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), layout, blocksize, dense_dim);</span>
<a name="l4170"><span class="ln">4170 </span></a><span class="s0">}</span>
<a name="l4171"><span class="ln">4171 </span></a>
<a name="l4172"><span class="ln">4172 </span></a><span class="s3">// aten::to_sparse_csr(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4173"><span class="ln">4173 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4174"><span class="ln">4174 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_sparse_csr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dense_dim);</span>
<a name="l4175"><span class="ln">4175 </span></a><span class="s0">}</span>
<a name="l4176"><span class="ln">4176 </span></a>
<a name="l4177"><span class="ln">4177 </span></a><span class="s3">// aten::_to_sparse_csr(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4178"><span class="ln">4178 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4179"><span class="ln">4179 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_sparse_csr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dense_dim);</span>
<a name="l4180"><span class="ln">4180 </span></a><span class="s0">}</span>
<a name="l4181"><span class="ln">4181 </span></a>
<a name="l4182"><span class="ln">4182 </span></a><span class="s3">// aten::to_sparse_csc(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4183"><span class="ln">4183 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4184"><span class="ln">4184 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_sparse_csc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dense_dim);</span>
<a name="l4185"><span class="ln">4185 </span></a><span class="s0">}</span>
<a name="l4186"><span class="ln">4186 </span></a>
<a name="l4187"><span class="ln">4187 </span></a><span class="s3">// aten::_to_sparse_csc(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4188"><span class="ln">4188 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4189"><span class="ln">4189 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_sparse_csc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dense_dim);</span>
<a name="l4190"><span class="ln">4190 </span></a><span class="s0">}</span>
<a name="l4191"><span class="ln">4191 </span></a>
<a name="l4192"><span class="ln">4192 </span></a><span class="s3">// aten::to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4193"><span class="ln">4193 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4194"><span class="ln">4194 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_sparse_bsr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), blocksize, dense_dim);</span>
<a name="l4195"><span class="ln">4195 </span></a><span class="s0">}</span>
<a name="l4196"><span class="ln">4196 </span></a>
<a name="l4197"><span class="ln">4197 </span></a><span class="s3">// aten::_to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4198"><span class="ln">4198 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4199"><span class="ln">4199 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_sparse_bsr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), blocksize, dense_dim);</span>
<a name="l4200"><span class="ln">4200 </span></a><span class="s0">}</span>
<a name="l4201"><span class="ln">4201 </span></a>
<a name="l4202"><span class="ln">4202 </span></a><span class="s3">// aten::to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4203"><span class="ln">4203 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4204"><span class="ln">4204 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_sparse_bsc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), blocksize, dense_dim);</span>
<a name="l4205"><span class="ln">4205 </span></a><span class="s0">}</span>
<a name="l4206"><span class="ln">4206 </span></a>
<a name="l4207"><span class="ln">4207 </span></a><span class="s3">// aten::_to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<a name="l4208"><span class="ln">4208 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4209"><span class="ln">4209 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_to_sparse_bsc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), blocksize, dense_dim);</span>
<a name="l4210"><span class="ln">4210 </span></a><span class="s0">}</span>
<a name="l4211"><span class="ln">4211 </span></a>
<a name="l4212"><span class="ln">4212 </span></a><span class="s3">// aten::to_mkldnn(Tensor self, ScalarType? dtype=None) -&gt; Tensor</span>
<a name="l4213"><span class="ln">4213 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_mkldnn(::std::optional&lt;at::ScalarType&gt; dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4214"><span class="ln">4214 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_mkldnn::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype);</span>
<a name="l4215"><span class="ln">4215 </span></a><span class="s0">}</span>
<a name="l4216"><span class="ln">4216 </span></a>
<a name="l4217"><span class="ln">4217 </span></a><span class="s3">// aten::dequantize.self(Tensor self) -&gt; Tensor</span>
<a name="l4218"><span class="ln">4218 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::dequantize() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4219"><span class="ln">4219 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::dequantize_self::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4220"><span class="ln">4220 </span></a><span class="s0">}</span>
<a name="l4221"><span class="ln">4221 </span></a>
<a name="l4222"><span class="ln">4222 </span></a><span class="s3">// aten::q_scale(Tensor self) -&gt; float</span>
<a name="l4223"><span class="ln">4223 </span></a><span class="s2">inline </span><span class="s1">double </span><span class="s0">Tensor::q_scale() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4224"><span class="ln">4224 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::q_scale::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4225"><span class="ln">4225 </span></a><span class="s0">}</span>
<a name="l4226"><span class="ln">4226 </span></a>
<a name="l4227"><span class="ln">4227 </span></a><span class="s3">// aten::q_zero_point(Tensor self) -&gt; int</span>
<a name="l4228"><span class="ln">4228 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::q_zero_point() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4229"><span class="ln">4229 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::q_zero_point::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4230"><span class="ln">4230 </span></a><span class="s0">}</span>
<a name="l4231"><span class="ln">4231 </span></a>
<a name="l4232"><span class="ln">4232 </span></a><span class="s3">// aten::q_per_channel_scales(Tensor self) -&gt; Tensor</span>
<a name="l4233"><span class="ln">4233 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::q_per_channel_scales() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4234"><span class="ln">4234 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::q_per_channel_scales::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4235"><span class="ln">4235 </span></a><span class="s0">}</span>
<a name="l4236"><span class="ln">4236 </span></a>
<a name="l4237"><span class="ln">4237 </span></a><span class="s3">// aten::q_per_channel_zero_points(Tensor self) -&gt; Tensor</span>
<a name="l4238"><span class="ln">4238 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::q_per_channel_zero_points() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4239"><span class="ln">4239 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::q_per_channel_zero_points::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4240"><span class="ln">4240 </span></a><span class="s0">}</span>
<a name="l4241"><span class="ln">4241 </span></a>
<a name="l4242"><span class="ln">4242 </span></a><span class="s3">// aten::q_per_channel_axis(Tensor self) -&gt; int</span>
<a name="l4243"><span class="ln">4243 </span></a><span class="s2">inline </span><span class="s0">int64_t Tensor::q_per_channel_axis() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4244"><span class="ln">4244 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::q_per_channel_axis::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4245"><span class="ln">4245 </span></a><span class="s0">}</span>
<a name="l4246"><span class="ln">4246 </span></a>
<a name="l4247"><span class="ln">4247 </span></a><span class="s3">// aten::int_repr(Tensor self) -&gt; Tensor</span>
<a name="l4248"><span class="ln">4248 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::int_repr() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4249"><span class="ln">4249 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::int_repr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4250"><span class="ln">4250 </span></a><span class="s0">}</span>
<a name="l4251"><span class="ln">4251 </span></a>
<a name="l4252"><span class="ln">4252 </span></a><span class="s3">// aten::qscheme(Tensor self) -&gt; QScheme</span>
<a name="l4253"><span class="ln">4253 </span></a><span class="s2">inline </span><span class="s0">at::QScheme Tensor::qscheme() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4254"><span class="ln">4254 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::qscheme::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4255"><span class="ln">4255 </span></a><span class="s0">}</span>
<a name="l4256"><span class="ln">4256 </span></a>
<a name="l4257"><span class="ln">4257 </span></a><span class="s3">// aten::_autocast_to_reduced_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled, ScalarType cuda_dtype, ScalarType cpu_dtype) -&gt; Tensor(a)</span>
<a name="l4258"><span class="ln">4258 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_autocast_to_reduced_precision(</span><span class="s1">bool </span><span class="s0">cuda_enabled, </span><span class="s1">bool </span><span class="s0">cpu_enabled, at::ScalarType cuda_dtype, at::ScalarType cpu_dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4259"><span class="ln">4259 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_autocast_to_reduced_precision::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), cuda_enabled, cpu_enabled, cuda_dtype, cpu_dtype);</span>
<a name="l4260"><span class="ln">4260 </span></a><span class="s0">}</span>
<a name="l4261"><span class="ln">4261 </span></a>
<a name="l4262"><span class="ln">4262 </span></a><span class="s3">// aten::_autocast_to_full_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled) -&gt; Tensor(a)</span>
<a name="l4263"><span class="ln">4263 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::_autocast_to_full_precision(</span><span class="s1">bool </span><span class="s0">cuda_enabled, </span><span class="s1">bool </span><span class="s0">cpu_enabled) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4264"><span class="ln">4264 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::_autocast_to_full_precision::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), cuda_enabled, cpu_enabled);</span>
<a name="l4265"><span class="ln">4265 </span></a><span class="s0">}</span>
<a name="l4266"><span class="ln">4266 </span></a>
<a name="l4267"><span class="ln">4267 </span></a><span class="s3">// aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<a name="l4268"><span class="ln">4268 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to(at::TensorOptions options, </span><span class="s1">bool </span><span class="s0">non_blocking, </span><span class="s1">bool </span><span class="s0">copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4269"><span class="ln">4269 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_dtype_layout::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt(), non_blocking, copy, c10::impl::check_tensor_options_and_extract_memory_format(options, memory_format));</span>
<a name="l4270"><span class="ln">4270 </span></a><span class="s0">}</span>
<a name="l4271"><span class="ln">4271 </span></a>
<a name="l4272"><span class="ln">4272 </span></a><span class="s3">// aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<a name="l4273"><span class="ln">4273 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; pin_memory, </span><span class="s1">bool </span><span class="s0">non_blocking, </span><span class="s1">bool </span><span class="s0">copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4274"><span class="ln">4274 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_dtype_layout::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype, layout, device, pin_memory, non_blocking, copy, memory_format);</span>
<a name="l4275"><span class="ln">4275 </span></a><span class="s0">}</span>
<a name="l4276"><span class="ln">4276 </span></a>
<a name="l4277"><span class="ln">4277 </span></a><span class="s3">// aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<a name="l4278"><span class="ln">4278 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to(at::Device device, at::ScalarType dtype, </span><span class="s1">bool </span><span class="s0">non_blocking, </span><span class="s1">bool </span><span class="s0">copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4279"><span class="ln">4279 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_device::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), device, dtype, non_blocking, copy, memory_format);</span>
<a name="l4280"><span class="ln">4280 </span></a><span class="s0">}</span>
<a name="l4281"><span class="ln">4281 </span></a>
<a name="l4282"><span class="ln">4282 </span></a><span class="s3">// aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<a name="l4283"><span class="ln">4283 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to(at::ScalarType dtype, </span><span class="s1">bool </span><span class="s0">non_blocking, </span><span class="s1">bool </span><span class="s0">copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4284"><span class="ln">4284 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_dtype::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype, non_blocking, copy, memory_format);</span>
<a name="l4285"><span class="ln">4285 </span></a><span class="s0">}</span>
<a name="l4286"><span class="ln">4286 </span></a>
<a name="l4287"><span class="ln">4287 </span></a><span class="s3">// aten::to.other(Tensor(a) self, Tensor other, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<a name="l4288"><span class="ln">4288 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">bool </span><span class="s0">non_blocking, </span><span class="s1">bool </span><span class="s0">copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4289"><span class="ln">4289 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_other::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, non_blocking, copy, memory_format);</span>
<a name="l4290"><span class="ln">4290 </span></a><span class="s0">}</span>
<a name="l4291"><span class="ln">4291 </span></a>
<a name="l4292"><span class="ln">4292 </span></a><span class="s3">// aten::item(Tensor self) -&gt; Scalar</span>
<a name="l4293"><span class="ln">4293 </span></a><span class="s2">inline </span><span class="s0">at::Scalar Tensor::item() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4294"><span class="ln">4294 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::item::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4295"><span class="ln">4295 </span></a><span class="s0">}</span>
<a name="l4296"><span class="ln">4296 </span></a>
<a name="l4297"><span class="ln">4297 </span></a><span class="s3">// aten::set_.source_Storage(Tensor(a!) self, Storage source) -&gt; Tensor(a!)</span>
<a name="l4298"><span class="ln">4298 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set_(at::Storage source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4299"><span class="ln">4299 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set__source_Storage::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source);</span>
<a name="l4300"><span class="ln">4300 </span></a><span class="s0">}</span>
<a name="l4301"><span class="ln">4301 </span></a>
<a name="l4302"><span class="ln">4302 </span></a><span class="s3">// aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<a name="l4303"><span class="ln">4303 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set_(at::Storage source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4304"><span class="ln">4304 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set__source_Storage_storage_offset::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, storage_offset, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride));</span>
<a name="l4305"><span class="ln">4305 </span></a><span class="s0">}</span>
<a name="l4306"><span class="ln">4306 </span></a>
<a name="l4307"><span class="ln">4307 </span></a><span class="s3">// aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<a name="l4308"><span class="ln">4308 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set__symint(at::Storage source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4309"><span class="ln">4309 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set__source_Storage_storage_offset::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, storage_offset, size, stride);</span>
<a name="l4310"><span class="ln">4310 </span></a><span class="s0">}</span>
<a name="l4311"><span class="ln">4311 </span></a>
<a name="l4312"><span class="ln">4312 </span></a><span class="s3">// aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<a name="l4313"><span class="ln">4313 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4314"><span class="ln">4314 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set__source_Tensor_storage_offset::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, storage_offset, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride));</span>
<a name="l4315"><span class="ln">4315 </span></a><span class="s0">}</span>
<a name="l4316"><span class="ln">4316 </span></a>
<a name="l4317"><span class="ln">4317 </span></a><span class="s3">// aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<a name="l4318"><span class="ln">4318 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set__symint(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4319"><span class="ln">4319 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set__source_Tensor_storage_offset::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source, storage_offset, size, stride);</span>
<a name="l4320"><span class="ln">4320 </span></a><span class="s0">}</span>
<a name="l4321"><span class="ln">4321 </span></a>
<a name="l4322"><span class="ln">4322 </span></a><span class="s3">// aten::set_.source_Tensor(Tensor(a!) self, Tensor source) -&gt; Tensor(a!)</span>
<a name="l4323"><span class="ln">4323 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4324"><span class="ln">4324 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set__source_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), source);</span>
<a name="l4325"><span class="ln">4325 </span></a><span class="s0">}</span>
<a name="l4326"><span class="ln">4326 </span></a>
<a name="l4327"><span class="ln">4327 </span></a><span class="s3">// aten::set_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l4328"><span class="ln">4328 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::set_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4329"><span class="ln">4329 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::set_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4330"><span class="ln">4330 </span></a><span class="s0">}</span>
<a name="l4331"><span class="ln">4331 </span></a>
<a name="l4332"><span class="ln">4332 </span></a><span class="s3">// aten::is_set_to(Tensor self, Tensor tensor) -&gt; bool</span>
<a name="l4333"><span class="ln">4333 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::is_set_to(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4334"><span class="ln">4334 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::is_set_to::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor);</span>
<a name="l4335"><span class="ln">4335 </span></a><span class="s0">}</span>
<a name="l4336"><span class="ln">4336 </span></a>
<a name="l4337"><span class="ln">4337 </span></a><span class="s3">// aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -&gt; Tensor(a!)</span>
<a name="l4338"><span class="ln">4338 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::masked_fill_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4339"><span class="ln">4339 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_fill__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, value);</span>
<a name="l4340"><span class="ln">4340 </span></a><span class="s0">}</span>
<a name="l4341"><span class="ln">4341 </span></a>
<a name="l4342"><span class="ln">4342 </span></a><span class="s3">// aten::masked_fill.Scalar(Tensor self, Tensor mask, Scalar value) -&gt; Tensor</span>
<a name="l4343"><span class="ln">4343 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::masked_fill(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4344"><span class="ln">4344 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_fill_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, value);</span>
<a name="l4345"><span class="ln">4345 </span></a><span class="s0">}</span>
<a name="l4346"><span class="ln">4346 </span></a>
<a name="l4347"><span class="ln">4347 </span></a><span class="s3">// aten::masked_fill_.Tensor(Tensor(a!) self, Tensor mask, Tensor value) -&gt; Tensor(a!)</span>
<a name="l4348"><span class="ln">4348 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::masked_fill_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4349"><span class="ln">4349 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_fill__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, value);</span>
<a name="l4350"><span class="ln">4350 </span></a><span class="s0">}</span>
<a name="l4351"><span class="ln">4351 </span></a>
<a name="l4352"><span class="ln">4352 </span></a><span class="s3">// aten::masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -&gt; Tensor</span>
<a name="l4353"><span class="ln">4353 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::masked_fill(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4354"><span class="ln">4354 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_fill_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, value);</span>
<a name="l4355"><span class="ln">4355 </span></a><span class="s0">}</span>
<a name="l4356"><span class="ln">4356 </span></a>
<a name="l4357"><span class="ln">4357 </span></a><span class="s3">// aten::masked_scatter_(Tensor(a!) self, Tensor mask, Tensor source) -&gt; Tensor(a!)</span>
<a name="l4358"><span class="ln">4358 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::masked_scatter_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4359"><span class="ln">4359 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_scatter_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, source);</span>
<a name="l4360"><span class="ln">4360 </span></a><span class="s0">}</span>
<a name="l4361"><span class="ln">4361 </span></a>
<a name="l4362"><span class="ln">4362 </span></a><span class="s3">// aten::masked_scatter(Tensor self, Tensor mask, Tensor source) -&gt; Tensor</span>
<a name="l4363"><span class="ln">4363 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::masked_scatter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4364"><span class="ln">4364 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_scatter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask, source);</span>
<a name="l4365"><span class="ln">4365 </span></a><span class="s0">}</span>
<a name="l4366"><span class="ln">4366 </span></a>
<a name="l4367"><span class="ln">4367 </span></a><span class="s3">// aten::view(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<a name="l4368"><span class="ln">4368 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::view(at::IntArrayRef size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4369"><span class="ln">4369 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::view::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), c10::fromIntArrayRefSlow(size));</span>
<a name="l4370"><span class="ln">4370 </span></a><span class="s0">}</span>
<a name="l4371"><span class="ln">4371 </span></a>
<a name="l4372"><span class="ln">4372 </span></a><span class="s3">// aten::view(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<a name="l4373"><span class="ln">4373 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::view_symint(c10::SymIntArrayRef size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4374"><span class="ln">4374 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::view::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size);</span>
<a name="l4375"><span class="ln">4375 </span></a><span class="s0">}</span>
<a name="l4376"><span class="ln">4376 </span></a>
<a name="l4377"><span class="ln">4377 </span></a><span class="s3">// aten::view.dtype(Tensor(a) self, ScalarType dtype) -&gt; Tensor(a)</span>
<a name="l4378"><span class="ln">4378 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::view(at::ScalarType dtype) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4379"><span class="ln">4379 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::view_dtype::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dtype);</span>
<a name="l4380"><span class="ln">4380 </span></a><span class="s0">}</span>
<a name="l4381"><span class="ln">4381 </span></a>
<a name="l4382"><span class="ln">4382 </span></a><span class="s3">// aten::put_(Tensor(a!) self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor(a!)</span>
<a name="l4383"><span class="ln">4383 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::put_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">bool </span><span class="s0">accumulate) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4384"><span class="ln">4384 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::put_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), index, source, accumulate);</span>
<a name="l4385"><span class="ln">4385 </span></a><span class="s0">}</span>
<a name="l4386"><span class="ln">4386 </span></a>
<a name="l4387"><span class="ln">4387 </span></a><span class="s3">// aten::put(Tensor self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor</span>
<a name="l4388"><span class="ln">4388 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::put(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">bool </span><span class="s0">accumulate) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4389"><span class="ln">4389 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::put::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), index, source, accumulate);</span>
<a name="l4390"><span class="ln">4390 </span></a><span class="s0">}</span>
<a name="l4391"><span class="ln">4391 </span></a>
<a name="l4392"><span class="ln">4392 </span></a><span class="s3">// aten::index_add_(Tensor(a!) self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l4393"><span class="ln">4393 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_add_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4394"><span class="ln">4394 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_add_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source, alpha);</span>
<a name="l4395"><span class="ln">4395 </span></a><span class="s0">}</span>
<a name="l4396"><span class="ln">4396 </span></a>
<a name="l4397"><span class="ln">4397 </span></a><span class="s3">// aten::index_add(Tensor self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<a name="l4398"><span class="ln">4398 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_add(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4399"><span class="ln">4399 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_add::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source, alpha);</span>
<a name="l4400"><span class="ln">4400 </span></a><span class="s0">}</span>
<a name="l4401"><span class="ln">4401 </span></a>
<a name="l4402"><span class="ln">4402 </span></a><span class="s3">// aten::index_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<a name="l4403"><span class="ln">4403 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_add(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4404"><span class="ln">4404 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_add_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source, alpha);</span>
<a name="l4405"><span class="ln">4405 </span></a><span class="s0">}</span>
<a name="l4406"><span class="ln">4406 </span></a>
<a name="l4407"><span class="ln">4407 </span></a><span class="s3">// aten::index_reduce_(Tensor(a!) self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -&gt; Tensor(a!)</span>
<a name="l4408"><span class="ln">4408 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_reduce_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4409"><span class="ln">4409 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_reduce_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source, reduce, include_self);</span>
<a name="l4410"><span class="ln">4410 </span></a><span class="s0">}</span>
<a name="l4411"><span class="ln">4411 </span></a>
<a name="l4412"><span class="ln">4412 </span></a><span class="s3">// aten::index_reduce(Tensor self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -&gt; Tensor</span>
<a name="l4413"><span class="ln">4413 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_reduce(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; source, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4414"><span class="ln">4414 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_reduce::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, source, reduce, include_self);</span>
<a name="l4415"><span class="ln">4415 </span></a><span class="s0">}</span>
<a name="l4416"><span class="ln">4416 </span></a>
<a name="l4417"><span class="ln">4417 </span></a><span class="s3">// aten::index_fill_.int_Scalar(Tensor(a!) self, int dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<a name="l4418"><span class="ln">4418 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_fill_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4419"><span class="ln">4419 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill__int_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4420"><span class="ln">4420 </span></a><span class="s0">}</span>
<a name="l4421"><span class="ln">4421 </span></a>
<a name="l4422"><span class="ln">4422 </span></a><span class="s3">// aten::index_fill.int_Scalar(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<a name="l4423"><span class="ln">4423 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_fill(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4424"><span class="ln">4424 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill_int_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4425"><span class="ln">4425 </span></a><span class="s0">}</span>
<a name="l4426"><span class="ln">4426 </span></a>
<a name="l4427"><span class="ln">4427 </span></a><span class="s3">// aten::index_fill_.int_Tensor(Tensor(a!) self, int dim, Tensor index, Tensor value) -&gt; Tensor(a!)</span>
<a name="l4428"><span class="ln">4428 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_fill_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4429"><span class="ln">4429 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill__int_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4430"><span class="ln">4430 </span></a><span class="s0">}</span>
<a name="l4431"><span class="ln">4431 </span></a>
<a name="l4432"><span class="ln">4432 </span></a><span class="s3">// aten::index_fill.int_Tensor(Tensor self, int dim, Tensor index, Tensor value) -&gt; Tensor</span>
<a name="l4433"><span class="ln">4433 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_fill(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4434"><span class="ln">4434 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill_int_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4435"><span class="ln">4435 </span></a><span class="s0">}</span>
<a name="l4436"><span class="ln">4436 </span></a>
<a name="l4437"><span class="ln">4437 </span></a><span class="s3">// aten::index_fill_.Dimname_Scalar(Tensor(a!) self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<a name="l4438"><span class="ln">4438 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_fill_(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4439"><span class="ln">4439 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill__Dimname_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4440"><span class="ln">4440 </span></a><span class="s0">}</span>
<a name="l4441"><span class="ln">4441 </span></a>
<a name="l4442"><span class="ln">4442 </span></a><span class="s3">// aten::index_fill_.Dimname_Tensor(Tensor(a!) self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor(a!)</span>
<a name="l4443"><span class="ln">4443 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::index_fill_(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4444"><span class="ln">4444 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill__Dimname_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4445"><span class="ln">4445 </span></a><span class="s0">}</span>
<a name="l4446"><span class="ln">4446 </span></a>
<a name="l4447"><span class="ln">4447 </span></a><span class="s3">// aten::index_fill.Dimname_Scalar(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<a name="l4448"><span class="ln">4448 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_fill(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4449"><span class="ln">4449 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill_Dimname_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4450"><span class="ln">4450 </span></a><span class="s0">}</span>
<a name="l4451"><span class="ln">4451 </span></a>
<a name="l4452"><span class="ln">4452 </span></a><span class="s3">// aten::index_fill.Dimname_Tensor(Tensor self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor</span>
<a name="l4453"><span class="ln">4453 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_fill(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4454"><span class="ln">4454 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_fill_Dimname_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4455"><span class="ln">4455 </span></a><span class="s0">}</span>
<a name="l4456"><span class="ln">4456 </span></a>
<a name="l4457"><span class="ln">4457 </span></a><span class="s3">// aten::scatter.src(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<a name="l4458"><span class="ln">4458 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4459"><span class="ln">4459 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_src::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src);</span>
<a name="l4460"><span class="ln">4460 </span></a><span class="s0">}</span>
<a name="l4461"><span class="ln">4461 </span></a>
<a name="l4462"><span class="ln">4462 </span></a><span class="s3">// aten::scatter_.src(Tensor(a!) self, int dim, Tensor index, Tensor src) -&gt; Tensor(a!)</span>
<a name="l4463"><span class="ln">4463 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4464"><span class="ln">4464 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter__src::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src);</span>
<a name="l4465"><span class="ln">4465 </span></a><span class="s0">}</span>
<a name="l4466"><span class="ln">4466 </span></a>
<a name="l4467"><span class="ln">4467 </span></a><span class="s3">// aten::scatter.value(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<a name="l4468"><span class="ln">4468 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4469"><span class="ln">4469 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_value::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4470"><span class="ln">4470 </span></a><span class="s0">}</span>
<a name="l4471"><span class="ln">4471 </span></a>
<a name="l4472"><span class="ln">4472 </span></a><span class="s3">// aten::scatter_.value(Tensor(a!) self, int dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<a name="l4473"><span class="ln">4473 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4474"><span class="ln">4474 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter__value::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4475"><span class="ln">4475 </span></a><span class="s0">}</span>
<a name="l4476"><span class="ln">4476 </span></a>
<a name="l4477"><span class="ln">4477 </span></a><span class="s3">// aten::scatter.reduce(Tensor self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor</span>
<a name="l4478"><span class="ln">4478 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4479"><span class="ln">4479 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_reduce::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src, reduce);</span>
<a name="l4480"><span class="ln">4480 </span></a><span class="s0">}</span>
<a name="l4481"><span class="ln">4481 </span></a>
<a name="l4482"><span class="ln">4482 </span></a><span class="s3">// aten::scatter_.reduce(Tensor(a!) self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor(a!)</span>
<a name="l4483"><span class="ln">4483 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4484"><span class="ln">4484 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter__reduce::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src, reduce);</span>
<a name="l4485"><span class="ln">4485 </span></a><span class="s0">}</span>
<a name="l4486"><span class="ln">4486 </span></a>
<a name="l4487"><span class="ln">4487 </span></a><span class="s3">// aten::scatter.value_reduce(Tensor self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor</span>
<a name="l4488"><span class="ln">4488 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value, c10::string_view reduce) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4489"><span class="ln">4489 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_value_reduce::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value, reduce);</span>
<a name="l4490"><span class="ln">4490 </span></a><span class="s0">}</span>
<a name="l4491"><span class="ln">4491 </span></a>
<a name="l4492"><span class="ln">4492 </span></a><span class="s3">// aten::scatter_.value_reduce(Tensor(a!) self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor(a!)</span>
<a name="l4493"><span class="ln">4493 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::scatter_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value, c10::string_view reduce) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4494"><span class="ln">4494 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter__value_reduce::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value, reduce);</span>
<a name="l4495"><span class="ln">4495 </span></a><span class="s0">}</span>
<a name="l4496"><span class="ln">4496 </span></a>
<a name="l4497"><span class="ln">4497 </span></a><span class="s3">// aten::scatter.dimname_src(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<a name="l4498"><span class="ln">4498 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4499"><span class="ln">4499 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_dimname_src::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src);</span>
<a name="l4500"><span class="ln">4500 </span></a><span class="s0">}</span>
<a name="l4501"><span class="ln">4501 </span></a>
<a name="l4502"><span class="ln">4502 </span></a><span class="s3">// aten::scatter.dimname_value(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<a name="l4503"><span class="ln">4503 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4504"><span class="ln">4504 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_dimname_value::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, value);</span>
<a name="l4505"><span class="ln">4505 </span></a><span class="s0">}</span>
<a name="l4506"><span class="ln">4506 </span></a>
<a name="l4507"><span class="ln">4507 </span></a><span class="s3">// aten::scatter_add(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<a name="l4508"><span class="ln">4508 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter_add(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4509"><span class="ln">4509 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_add::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src);</span>
<a name="l4510"><span class="ln">4510 </span></a><span class="s0">}</span>
<a name="l4511"><span class="ln">4511 </span></a>
<a name="l4512"><span class="ln">4512 </span></a><span class="s3">// aten::scatter_add_(Tensor(a!) self, int dim, Tensor index, Tensor src) -&gt; Tensor(a!)</span>
<a name="l4513"><span class="ln">4513 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::scatter_add_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4514"><span class="ln">4514 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_add_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src);</span>
<a name="l4515"><span class="ln">4515 </span></a><span class="s0">}</span>
<a name="l4516"><span class="ln">4516 </span></a>
<a name="l4517"><span class="ln">4517 </span></a><span class="s3">// aten::scatter_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<a name="l4518"><span class="ln">4518 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter_add(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4519"><span class="ln">4519 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_add_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src);</span>
<a name="l4520"><span class="ln">4520 </span></a><span class="s0">}</span>
<a name="l4521"><span class="ln">4521 </span></a>
<a name="l4522"><span class="ln">4522 </span></a><span class="s3">// aten::scatter_reduce.two(Tensor self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -&gt; Tensor</span>
<a name="l4523"><span class="ln">4523 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::scatter_reduce(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4524"><span class="ln">4524 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_reduce_two::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src, reduce, include_self);</span>
<a name="l4525"><span class="ln">4525 </span></a><span class="s0">}</span>
<a name="l4526"><span class="ln">4526 </span></a>
<a name="l4527"><span class="ln">4527 </span></a><span class="s3">// aten::scatter_reduce_.two(Tensor(a!) self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -&gt; Tensor(a!)</span>
<a name="l4528"><span class="ln">4528 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::scatter_reduce_(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; src, c10::string_view reduce, </span><span class="s1">bool </span><span class="s0">include_self) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4529"><span class="ln">4529 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::scatter_reduce__two::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, src, reduce, include_self);</span>
<a name="l4530"><span class="ln">4530 </span></a><span class="s0">}</span>
<a name="l4531"><span class="ln">4531 </span></a>
<a name="l4532"><span class="ln">4532 </span></a><span class="s3">// aten::eq_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4533"><span class="ln">4533 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::eq_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4534"><span class="ln">4534 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::eq__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4535"><span class="ln">4535 </span></a><span class="s0">}</span>
<a name="l4536"><span class="ln">4536 </span></a>
<a name="l4537"><span class="ln">4537 </span></a><span class="s3">// aten::eq_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4538"><span class="ln">4538 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::eq_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4539"><span class="ln">4539 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::eq__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4540"><span class="ln">4540 </span></a><span class="s0">}</span>
<a name="l4541"><span class="ln">4541 </span></a>
<a name="l4542"><span class="ln">4542 </span></a><span class="s3">// aten::bitwise_and.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4543"><span class="ln">4543 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_and(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4544"><span class="ln">4544 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_and_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4545"><span class="ln">4545 </span></a><span class="s0">}</span>
<a name="l4546"><span class="ln">4546 </span></a>
<a name="l4547"><span class="ln">4547 </span></a><span class="s3">// aten::bitwise_and.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4548"><span class="ln">4548 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_and(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4549"><span class="ln">4549 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_and_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4550"><span class="ln">4550 </span></a><span class="s0">}</span>
<a name="l4551"><span class="ln">4551 </span></a>
<a name="l4552"><span class="ln">4552 </span></a><span class="s3">// aten::bitwise_and_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4553"><span class="ln">4553 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_and_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4554"><span class="ln">4554 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_and__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4555"><span class="ln">4555 </span></a><span class="s0">}</span>
<a name="l4556"><span class="ln">4556 </span></a>
<a name="l4557"><span class="ln">4557 </span></a><span class="s3">// aten::bitwise_and_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4558"><span class="ln">4558 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_and_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4559"><span class="ln">4559 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_and__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4560"><span class="ln">4560 </span></a><span class="s0">}</span>
<a name="l4561"><span class="ln">4561 </span></a>
<a name="l4562"><span class="ln">4562 </span></a><span class="s3">// aten::__and__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4563"><span class="ln">4563 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__and__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4564"><span class="ln">4564 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__and___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4565"><span class="ln">4565 </span></a><span class="s0">}</span>
<a name="l4566"><span class="ln">4566 </span></a>
<a name="l4567"><span class="ln">4567 </span></a><span class="s3">// aten::__and__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4568"><span class="ln">4568 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__and__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4569"><span class="ln">4569 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__and___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4570"><span class="ln">4570 </span></a><span class="s0">}</span>
<a name="l4571"><span class="ln">4571 </span></a>
<a name="l4572"><span class="ln">4572 </span></a><span class="s3">// aten::__iand__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4573"><span class="ln">4573 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__iand__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4574"><span class="ln">4574 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__iand___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4575"><span class="ln">4575 </span></a><span class="s0">}</span>
<a name="l4576"><span class="ln">4576 </span></a>
<a name="l4577"><span class="ln">4577 </span></a><span class="s3">// aten::__iand__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4578"><span class="ln">4578 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__iand__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4579"><span class="ln">4579 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__iand___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4580"><span class="ln">4580 </span></a><span class="s0">}</span>
<a name="l4581"><span class="ln">4581 </span></a>
<a name="l4582"><span class="ln">4582 </span></a><span class="s3">// aten::bitwise_or.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4583"><span class="ln">4583 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_or(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4584"><span class="ln">4584 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_or_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4585"><span class="ln">4585 </span></a><span class="s0">}</span>
<a name="l4586"><span class="ln">4586 </span></a>
<a name="l4587"><span class="ln">4587 </span></a><span class="s3">// aten::bitwise_or.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4588"><span class="ln">4588 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_or(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4589"><span class="ln">4589 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_or_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4590"><span class="ln">4590 </span></a><span class="s0">}</span>
<a name="l4591"><span class="ln">4591 </span></a>
<a name="l4592"><span class="ln">4592 </span></a><span class="s3">// aten::bitwise_or_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4593"><span class="ln">4593 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_or_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4594"><span class="ln">4594 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_or__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4595"><span class="ln">4595 </span></a><span class="s0">}</span>
<a name="l4596"><span class="ln">4596 </span></a>
<a name="l4597"><span class="ln">4597 </span></a><span class="s3">// aten::bitwise_or_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4598"><span class="ln">4598 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_or_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4599"><span class="ln">4599 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_or__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4600"><span class="ln">4600 </span></a><span class="s0">}</span>
<a name="l4601"><span class="ln">4601 </span></a>
<a name="l4602"><span class="ln">4602 </span></a><span class="s3">// aten::__or__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4603"><span class="ln">4603 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__or__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4604"><span class="ln">4604 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__or___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4605"><span class="ln">4605 </span></a><span class="s0">}</span>
<a name="l4606"><span class="ln">4606 </span></a>
<a name="l4607"><span class="ln">4607 </span></a><span class="s3">// aten::__or__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4608"><span class="ln">4608 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__or__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4609"><span class="ln">4609 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__or___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4610"><span class="ln">4610 </span></a><span class="s0">}</span>
<a name="l4611"><span class="ln">4611 </span></a>
<a name="l4612"><span class="ln">4612 </span></a><span class="s3">// aten::__ior__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4613"><span class="ln">4613 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__ior__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4614"><span class="ln">4614 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__ior___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4615"><span class="ln">4615 </span></a><span class="s0">}</span>
<a name="l4616"><span class="ln">4616 </span></a>
<a name="l4617"><span class="ln">4617 </span></a><span class="s3">// aten::__ior__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4618"><span class="ln">4618 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__ior__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4619"><span class="ln">4619 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__ior___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4620"><span class="ln">4620 </span></a><span class="s0">}</span>
<a name="l4621"><span class="ln">4621 </span></a>
<a name="l4622"><span class="ln">4622 </span></a><span class="s3">// aten::bitwise_xor.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4623"><span class="ln">4623 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_xor(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4624"><span class="ln">4624 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_xor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4625"><span class="ln">4625 </span></a><span class="s0">}</span>
<a name="l4626"><span class="ln">4626 </span></a>
<a name="l4627"><span class="ln">4627 </span></a><span class="s3">// aten::bitwise_xor.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4628"><span class="ln">4628 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_xor(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4629"><span class="ln">4629 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_xor_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4630"><span class="ln">4630 </span></a><span class="s0">}</span>
<a name="l4631"><span class="ln">4631 </span></a>
<a name="l4632"><span class="ln">4632 </span></a><span class="s3">// aten::bitwise_xor_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4633"><span class="ln">4633 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_xor_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4634"><span class="ln">4634 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_xor__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4635"><span class="ln">4635 </span></a><span class="s0">}</span>
<a name="l4636"><span class="ln">4636 </span></a>
<a name="l4637"><span class="ln">4637 </span></a><span class="s3">// aten::bitwise_xor_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4638"><span class="ln">4638 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_xor_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4639"><span class="ln">4639 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_xor__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4640"><span class="ln">4640 </span></a><span class="s0">}</span>
<a name="l4641"><span class="ln">4641 </span></a>
<a name="l4642"><span class="ln">4642 </span></a><span class="s3">// aten::__xor__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4643"><span class="ln">4643 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__xor__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4644"><span class="ln">4644 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__xor___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4645"><span class="ln">4645 </span></a><span class="s0">}</span>
<a name="l4646"><span class="ln">4646 </span></a>
<a name="l4647"><span class="ln">4647 </span></a><span class="s3">// aten::__xor__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4648"><span class="ln">4648 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__xor__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4649"><span class="ln">4649 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__xor___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4650"><span class="ln">4650 </span></a><span class="s0">}</span>
<a name="l4651"><span class="ln">4651 </span></a>
<a name="l4652"><span class="ln">4652 </span></a><span class="s3">// aten::__ixor__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4653"><span class="ln">4653 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__ixor__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4654"><span class="ln">4654 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__ixor___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4655"><span class="ln">4655 </span></a><span class="s0">}</span>
<a name="l4656"><span class="ln">4656 </span></a>
<a name="l4657"><span class="ln">4657 </span></a><span class="s3">// aten::__ixor__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4658"><span class="ln">4658 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__ixor__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4659"><span class="ln">4659 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__ixor___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4660"><span class="ln">4660 </span></a><span class="s0">}</span>
<a name="l4661"><span class="ln">4661 </span></a>
<a name="l4662"><span class="ln">4662 </span></a><span class="s3">// aten::__lshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4663"><span class="ln">4663 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__lshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4664"><span class="ln">4664 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__lshift___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4665"><span class="ln">4665 </span></a><span class="s0">}</span>
<a name="l4666"><span class="ln">4666 </span></a>
<a name="l4667"><span class="ln">4667 </span></a><span class="s3">// aten::__lshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4668"><span class="ln">4668 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__lshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4669"><span class="ln">4669 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__lshift___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4670"><span class="ln">4670 </span></a><span class="s0">}</span>
<a name="l4671"><span class="ln">4671 </span></a>
<a name="l4672"><span class="ln">4672 </span></a><span class="s3">// aten::__ilshift__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4673"><span class="ln">4673 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__ilshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4674"><span class="ln">4674 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__ilshift___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4675"><span class="ln">4675 </span></a><span class="s0">}</span>
<a name="l4676"><span class="ln">4676 </span></a>
<a name="l4677"><span class="ln">4677 </span></a><span class="s3">// aten::__ilshift__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4678"><span class="ln">4678 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__ilshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4679"><span class="ln">4679 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__ilshift___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4680"><span class="ln">4680 </span></a><span class="s0">}</span>
<a name="l4681"><span class="ln">4681 </span></a>
<a name="l4682"><span class="ln">4682 </span></a><span class="s3">// aten::bitwise_left_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4683"><span class="ln">4683 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_left_shift(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4684"><span class="ln">4684 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_left_shift_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4685"><span class="ln">4685 </span></a><span class="s0">}</span>
<a name="l4686"><span class="ln">4686 </span></a>
<a name="l4687"><span class="ln">4687 </span></a><span class="s3">// aten::bitwise_left_shift_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4688"><span class="ln">4688 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_left_shift_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4689"><span class="ln">4689 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_left_shift__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4690"><span class="ln">4690 </span></a><span class="s0">}</span>
<a name="l4691"><span class="ln">4691 </span></a>
<a name="l4692"><span class="ln">4692 </span></a><span class="s3">// aten::bitwise_left_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4693"><span class="ln">4693 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_left_shift(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4694"><span class="ln">4694 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_left_shift_Tensor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4695"><span class="ln">4695 </span></a><span class="s0">}</span>
<a name="l4696"><span class="ln">4696 </span></a>
<a name="l4697"><span class="ln">4697 </span></a><span class="s3">// aten::bitwise_left_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4698"><span class="ln">4698 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_left_shift_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4699"><span class="ln">4699 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_left_shift__Tensor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4700"><span class="ln">4700 </span></a><span class="s0">}</span>
<a name="l4701"><span class="ln">4701 </span></a>
<a name="l4702"><span class="ln">4702 </span></a><span class="s3">// aten::__rshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4703"><span class="ln">4703 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__rshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4704"><span class="ln">4704 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__rshift___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4705"><span class="ln">4705 </span></a><span class="s0">}</span>
<a name="l4706"><span class="ln">4706 </span></a>
<a name="l4707"><span class="ln">4707 </span></a><span class="s3">// aten::__rshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4708"><span class="ln">4708 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::__rshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4709"><span class="ln">4709 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__rshift___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4710"><span class="ln">4710 </span></a><span class="s0">}</span>
<a name="l4711"><span class="ln">4711 </span></a>
<a name="l4712"><span class="ln">4712 </span></a><span class="s3">// aten::__irshift__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4713"><span class="ln">4713 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__irshift__(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4714"><span class="ln">4714 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__irshift___Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4715"><span class="ln">4715 </span></a><span class="s0">}</span>
<a name="l4716"><span class="ln">4716 </span></a>
<a name="l4717"><span class="ln">4717 </span></a><span class="s3">// aten::__irshift__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4718"><span class="ln">4718 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::__irshift__(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4719"><span class="ln">4719 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::__irshift___Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4720"><span class="ln">4720 </span></a><span class="s0">}</span>
<a name="l4721"><span class="ln">4721 </span></a>
<a name="l4722"><span class="ln">4722 </span></a><span class="s3">// aten::bitwise_right_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4723"><span class="ln">4723 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_right_shift(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4724"><span class="ln">4724 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_right_shift_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4725"><span class="ln">4725 </span></a><span class="s0">}</span>
<a name="l4726"><span class="ln">4726 </span></a>
<a name="l4727"><span class="ln">4727 </span></a><span class="s3">// aten::bitwise_right_shift_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4728"><span class="ln">4728 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_right_shift_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4729"><span class="ln">4729 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_right_shift__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4730"><span class="ln">4730 </span></a><span class="s0">}</span>
<a name="l4731"><span class="ln">4731 </span></a>
<a name="l4732"><span class="ln">4732 </span></a><span class="s3">// aten::bitwise_right_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4733"><span class="ln">4733 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::bitwise_right_shift(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4734"><span class="ln">4734 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_right_shift_Tensor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4735"><span class="ln">4735 </span></a><span class="s0">}</span>
<a name="l4736"><span class="ln">4736 </span></a>
<a name="l4737"><span class="ln">4737 </span></a><span class="s3">// aten::bitwise_right_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4738"><span class="ln">4738 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::bitwise_right_shift_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4739"><span class="ln">4739 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::bitwise_right_shift__Tensor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4740"><span class="ln">4740 </span></a><span class="s0">}</span>
<a name="l4741"><span class="ln">4741 </span></a>
<a name="l4742"><span class="ln">4742 </span></a><span class="s3">// aten::tril_(Tensor(a!) self, int diagonal=0) -&gt; Tensor(a!)</span>
<a name="l4743"><span class="ln">4743 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::tril_(int64_t diagonal) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4744"><span class="ln">4744 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tril_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), diagonal);</span>
<a name="l4745"><span class="ln">4745 </span></a><span class="s0">}</span>
<a name="l4746"><span class="ln">4746 </span></a>
<a name="l4747"><span class="ln">4747 </span></a><span class="s3">// aten::triu_(Tensor(a!) self, int diagonal=0) -&gt; Tensor(a!)</span>
<a name="l4748"><span class="ln">4748 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::triu_(int64_t diagonal) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4749"><span class="ln">4749 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::triu_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), diagonal);</span>
<a name="l4750"><span class="ln">4750 </span></a><span class="s0">}</span>
<a name="l4751"><span class="ln">4751 </span></a>
<a name="l4752"><span class="ln">4752 </span></a><span class="s3">// aten::digamma_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l4753"><span class="ln">4753 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::digamma_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4754"><span class="ln">4754 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::digamma_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4755"><span class="ln">4755 </span></a><span class="s0">}</span>
<a name="l4756"><span class="ln">4756 </span></a>
<a name="l4757"><span class="ln">4757 </span></a><span class="s3">// aten::lerp_.Scalar(Tensor(a!) self, Tensor end, Scalar weight) -&gt; Tensor(a!)</span>
<a name="l4758"><span class="ln">4758 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::lerp_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; weight) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4759"><span class="ln">4759 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lerp__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), end, weight);</span>
<a name="l4760"><span class="ln">4760 </span></a><span class="s0">}</span>
<a name="l4761"><span class="ln">4761 </span></a>
<a name="l4762"><span class="ln">4762 </span></a><span class="s3">// aten::lerp_.Tensor(Tensor(a!) self, Tensor end, Tensor weight) -&gt; Tensor(a!)</span>
<a name="l4763"><span class="ln">4763 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::lerp_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; weight) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4764"><span class="ln">4764 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lerp__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), end, weight);</span>
<a name="l4765"><span class="ln">4765 </span></a><span class="s0">}</span>
<a name="l4766"><span class="ln">4766 </span></a>
<a name="l4767"><span class="ln">4767 </span></a><span class="s3">// aten::addbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<a name="l4768"><span class="ln">4768 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::addbmm_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4769"><span class="ln">4769 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addbmm_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), batch1, batch2, beta, alpha);</span>
<a name="l4770"><span class="ln">4770 </span></a><span class="s0">}</span>
<a name="l4771"><span class="ln">4771 </span></a>
<a name="l4772"><span class="ln">4772 </span></a><span class="s3">// aten::addbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<a name="l4773"><span class="ln">4773 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::addbmm(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; batch2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; beta, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; alpha) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4774"><span class="ln">4774 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addbmm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), batch1, batch2, beta, alpha);</span>
<a name="l4775"><span class="ln">4775 </span></a><span class="s0">}</span>
<a name="l4776"><span class="ln">4776 </span></a>
<a name="l4777"><span class="ln">4777 </span></a><span class="s3">// aten::random_.from(Tensor(a!) self, int from, int? to, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4778"><span class="ln">4778 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::random_(int64_t from, ::std::optional&lt;int64_t&gt; to, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4779"><span class="ln">4779 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::random__from::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), from, to, generator);</span>
<a name="l4780"><span class="ln">4780 </span></a><span class="s0">}</span>
<a name="l4781"><span class="ln">4781 </span></a>
<a name="l4782"><span class="ln">4782 </span></a><span class="s3">// aten::random_.to(Tensor(a!) self, int to, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4783"><span class="ln">4783 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::random_(int64_t to, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4784"><span class="ln">4784 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::random__to::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), to, generator);</span>
<a name="l4785"><span class="ln">4785 </span></a><span class="s0">}</span>
<a name="l4786"><span class="ln">4786 </span></a>
<a name="l4787"><span class="ln">4787 </span></a><span class="s3">// aten::random_(Tensor(a!) self, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4788"><span class="ln">4788 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::random_(::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4789"><span class="ln">4789 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::random_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), generator);</span>
<a name="l4790"><span class="ln">4790 </span></a><span class="s0">}</span>
<a name="l4791"><span class="ln">4791 </span></a>
<a name="l4792"><span class="ln">4792 </span></a><span class="s3">// aten::uniform_(Tensor(a!) self, float from=0, float to=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4793"><span class="ln">4793 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::uniform_(</span><span class="s1">double </span><span class="s0">from, </span><span class="s1">double </span><span class="s0">to, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4794"><span class="ln">4794 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::uniform_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), from, to, generator);</span>
<a name="l4795"><span class="ln">4795 </span></a><span class="s0">}</span>
<a name="l4796"><span class="ln">4796 </span></a>
<a name="l4797"><span class="ln">4797 </span></a><span class="s3">// aten::cauchy_(Tensor(a!) self, float median=0, float sigma=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4798"><span class="ln">4798 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::cauchy_(</span><span class="s1">double </span><span class="s0">median, </span><span class="s1">double </span><span class="s0">sigma, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4799"><span class="ln">4799 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cauchy_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), median, sigma, generator);</span>
<a name="l4800"><span class="ln">4800 </span></a><span class="s0">}</span>
<a name="l4801"><span class="ln">4801 </span></a>
<a name="l4802"><span class="ln">4802 </span></a><span class="s3">// aten::log_normal_(Tensor(a!) self, float mean=1, float std=2, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4803"><span class="ln">4803 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::log_normal_(</span><span class="s1">double </span><span class="s0">mean, </span><span class="s1">double </span><span class="s0">std, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4804"><span class="ln">4804 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::log_normal_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mean, std, generator);</span>
<a name="l4805"><span class="ln">4805 </span></a><span class="s0">}</span>
<a name="l4806"><span class="ln">4806 </span></a>
<a name="l4807"><span class="ln">4807 </span></a><span class="s3">// aten::exponential_(Tensor(a!) self, float lambd=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4808"><span class="ln">4808 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::exponential_(</span><span class="s1">double </span><span class="s0">lambd, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4809"><span class="ln">4809 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::exponential_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), lambd, generator);</span>
<a name="l4810"><span class="ln">4810 </span></a><span class="s0">}</span>
<a name="l4811"><span class="ln">4811 </span></a>
<a name="l4812"><span class="ln">4812 </span></a><span class="s3">// aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l4813"><span class="ln">4813 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::geometric_(</span><span class="s1">double </span><span class="s0">p, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4814"><span class="ln">4814 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::geometric_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, generator);</span>
<a name="l4815"><span class="ln">4815 </span></a><span class="s0">}</span>
<a name="l4816"><span class="ln">4816 </span></a>
<a name="l4817"><span class="ln">4817 </span></a><span class="s3">// aten::diag(Tensor self, int diagonal=0) -&gt; Tensor</span>
<a name="l4818"><span class="ln">4818 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::diag(int64_t diagonal) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4819"><span class="ln">4819 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::diag::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), diagonal);</span>
<a name="l4820"><span class="ln">4820 </span></a><span class="s0">}</span>
<a name="l4821"><span class="ln">4821 </span></a>
<a name="l4822"><span class="ln">4822 </span></a><span class="s3">// aten::cross(Tensor self, Tensor other, int? dim=None) -&gt; Tensor</span>
<a name="l4823"><span class="ln">4823 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cross(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, ::std::optional&lt;int64_t&gt; dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4824"><span class="ln">4824 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cross::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, dim);</span>
<a name="l4825"><span class="ln">4825 </span></a><span class="s0">}</span>
<a name="l4826"><span class="ln">4826 </span></a>
<a name="l4827"><span class="ln">4827 </span></a><span class="s3">// aten::triu(Tensor self, int diagonal=0) -&gt; Tensor</span>
<a name="l4828"><span class="ln">4828 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::triu(int64_t diagonal) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4829"><span class="ln">4829 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::triu::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), diagonal);</span>
<a name="l4830"><span class="ln">4830 </span></a><span class="s0">}</span>
<a name="l4831"><span class="ln">4831 </span></a>
<a name="l4832"><span class="ln">4832 </span></a><span class="s3">// aten::tril(Tensor self, int diagonal=0) -&gt; Tensor</span>
<a name="l4833"><span class="ln">4833 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::tril(int64_t diagonal) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4834"><span class="ln">4834 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::tril::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), diagonal);</span>
<a name="l4835"><span class="ln">4835 </span></a><span class="s0">}</span>
<a name="l4836"><span class="ln">4836 </span></a>
<a name="l4837"><span class="ln">4837 </span></a><span class="s3">// aten::trace(Tensor self) -&gt; Tensor</span>
<a name="l4838"><span class="ln">4838 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::trace() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4839"><span class="ln">4839 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::trace::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l4840"><span class="ln">4840 </span></a><span class="s0">}</span>
<a name="l4841"><span class="ln">4841 </span></a>
<a name="l4842"><span class="ln">4842 </span></a><span class="s3">// aten::ne.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4843"><span class="ln">4843 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ne(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4844"><span class="ln">4844 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ne_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4845"><span class="ln">4845 </span></a><span class="s0">}</span>
<a name="l4846"><span class="ln">4846 </span></a>
<a name="l4847"><span class="ln">4847 </span></a><span class="s3">// aten::ne.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4848"><span class="ln">4848 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ne(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4849"><span class="ln">4849 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ne_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4850"><span class="ln">4850 </span></a><span class="s0">}</span>
<a name="l4851"><span class="ln">4851 </span></a>
<a name="l4852"><span class="ln">4852 </span></a><span class="s3">// aten::ne_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4853"><span class="ln">4853 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::ne_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4854"><span class="ln">4854 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ne__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4855"><span class="ln">4855 </span></a><span class="s0">}</span>
<a name="l4856"><span class="ln">4856 </span></a>
<a name="l4857"><span class="ln">4857 </span></a><span class="s3">// aten::ne_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4858"><span class="ln">4858 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::ne_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4859"><span class="ln">4859 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ne__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4860"><span class="ln">4860 </span></a><span class="s0">}</span>
<a name="l4861"><span class="ln">4861 </span></a>
<a name="l4862"><span class="ln">4862 </span></a><span class="s3">// aten::not_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4863"><span class="ln">4863 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::not_equal(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4864"><span class="ln">4864 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::not_equal_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4865"><span class="ln">4865 </span></a><span class="s0">}</span>
<a name="l4866"><span class="ln">4866 </span></a>
<a name="l4867"><span class="ln">4867 </span></a><span class="s3">// aten::not_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4868"><span class="ln">4868 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::not_equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4869"><span class="ln">4869 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::not_equal_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4870"><span class="ln">4870 </span></a><span class="s0">}</span>
<a name="l4871"><span class="ln">4871 </span></a>
<a name="l4872"><span class="ln">4872 </span></a><span class="s3">// aten::not_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4873"><span class="ln">4873 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::not_equal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4874"><span class="ln">4874 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::not_equal__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4875"><span class="ln">4875 </span></a><span class="s0">}</span>
<a name="l4876"><span class="ln">4876 </span></a>
<a name="l4877"><span class="ln">4877 </span></a><span class="s3">// aten::not_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4878"><span class="ln">4878 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::not_equal_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4879"><span class="ln">4879 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::not_equal__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4880"><span class="ln">4880 </span></a><span class="s0">}</span>
<a name="l4881"><span class="ln">4881 </span></a>
<a name="l4882"><span class="ln">4882 </span></a><span class="s3">// aten::eq.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4883"><span class="ln">4883 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::eq(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4884"><span class="ln">4884 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::eq_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4885"><span class="ln">4885 </span></a><span class="s0">}</span>
<a name="l4886"><span class="ln">4886 </span></a>
<a name="l4887"><span class="ln">4887 </span></a><span class="s3">// aten::eq.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4888"><span class="ln">4888 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::eq(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4889"><span class="ln">4889 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::eq_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4890"><span class="ln">4890 </span></a><span class="s0">}</span>
<a name="l4891"><span class="ln">4891 </span></a>
<a name="l4892"><span class="ln">4892 </span></a><span class="s3">// aten::ge.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4893"><span class="ln">4893 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ge(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4894"><span class="ln">4894 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ge_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4895"><span class="ln">4895 </span></a><span class="s0">}</span>
<a name="l4896"><span class="ln">4896 </span></a>
<a name="l4897"><span class="ln">4897 </span></a><span class="s3">// aten::ge.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4898"><span class="ln">4898 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ge(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4899"><span class="ln">4899 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ge_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4900"><span class="ln">4900 </span></a><span class="s0">}</span>
<a name="l4901"><span class="ln">4901 </span></a>
<a name="l4902"><span class="ln">4902 </span></a><span class="s3">// aten::ge_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4903"><span class="ln">4903 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::ge_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4904"><span class="ln">4904 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ge__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4905"><span class="ln">4905 </span></a><span class="s0">}</span>
<a name="l4906"><span class="ln">4906 </span></a>
<a name="l4907"><span class="ln">4907 </span></a><span class="s3">// aten::ge_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4908"><span class="ln">4908 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::ge_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4909"><span class="ln">4909 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ge__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4910"><span class="ln">4910 </span></a><span class="s0">}</span>
<a name="l4911"><span class="ln">4911 </span></a>
<a name="l4912"><span class="ln">4912 </span></a><span class="s3">// aten::greater_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4913"><span class="ln">4913 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::greater_equal(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4914"><span class="ln">4914 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater_equal_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4915"><span class="ln">4915 </span></a><span class="s0">}</span>
<a name="l4916"><span class="ln">4916 </span></a>
<a name="l4917"><span class="ln">4917 </span></a><span class="s3">// aten::greater_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4918"><span class="ln">4918 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::greater_equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4919"><span class="ln">4919 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater_equal_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4920"><span class="ln">4920 </span></a><span class="s0">}</span>
<a name="l4921"><span class="ln">4921 </span></a>
<a name="l4922"><span class="ln">4922 </span></a><span class="s3">// aten::greater_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4923"><span class="ln">4923 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::greater_equal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4924"><span class="ln">4924 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater_equal__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4925"><span class="ln">4925 </span></a><span class="s0">}</span>
<a name="l4926"><span class="ln">4926 </span></a>
<a name="l4927"><span class="ln">4927 </span></a><span class="s3">// aten::greater_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4928"><span class="ln">4928 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::greater_equal_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4929"><span class="ln">4929 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater_equal__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4930"><span class="ln">4930 </span></a><span class="s0">}</span>
<a name="l4931"><span class="ln">4931 </span></a>
<a name="l4932"><span class="ln">4932 </span></a><span class="s3">// aten::le.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4933"><span class="ln">4933 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::le(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4934"><span class="ln">4934 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::le_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4935"><span class="ln">4935 </span></a><span class="s0">}</span>
<a name="l4936"><span class="ln">4936 </span></a>
<a name="l4937"><span class="ln">4937 </span></a><span class="s3">// aten::le.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4938"><span class="ln">4938 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::le(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4939"><span class="ln">4939 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::le_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4940"><span class="ln">4940 </span></a><span class="s0">}</span>
<a name="l4941"><span class="ln">4941 </span></a>
<a name="l4942"><span class="ln">4942 </span></a><span class="s3">// aten::le_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4943"><span class="ln">4943 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::le_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4944"><span class="ln">4944 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::le__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4945"><span class="ln">4945 </span></a><span class="s0">}</span>
<a name="l4946"><span class="ln">4946 </span></a>
<a name="l4947"><span class="ln">4947 </span></a><span class="s3">// aten::le_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4948"><span class="ln">4948 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::le_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4949"><span class="ln">4949 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::le__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4950"><span class="ln">4950 </span></a><span class="s0">}</span>
<a name="l4951"><span class="ln">4951 </span></a>
<a name="l4952"><span class="ln">4952 </span></a><span class="s3">// aten::less_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4953"><span class="ln">4953 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::less_equal(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4954"><span class="ln">4954 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less_equal_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4955"><span class="ln">4955 </span></a><span class="s0">}</span>
<a name="l4956"><span class="ln">4956 </span></a>
<a name="l4957"><span class="ln">4957 </span></a><span class="s3">// aten::less_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4958"><span class="ln">4958 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::less_equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4959"><span class="ln">4959 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less_equal_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4960"><span class="ln">4960 </span></a><span class="s0">}</span>
<a name="l4961"><span class="ln">4961 </span></a>
<a name="l4962"><span class="ln">4962 </span></a><span class="s3">// aten::less_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4963"><span class="ln">4963 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::less_equal_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4964"><span class="ln">4964 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less_equal__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4965"><span class="ln">4965 </span></a><span class="s0">}</span>
<a name="l4966"><span class="ln">4966 </span></a>
<a name="l4967"><span class="ln">4967 </span></a><span class="s3">// aten::less_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4968"><span class="ln">4968 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::less_equal_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4969"><span class="ln">4969 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less_equal__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4970"><span class="ln">4970 </span></a><span class="s0">}</span>
<a name="l4971"><span class="ln">4971 </span></a>
<a name="l4972"><span class="ln">4972 </span></a><span class="s3">// aten::gt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4973"><span class="ln">4973 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::gt(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4974"><span class="ln">4974 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gt_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4975"><span class="ln">4975 </span></a><span class="s0">}</span>
<a name="l4976"><span class="ln">4976 </span></a>
<a name="l4977"><span class="ln">4977 </span></a><span class="s3">// aten::gt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4978"><span class="ln">4978 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::gt(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4979"><span class="ln">4979 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gt_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4980"><span class="ln">4980 </span></a><span class="s0">}</span>
<a name="l4981"><span class="ln">4981 </span></a>
<a name="l4982"><span class="ln">4982 </span></a><span class="s3">// aten::gt_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l4983"><span class="ln">4983 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::gt_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4984"><span class="ln">4984 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gt__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4985"><span class="ln">4985 </span></a><span class="s0">}</span>
<a name="l4986"><span class="ln">4986 </span></a>
<a name="l4987"><span class="ln">4987 </span></a><span class="s3">// aten::gt_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l4988"><span class="ln">4988 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::gt_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4989"><span class="ln">4989 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gt__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4990"><span class="ln">4990 </span></a><span class="s0">}</span>
<a name="l4991"><span class="ln">4991 </span></a>
<a name="l4992"><span class="ln">4992 </span></a><span class="s3">// aten::greater.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l4993"><span class="ln">4993 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::greater(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4994"><span class="ln">4994 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l4995"><span class="ln">4995 </span></a><span class="s0">}</span>
<a name="l4996"><span class="ln">4996 </span></a>
<a name="l4997"><span class="ln">4997 </span></a><span class="s3">// aten::greater.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l4998"><span class="ln">4998 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::greater(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l4999"><span class="ln">4999 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5000"><span class="ln">5000 </span></a><span class="s0">}</span>
<a name="l5001"><span class="ln">5001 </span></a>
<a name="l5002"><span class="ln">5002 </span></a><span class="s3">// aten::greater_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l5003"><span class="ln">5003 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::greater_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5004"><span class="ln">5004 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5005"><span class="ln">5005 </span></a><span class="s0">}</span>
<a name="l5006"><span class="ln">5006 </span></a>
<a name="l5007"><span class="ln">5007 </span></a><span class="s3">// aten::greater_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5008"><span class="ln">5008 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::greater_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5009"><span class="ln">5009 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::greater__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5010"><span class="ln">5010 </span></a><span class="s0">}</span>
<a name="l5011"><span class="ln">5011 </span></a>
<a name="l5012"><span class="ln">5012 </span></a><span class="s3">// aten::lt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l5013"><span class="ln">5013 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lt(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5014"><span class="ln">5014 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lt_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5015"><span class="ln">5015 </span></a><span class="s0">}</span>
<a name="l5016"><span class="ln">5016 </span></a>
<a name="l5017"><span class="ln">5017 </span></a><span class="s3">// aten::lt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5018"><span class="ln">5018 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lt(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5019"><span class="ln">5019 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lt_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5020"><span class="ln">5020 </span></a><span class="s0">}</span>
<a name="l5021"><span class="ln">5021 </span></a>
<a name="l5022"><span class="ln">5022 </span></a><span class="s3">// aten::lt_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l5023"><span class="ln">5023 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::lt_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5024"><span class="ln">5024 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lt__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5025"><span class="ln">5025 </span></a><span class="s0">}</span>
<a name="l5026"><span class="ln">5026 </span></a>
<a name="l5027"><span class="ln">5027 </span></a><span class="s3">// aten::lt_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5028"><span class="ln">5028 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::lt_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5029"><span class="ln">5029 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lt__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5030"><span class="ln">5030 </span></a><span class="s0">}</span>
<a name="l5031"><span class="ln">5031 </span></a>
<a name="l5032"><span class="ln">5032 </span></a><span class="s3">// aten::less.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l5033"><span class="ln">5033 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::less(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5034"><span class="ln">5034 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5035"><span class="ln">5035 </span></a><span class="s0">}</span>
<a name="l5036"><span class="ln">5036 </span></a>
<a name="l5037"><span class="ln">5037 </span></a><span class="s3">// aten::less.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5038"><span class="ln">5038 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::less(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5039"><span class="ln">5039 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5040"><span class="ln">5040 </span></a><span class="s0">}</span>
<a name="l5041"><span class="ln">5041 </span></a>
<a name="l5042"><span class="ln">5042 </span></a><span class="s3">// aten::less_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l5043"><span class="ln">5043 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::less_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5044"><span class="ln">5044 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5045"><span class="ln">5045 </span></a><span class="s0">}</span>
<a name="l5046"><span class="ln">5046 </span></a>
<a name="l5047"><span class="ln">5047 </span></a><span class="s3">// aten::less_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5048"><span class="ln">5048 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::less_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5049"><span class="ln">5049 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::less__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5050"><span class="ln">5050 </span></a><span class="s0">}</span>
<a name="l5051"><span class="ln">5051 </span></a>
<a name="l5052"><span class="ln">5052 </span></a><span class="s3">// aten::take(Tensor self, Tensor index) -&gt; Tensor</span>
<a name="l5053"><span class="ln">5053 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::take(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5054"><span class="ln">5054 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::take::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), index);</span>
<a name="l5055"><span class="ln">5055 </span></a><span class="s0">}</span>
<a name="l5056"><span class="ln">5056 </span></a>
<a name="l5057"><span class="ln">5057 </span></a><span class="s3">// aten::take_along_dim(Tensor self, Tensor indices, int? dim=None) -&gt; Tensor</span>
<a name="l5058"><span class="ln">5058 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::take_along_dim(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; indices, ::std::optional&lt;int64_t&gt; dim) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5059"><span class="ln">5059 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::take_along_dim::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), indices, dim);</span>
<a name="l5060"><span class="ln">5060 </span></a><span class="s0">}</span>
<a name="l5061"><span class="ln">5061 </span></a>
<a name="l5062"><span class="ln">5062 </span></a><span class="s3">// aten::index_select(Tensor self, int dim, Tensor index) -&gt; Tensor</span>
<a name="l5063"><span class="ln">5063 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_select(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5064"><span class="ln">5064 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_select::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index);</span>
<a name="l5065"><span class="ln">5065 </span></a><span class="s0">}</span>
<a name="l5066"><span class="ln">5066 </span></a>
<a name="l5067"><span class="ln">5067 </span></a><span class="s3">// aten::index_select.dimname(Tensor self, Dimname dim, Tensor index) -&gt; Tensor</span>
<a name="l5068"><span class="ln">5068 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::index_select(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5069"><span class="ln">5069 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::index_select_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index);</span>
<a name="l5070"><span class="ln">5070 </span></a><span class="s0">}</span>
<a name="l5071"><span class="ln">5071 </span></a>
<a name="l5072"><span class="ln">5072 </span></a><span class="s3">// aten::masked_select(Tensor self, Tensor mask) -&gt; Tensor</span>
<a name="l5073"><span class="ln">5073 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::masked_select(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; mask) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5074"><span class="ln">5074 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::masked_select::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mask);</span>
<a name="l5075"><span class="ln">5075 </span></a><span class="s0">}</span>
<a name="l5076"><span class="ln">5076 </span></a>
<a name="l5077"><span class="ln">5077 </span></a><span class="s3">// aten::nonzero(Tensor self) -&gt; Tensor</span>
<a name="l5078"><span class="ln">5078 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nonzero() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5079"><span class="ln">5079 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nonzero::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5080"><span class="ln">5080 </span></a><span class="s0">}</span>
<a name="l5081"><span class="ln">5081 </span></a>
<a name="l5082"><span class="ln">5082 </span></a><span class="s3">// aten::nonzero_static(Tensor self, *, SymInt size, int fill_value=-1) -&gt; Tensor</span>
<a name="l5083"><span class="ln">5083 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nonzero_static(int64_t size, int64_t fill_value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5084"><span class="ln">5084 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nonzero_static::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, fill_value);</span>
<a name="l5085"><span class="ln">5085 </span></a><span class="s0">}</span>
<a name="l5086"><span class="ln">5086 </span></a>
<a name="l5087"><span class="ln">5087 </span></a><span class="s3">// aten::nonzero_static(Tensor self, *, SymInt size, int fill_value=-1) -&gt; Tensor</span>
<a name="l5088"><span class="ln">5088 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nonzero_static_symint(c10::SymInt size, int64_t fill_value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5089"><span class="ln">5089 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nonzero_static::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), size, fill_value);</span>
<a name="l5090"><span class="ln">5090 </span></a><span class="s0">}</span>
<a name="l5091"><span class="ln">5091 </span></a>
<a name="l5092"><span class="ln">5092 </span></a><span class="s3">// aten::nonzero_numpy(Tensor self) -&gt; Tensor[]</span>
<a name="l5093"><span class="ln">5093 </span></a><span class="s2">inline </span><span class="s0">::std::vector&lt;at::Tensor&gt; Tensor::nonzero_numpy() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5094"><span class="ln">5094 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nonzero_numpy::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5095"><span class="ln">5095 </span></a><span class="s0">}</span>
<a name="l5096"><span class="ln">5096 </span></a>
<a name="l5097"><span class="ln">5097 </span></a><span class="s3">// aten::argwhere(Tensor self) -&gt; Tensor</span>
<a name="l5098"><span class="ln">5098 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::argwhere() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5099"><span class="ln">5099 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::argwhere::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5100"><span class="ln">5100 </span></a><span class="s0">}</span>
<a name="l5101"><span class="ln">5101 </span></a>
<a name="l5102"><span class="ln">5102 </span></a><span class="s3">// aten::gather(Tensor self, int dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<a name="l5103"><span class="ln">5103 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::gather(int64_t dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">bool </span><span class="s0">sparse_grad) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5104"><span class="ln">5104 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gather::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, sparse_grad);</span>
<a name="l5105"><span class="ln">5105 </span></a><span class="s0">}</span>
<a name="l5106"><span class="ln">5106 </span></a>
<a name="l5107"><span class="ln">5107 </span></a><span class="s3">// aten::gather.dimname(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<a name="l5108"><span class="ln">5108 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::gather(at::Dimname dim, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; index, </span><span class="s1">bool </span><span class="s0">sparse_grad) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5109"><span class="ln">5109 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::gather_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, index, sparse_grad);</span>
<a name="l5110"><span class="ln">5110 </span></a><span class="s0">}</span>
<a name="l5111"><span class="ln">5111 </span></a>
<a name="l5112"><span class="ln">5112 </span></a><span class="s3">// aten::addcmul(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<a name="l5113"><span class="ln">5113 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::addcmul(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5114"><span class="ln">5114 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addcmul::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor1, tensor2, value);</span>
<a name="l5115"><span class="ln">5115 </span></a><span class="s0">}</span>
<a name="l5116"><span class="ln">5116 </span></a>
<a name="l5117"><span class="ln">5117 </span></a><span class="s3">// aten::addcmul_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor(a!)</span>
<a name="l5118"><span class="ln">5118 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::addcmul_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5119"><span class="ln">5119 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addcmul_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor1, tensor2, value);</span>
<a name="l5120"><span class="ln">5120 </span></a><span class="s0">}</span>
<a name="l5121"><span class="ln">5121 </span></a>
<a name="l5122"><span class="ln">5122 </span></a><span class="s3">// aten::addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<a name="l5123"><span class="ln">5123 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::addcdiv(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5124"><span class="ln">5124 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addcdiv::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor1, tensor2, value);</span>
<a name="l5125"><span class="ln">5125 </span></a><span class="s0">}</span>
<a name="l5126"><span class="ln">5126 </span></a>
<a name="l5127"><span class="ln">5127 </span></a><span class="s3">// aten::addcdiv_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor(a!)</span>
<a name="l5128"><span class="ln">5128 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::addcdiv_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor1, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; tensor2, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; value) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5129"><span class="ln">5129 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::addcdiv_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), tensor1, tensor2, value);</span>
<a name="l5130"><span class="ln">5130 </span></a><span class="s0">}</span>
<a name="l5131"><span class="ln">5131 </span></a>
<a name="l5132"><span class="ln">5132 </span></a><span class="s3">// aten::triangular_solve(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False) -&gt; (Tensor solution, Tensor cloned_coefficient)</span>
<a name="l5133"><span class="ln">5133 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::triangular_solve(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; A, </span><span class="s1">bool </span><span class="s0">upper, </span><span class="s1">bool </span><span class="s0">transpose, </span><span class="s1">bool </span><span class="s0">unitriangular) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5134"><span class="ln">5134 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::triangular_solve::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), A, upper, transpose, unitriangular);</span>
<a name="l5135"><span class="ln">5135 </span></a><span class="s0">}</span>
<a name="l5136"><span class="ln">5136 </span></a>
<a name="l5137"><span class="ln">5137 </span></a><span class="s3">// aten::svd(Tensor self, bool some=True, bool compute_uv=True) -&gt; (Tensor U, Tensor S, Tensor V)</span>
<a name="l5138"><span class="ln">5138 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt; Tensor::svd(</span><span class="s1">bool </span><span class="s0">some, </span><span class="s1">bool </span><span class="s0">compute_uv) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5139"><span class="ln">5139 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::svd::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), some, compute_uv);</span>
<a name="l5140"><span class="ln">5140 </span></a><span class="s0">}</span>
<a name="l5141"><span class="ln">5141 </span></a>
<a name="l5142"><span class="ln">5142 </span></a><span class="s3">// aten::swapaxes(Tensor(a) self, int axis0, int axis1) -&gt; Tensor(a)</span>
<a name="l5143"><span class="ln">5143 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::swapaxes(int64_t axis0, int64_t axis1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5144"><span class="ln">5144 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::swapaxes::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), axis0, axis1);</span>
<a name="l5145"><span class="ln">5145 </span></a><span class="s0">}</span>
<a name="l5146"><span class="ln">5146 </span></a>
<a name="l5147"><span class="ln">5147 </span></a><span class="s3">// aten::swapaxes_(Tensor(a!) self, int axis0, int axis1) -&gt; Tensor(a!)</span>
<a name="l5148"><span class="ln">5148 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::swapaxes_(int64_t axis0, int64_t axis1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5149"><span class="ln">5149 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::swapaxes_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), axis0, axis1);</span>
<a name="l5150"><span class="ln">5150 </span></a><span class="s0">}</span>
<a name="l5151"><span class="ln">5151 </span></a>
<a name="l5152"><span class="ln">5152 </span></a><span class="s3">// aten::swapdims(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<a name="l5153"><span class="ln">5153 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::swapdims(int64_t dim0, int64_t dim1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5154"><span class="ln">5154 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::swapdims::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim0, dim1);</span>
<a name="l5155"><span class="ln">5155 </span></a><span class="s0">}</span>
<a name="l5156"><span class="ln">5156 </span></a>
<a name="l5157"><span class="ln">5157 </span></a><span class="s3">// aten::swapdims_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<a name="l5158"><span class="ln">5158 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::swapdims_(int64_t dim0, int64_t dim1) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5159"><span class="ln">5159 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::swapdims_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim0, dim1);</span>
<a name="l5160"><span class="ln">5160 </span></a><span class="s0">}</span>
<a name="l5161"><span class="ln">5161 </span></a>
<a name="l5162"><span class="ln">5162 </span></a><span class="s3">// aten::cholesky(Tensor self, bool upper=False) -&gt; Tensor</span>
<a name="l5163"><span class="ln">5163 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cholesky(</span><span class="s1">bool </span><span class="s0">upper) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5164"><span class="ln">5164 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cholesky::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), upper);</span>
<a name="l5165"><span class="ln">5165 </span></a><span class="s0">}</span>
<a name="l5166"><span class="ln">5166 </span></a>
<a name="l5167"><span class="ln">5167 </span></a><span class="s3">// aten::cholesky_solve(Tensor self, Tensor input2, bool upper=False) -&gt; Tensor</span>
<a name="l5168"><span class="ln">5168 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cholesky_solve(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; input2, </span><span class="s1">bool </span><span class="s0">upper) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5169"><span class="ln">5169 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cholesky_solve::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), input2, upper);</span>
<a name="l5170"><span class="ln">5170 </span></a><span class="s0">}</span>
<a name="l5171"><span class="ln">5171 </span></a>
<a name="l5172"><span class="ln">5172 </span></a><span class="s3">// aten::cholesky_inverse(Tensor self, bool upper=False) -&gt; Tensor</span>
<a name="l5173"><span class="ln">5173 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::cholesky_inverse(</span><span class="s1">bool </span><span class="s0">upper) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5174"><span class="ln">5174 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::cholesky_inverse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), upper);</span>
<a name="l5175"><span class="ln">5175 </span></a><span class="s0">}</span>
<a name="l5176"><span class="ln">5176 </span></a>
<a name="l5177"><span class="ln">5177 </span></a><span class="s3">// aten::qr(Tensor self, bool some=True) -&gt; (Tensor Q, Tensor R)</span>
<a name="l5178"><span class="ln">5178 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::qr(</span><span class="s1">bool </span><span class="s0">some) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5179"><span class="ln">5179 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::qr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), some);</span>
<a name="l5180"><span class="ln">5180 </span></a><span class="s0">}</span>
<a name="l5181"><span class="ln">5181 </span></a>
<a name="l5182"><span class="ln">5182 </span></a><span class="s3">// aten::geqrf(Tensor self) -&gt; (Tensor a, Tensor tau)</span>
<a name="l5183"><span class="ln">5183 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::geqrf() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5184"><span class="ln">5184 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::geqrf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5185"><span class="ln">5185 </span></a><span class="s0">}</span>
<a name="l5186"><span class="ln">5186 </span></a>
<a name="l5187"><span class="ln">5187 </span></a><span class="s3">// aten::orgqr(Tensor self, Tensor input2) -&gt; Tensor</span>
<a name="l5188"><span class="ln">5188 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::orgqr(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; input2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5189"><span class="ln">5189 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::orgqr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), input2);</span>
<a name="l5190"><span class="ln">5190 </span></a><span class="s0">}</span>
<a name="l5191"><span class="ln">5191 </span></a>
<a name="l5192"><span class="ln">5192 </span></a><span class="s3">// aten::ormqr(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False) -&gt; Tensor</span>
<a name="l5193"><span class="ln">5193 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ormqr(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; input2, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; input3, </span><span class="s1">bool </span><span class="s0">left, </span><span class="s1">bool </span><span class="s0">transpose) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5194"><span class="ln">5194 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ormqr::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), input2, input3, left, transpose);</span>
<a name="l5195"><span class="ln">5195 </span></a><span class="s0">}</span>
<a name="l5196"><span class="ln">5196 </span></a>
<a name="l5197"><span class="ln">5197 </span></a><span class="s3">// aten::lu_solve(Tensor self, Tensor LU_data, Tensor LU_pivots) -&gt; Tensor</span>
<a name="l5198"><span class="ln">5198 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lu_solve(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; LU_data, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; LU_pivots) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5199"><span class="ln">5199 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lu_solve::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), LU_data, LU_pivots);</span>
<a name="l5200"><span class="ln">5200 </span></a><span class="s0">}</span>
<a name="l5201"><span class="ln">5201 </span></a>
<a name="l5202"><span class="ln">5202 </span></a><span class="s3">// aten::multinomial(Tensor self, SymInt num_samples, bool replacement=False, *, Generator? generator=None) -&gt; Tensor</span>
<a name="l5203"><span class="ln">5203 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::multinomial(int64_t num_samples, </span><span class="s1">bool </span><span class="s0">replacement, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5204"><span class="ln">5204 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::multinomial::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), num_samples, replacement, generator);</span>
<a name="l5205"><span class="ln">5205 </span></a><span class="s0">}</span>
<a name="l5206"><span class="ln">5206 </span></a>
<a name="l5207"><span class="ln">5207 </span></a><span class="s3">// aten::multinomial(Tensor self, SymInt num_samples, bool replacement=False, *, Generator? generator=None) -&gt; Tensor</span>
<a name="l5208"><span class="ln">5208 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::multinomial_symint(c10::SymInt num_samples, </span><span class="s1">bool </span><span class="s0">replacement, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5209"><span class="ln">5209 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::multinomial::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), num_samples, replacement, generator);</span>
<a name="l5210"><span class="ln">5210 </span></a><span class="s0">}</span>
<a name="l5211"><span class="ln">5211 </span></a>
<a name="l5212"><span class="ln">5212 </span></a><span class="s3">// aten::lgamma_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l5213"><span class="ln">5213 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::lgamma_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5214"><span class="ln">5214 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lgamma_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5215"><span class="ln">5215 </span></a><span class="s0">}</span>
<a name="l5216"><span class="ln">5216 </span></a>
<a name="l5217"><span class="ln">5217 </span></a><span class="s3">// aten::lgamma(Tensor self) -&gt; Tensor</span>
<a name="l5218"><span class="ln">5218 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lgamma() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5219"><span class="ln">5219 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lgamma::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5220"><span class="ln">5220 </span></a><span class="s0">}</span>
<a name="l5221"><span class="ln">5221 </span></a>
<a name="l5222"><span class="ln">5222 </span></a><span class="s3">// aten::digamma(Tensor self) -&gt; Tensor</span>
<a name="l5223"><span class="ln">5223 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::digamma() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5224"><span class="ln">5224 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::digamma::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5225"><span class="ln">5225 </span></a><span class="s0">}</span>
<a name="l5226"><span class="ln">5226 </span></a>
<a name="l5227"><span class="ln">5227 </span></a><span class="s3">// aten::polygamma(int n, Tensor self) -&gt; Tensor</span>
<a name="l5228"><span class="ln">5228 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::polygamma(int64_t n) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5229"><span class="ln">5229 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::polygamma::call(n, </span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5230"><span class="ln">5230 </span></a><span class="s0">}</span>
<a name="l5231"><span class="ln">5231 </span></a>
<a name="l5232"><span class="ln">5232 </span></a><span class="s3">// aten::polygamma_(Tensor(a!) self, int n) -&gt; Tensor(a!)</span>
<a name="l5233"><span class="ln">5233 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::polygamma_(int64_t n) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5234"><span class="ln">5234 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::polygamma_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), n);</span>
<a name="l5235"><span class="ln">5235 </span></a><span class="s0">}</span>
<a name="l5236"><span class="ln">5236 </span></a>
<a name="l5237"><span class="ln">5237 </span></a><span class="s3">// aten::erfinv(Tensor self) -&gt; Tensor</span>
<a name="l5238"><span class="ln">5238 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::erfinv() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5239"><span class="ln">5239 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::erfinv::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5240"><span class="ln">5240 </span></a><span class="s0">}</span>
<a name="l5241"><span class="ln">5241 </span></a>
<a name="l5242"><span class="ln">5242 </span></a><span class="s3">// aten::erfinv_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l5243"><span class="ln">5243 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::erfinv_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5244"><span class="ln">5244 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::erfinv_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5245"><span class="ln">5245 </span></a><span class="s0">}</span>
<a name="l5246"><span class="ln">5246 </span></a>
<a name="l5247"><span class="ln">5247 </span></a><span class="s3">// aten::i0(Tensor self) -&gt; Tensor</span>
<a name="l5248"><span class="ln">5248 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::i0() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5249"><span class="ln">5249 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::i0::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5250"><span class="ln">5250 </span></a><span class="s0">}</span>
<a name="l5251"><span class="ln">5251 </span></a>
<a name="l5252"><span class="ln">5252 </span></a><span class="s3">// aten::i0_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l5253"><span class="ln">5253 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::i0_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5254"><span class="ln">5254 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::i0_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5255"><span class="ln">5255 </span></a><span class="s0">}</span>
<a name="l5256"><span class="ln">5256 </span></a>
<a name="l5257"><span class="ln">5257 </span></a><span class="s3">// aten::sign(Tensor self) -&gt; Tensor</span>
<a name="l5258"><span class="ln">5258 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::sign() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5259"><span class="ln">5259 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sign::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5260"><span class="ln">5260 </span></a><span class="s0">}</span>
<a name="l5261"><span class="ln">5261 </span></a>
<a name="l5262"><span class="ln">5262 </span></a><span class="s3">// aten::sign_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<a name="l5263"><span class="ln">5263 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::sign_() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5264"><span class="ln">5264 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sign_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5265"><span class="ln">5265 </span></a><span class="s0">}</span>
<a name="l5266"><span class="ln">5266 </span></a>
<a name="l5267"><span class="ln">5267 </span></a><span class="s3">// aten::signbit(Tensor self) -&gt; Tensor</span>
<a name="l5268"><span class="ln">5268 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::signbit() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5269"><span class="ln">5269 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::signbit::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5270"><span class="ln">5270 </span></a><span class="s0">}</span>
<a name="l5271"><span class="ln">5271 </span></a>
<a name="l5272"><span class="ln">5272 </span></a><span class="s3">// aten::dist(Tensor self, Tensor other, Scalar p=2) -&gt; Tensor</span>
<a name="l5273"><span class="ln">5273 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::dist(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; p) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5274"><span class="ln">5274 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::dist::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other, p);</span>
<a name="l5275"><span class="ln">5275 </span></a><span class="s0">}</span>
<a name="l5276"><span class="ln">5276 </span></a>
<a name="l5277"><span class="ln">5277 </span></a><span class="s3">// aten::atan2_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5278"><span class="ln">5278 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::atan2_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5279"><span class="ln">5279 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::atan2_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5280"><span class="ln">5280 </span></a><span class="s0">}</span>
<a name="l5281"><span class="ln">5281 </span></a>
<a name="l5282"><span class="ln">5282 </span></a><span class="s3">// aten::atan2(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5283"><span class="ln">5283 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::atan2(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5284"><span class="ln">5284 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::atan2::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5285"><span class="ln">5285 </span></a><span class="s0">}</span>
<a name="l5286"><span class="ln">5286 </span></a>
<a name="l5287"><span class="ln">5287 </span></a><span class="s3">// aten::arctan2(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5288"><span class="ln">5288 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::arctan2(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5289"><span class="ln">5289 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arctan2::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5290"><span class="ln">5290 </span></a><span class="s0">}</span>
<a name="l5291"><span class="ln">5291 </span></a>
<a name="l5292"><span class="ln">5292 </span></a><span class="s3">// aten::arctan2_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5293"><span class="ln">5293 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::arctan2_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5294"><span class="ln">5294 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::arctan2_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5295"><span class="ln">5295 </span></a><span class="s0">}</span>
<a name="l5296"><span class="ln">5296 </span></a>
<a name="l5297"><span class="ln">5297 </span></a><span class="s3">// aten::lerp.Scalar(Tensor self, Tensor end, Scalar weight) -&gt; Tensor</span>
<a name="l5298"><span class="ln">5298 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lerp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; weight) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5299"><span class="ln">5299 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lerp_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), end, weight);</span>
<a name="l5300"><span class="ln">5300 </span></a><span class="s0">}</span>
<a name="l5301"><span class="ln">5301 </span></a>
<a name="l5302"><span class="ln">5302 </span></a><span class="s3">// aten::lerp.Tensor(Tensor self, Tensor end, Tensor weight) -&gt; Tensor</span>
<a name="l5303"><span class="ln">5303 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::lerp(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; end, </span><span class="s1">const </span><span class="s0">at::Tensor &amp; weight) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5304"><span class="ln">5304 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::lerp_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), end, weight);</span>
<a name="l5305"><span class="ln">5305 </span></a><span class="s0">}</span>
<a name="l5306"><span class="ln">5306 </span></a>
<a name="l5307"><span class="ln">5307 </span></a><span class="s3">// aten::histc(Tensor self, int bins=100, Scalar min=0, Scalar max=0) -&gt; Tensor</span>
<a name="l5308"><span class="ln">5308 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::histc(int64_t bins, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; min, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; max) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5309"><span class="ln">5309 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::histc::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), bins, min, max);</span>
<a name="l5310"><span class="ln">5310 </span></a><span class="s0">}</span>
<a name="l5311"><span class="ln">5311 </span></a>
<a name="l5312"><span class="ln">5312 </span></a><span class="s3">// aten::histogram.bins_tensor(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<a name="l5313"><span class="ln">5313 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::histogram(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; bins, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weight, </span><span class="s1">bool </span><span class="s0">density) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5314"><span class="ln">5314 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::histogram_bins_tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), bins, weight, density);</span>
<a name="l5315"><span class="ln">5315 </span></a><span class="s0">}</span>
<a name="l5316"><span class="ln">5316 </span></a>
<a name="l5317"><span class="ln">5317 </span></a><span class="s3">// aten::histogram.bin_ct(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<a name="l5318"><span class="ln">5318 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::histogram(int64_t bins, ::std::optional&lt;at::ArrayRef&lt;</span><span class="s1">double</span><span class="s0">&gt;&gt; range, </span><span class="s1">const </span><span class="s0">::std::optional&lt;at::Tensor&gt; &amp; weight, </span><span class="s1">bool </span><span class="s0">density) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5319"><span class="ln">5319 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::histogram_bin_ct::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), bins, range, weight, density);</span>
<a name="l5320"><span class="ln">5320 </span></a><span class="s0">}</span>
<a name="l5321"><span class="ln">5321 </span></a>
<a name="l5322"><span class="ln">5322 </span></a><span class="s3">// aten::fmod.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l5323"><span class="ln">5323 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::fmod(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5324"><span class="ln">5324 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fmod_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5325"><span class="ln">5325 </span></a><span class="s0">}</span>
<a name="l5326"><span class="ln">5326 </span></a>
<a name="l5327"><span class="ln">5327 </span></a><span class="s3">// aten::fmod_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l5328"><span class="ln">5328 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::fmod_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5329"><span class="ln">5329 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fmod__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5330"><span class="ln">5330 </span></a><span class="s0">}</span>
<a name="l5331"><span class="ln">5331 </span></a>
<a name="l5332"><span class="ln">5332 </span></a><span class="s3">// aten::fmod.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5333"><span class="ln">5333 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::fmod(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5334"><span class="ln">5334 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fmod_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5335"><span class="ln">5335 </span></a><span class="s0">}</span>
<a name="l5336"><span class="ln">5336 </span></a>
<a name="l5337"><span class="ln">5337 </span></a><span class="s3">// aten::fmod_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5338"><span class="ln">5338 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::fmod_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5339"><span class="ln">5339 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fmod__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5340"><span class="ln">5340 </span></a><span class="s0">}</span>
<a name="l5341"><span class="ln">5341 </span></a>
<a name="l5342"><span class="ln">5342 </span></a><span class="s3">// aten::hypot(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5343"><span class="ln">5343 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::hypot(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5344"><span class="ln">5344 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::hypot::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5345"><span class="ln">5345 </span></a><span class="s0">}</span>
<a name="l5346"><span class="ln">5346 </span></a>
<a name="l5347"><span class="ln">5347 </span></a><span class="s3">// aten::hypot_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5348"><span class="ln">5348 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::hypot_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5349"><span class="ln">5349 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::hypot_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5350"><span class="ln">5350 </span></a><span class="s0">}</span>
<a name="l5351"><span class="ln">5351 </span></a>
<a name="l5352"><span class="ln">5352 </span></a><span class="s3">// aten::igamma(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5353"><span class="ln">5353 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::igamma(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5354"><span class="ln">5354 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::igamma::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5355"><span class="ln">5355 </span></a><span class="s0">}</span>
<a name="l5356"><span class="ln">5356 </span></a>
<a name="l5357"><span class="ln">5357 </span></a><span class="s3">// aten::igamma_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5358"><span class="ln">5358 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::igamma_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5359"><span class="ln">5359 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::igamma_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5360"><span class="ln">5360 </span></a><span class="s0">}</span>
<a name="l5361"><span class="ln">5361 </span></a>
<a name="l5362"><span class="ln">5362 </span></a><span class="s3">// aten::igammac(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5363"><span class="ln">5363 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::igammac(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5364"><span class="ln">5364 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::igammac::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5365"><span class="ln">5365 </span></a><span class="s0">}</span>
<a name="l5366"><span class="ln">5366 </span></a>
<a name="l5367"><span class="ln">5367 </span></a><span class="s3">// aten::igammac_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5368"><span class="ln">5368 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::igammac_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5369"><span class="ln">5369 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::igammac_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5370"><span class="ln">5370 </span></a><span class="s0">}</span>
<a name="l5371"><span class="ln">5371 </span></a>
<a name="l5372"><span class="ln">5372 </span></a><span class="s3">// aten::nextafter(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5373"><span class="ln">5373 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nextafter(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5374"><span class="ln">5374 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nextafter::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5375"><span class="ln">5375 </span></a><span class="s0">}</span>
<a name="l5376"><span class="ln">5376 </span></a>
<a name="l5377"><span class="ln">5377 </span></a><span class="s3">// aten::nextafter_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5378"><span class="ln">5378 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::nextafter_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5379"><span class="ln">5379 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nextafter_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5380"><span class="ln">5380 </span></a><span class="s0">}</span>
<a name="l5381"><span class="ln">5381 </span></a>
<a name="l5382"><span class="ln">5382 </span></a><span class="s3">// aten::remainder.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<a name="l5383"><span class="ln">5383 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::remainder(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5384"><span class="ln">5384 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::remainder_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5385"><span class="ln">5385 </span></a><span class="s0">}</span>
<a name="l5386"><span class="ln">5386 </span></a>
<a name="l5387"><span class="ln">5387 </span></a><span class="s3">// aten::remainder_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<a name="l5388"><span class="ln">5388 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::remainder_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5389"><span class="ln">5389 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::remainder__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5390"><span class="ln">5390 </span></a><span class="s0">}</span>
<a name="l5391"><span class="ln">5391 </span></a>
<a name="l5392"><span class="ln">5392 </span></a><span class="s3">// aten::remainder.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5393"><span class="ln">5393 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::remainder(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5394"><span class="ln">5394 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::remainder_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5395"><span class="ln">5395 </span></a><span class="s0">}</span>
<a name="l5396"><span class="ln">5396 </span></a>
<a name="l5397"><span class="ln">5397 </span></a><span class="s3">// aten::remainder_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<a name="l5398"><span class="ln">5398 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::remainder_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5399"><span class="ln">5399 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::remainder__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5400"><span class="ln">5400 </span></a><span class="s0">}</span>
<a name="l5401"><span class="ln">5401 </span></a>
<a name="l5402"><span class="ln">5402 </span></a><span class="s3">// aten::min(Tensor self) -&gt; Tensor</span>
<a name="l5403"><span class="ln">5403 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::min() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5404"><span class="ln">5404 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::min::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5405"><span class="ln">5405 </span></a><span class="s0">}</span>
<a name="l5406"><span class="ln">5406 </span></a>
<a name="l5407"><span class="ln">5407 </span></a><span class="s3">// aten::fmin(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5408"><span class="ln">5408 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::fmin(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5409"><span class="ln">5409 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fmin::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5410"><span class="ln">5410 </span></a><span class="s0">}</span>
<a name="l5411"><span class="ln">5411 </span></a>
<a name="l5412"><span class="ln">5412 </span></a><span class="s3">// aten::max(Tensor self) -&gt; Tensor</span>
<a name="l5413"><span class="ln">5413 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::max() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5414"><span class="ln">5414 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::max::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5415"><span class="ln">5415 </span></a><span class="s0">}</span>
<a name="l5416"><span class="ln">5416 </span></a>
<a name="l5417"><span class="ln">5417 </span></a><span class="s3">// aten::fmax(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5418"><span class="ln">5418 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::fmax(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5419"><span class="ln">5419 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::fmax::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5420"><span class="ln">5420 </span></a><span class="s0">}</span>
<a name="l5421"><span class="ln">5421 </span></a>
<a name="l5422"><span class="ln">5422 </span></a><span class="s3">// aten::maximum(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5423"><span class="ln">5423 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::maximum(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5424"><span class="ln">5424 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::maximum::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5425"><span class="ln">5425 </span></a><span class="s0">}</span>
<a name="l5426"><span class="ln">5426 </span></a>
<a name="l5427"><span class="ln">5427 </span></a><span class="s3">// aten::max.other(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5428"><span class="ln">5428 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::max(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5429"><span class="ln">5429 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::max_other::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5430"><span class="ln">5430 </span></a><span class="s0">}</span>
<a name="l5431"><span class="ln">5431 </span></a>
<a name="l5432"><span class="ln">5432 </span></a><span class="s3">// aten::minimum(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5433"><span class="ln">5433 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::minimum(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5434"><span class="ln">5434 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::minimum::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5435"><span class="ln">5435 </span></a><span class="s0">}</span>
<a name="l5436"><span class="ln">5436 </span></a>
<a name="l5437"><span class="ln">5437 </span></a><span class="s3">// aten::min.other(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5438"><span class="ln">5438 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::min(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5439"><span class="ln">5439 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::min_other::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5440"><span class="ln">5440 </span></a><span class="s0">}</span>
<a name="l5441"><span class="ln">5441 </span></a>
<a name="l5442"><span class="ln">5442 </span></a><span class="s3">// aten::quantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<a name="l5443"><span class="ln">5443 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::quantile(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim, c10::string_view interpolation) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5444"><span class="ln">5444 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::quantile::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), q, dim, keepdim, interpolation);</span>
<a name="l5445"><span class="ln">5445 </span></a><span class="s0">}</span>
<a name="l5446"><span class="ln">5446 </span></a>
<a name="l5447"><span class="ln">5447 </span></a><span class="s3">// aten::quantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<a name="l5448"><span class="ln">5448 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::quantile(</span><span class="s1">double </span><span class="s0">q, ::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim, c10::string_view interpolation) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5449"><span class="ln">5449 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::quantile_scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), q, dim, keepdim, interpolation);</span>
<a name="l5450"><span class="ln">5450 </span></a><span class="s0">}</span>
<a name="l5451"><span class="ln">5451 </span></a>
<a name="l5452"><span class="ln">5452 </span></a><span class="s3">// aten::nanquantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<a name="l5453"><span class="ln">5453 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nanquantile(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim, c10::string_view interpolation) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5454"><span class="ln">5454 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nanquantile::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), q, dim, keepdim, interpolation);</span>
<a name="l5455"><span class="ln">5455 </span></a><span class="s0">}</span>
<a name="l5456"><span class="ln">5456 </span></a>
<a name="l5457"><span class="ln">5457 </span></a><span class="s3">// aten::nanquantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<a name="l5458"><span class="ln">5458 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::nanquantile(</span><span class="s1">double </span><span class="s0">q, ::std::optional&lt;int64_t&gt; dim, </span><span class="s1">bool </span><span class="s0">keepdim, c10::string_view interpolation) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5459"><span class="ln">5459 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::nanquantile_scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), q, dim, keepdim, interpolation);</span>
<a name="l5460"><span class="ln">5460 </span></a><span class="s0">}</span>
<a name="l5461"><span class="ln">5461 </span></a>
<a name="l5462"><span class="ln">5462 </span></a><span class="s3">// aten::sort(Tensor self, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l5463"><span class="ln">5463 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(int64_t dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5464"><span class="ln">5464 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sort::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, descending);</span>
<a name="l5465"><span class="ln">5465 </span></a><span class="s0">}</span>
<a name="l5466"><span class="ln">5466 </span></a>
<a name="l5467"><span class="ln">5467 </span></a><span class="s3">// aten::sort.stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l5468"><span class="ln">5468 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; stable, int64_t dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5469"><span class="ln">5469 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sort_stable::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), stable, dim, descending);</span>
<a name="l5470"><span class="ln">5470 </span></a><span class="s0">}</span>
<a name="l5471"><span class="ln">5471 </span></a>
<a name="l5472"><span class="ln">5472 </span></a><span class="s3">// aten::sort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l5473"><span class="ln">5473 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5474"><span class="ln">5474 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sort_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, descending);</span>
<a name="l5475"><span class="ln">5475 </span></a><span class="s0">}</span>
<a name="l5476"><span class="ln">5476 </span></a>
<a name="l5477"><span class="ln">5477 </span></a><span class="s3">// aten::sort.dimname_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<a name="l5478"><span class="ln">5478 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(::std::optional&lt;</span><span class="s1">bool</span><span class="s0">&gt; stable, at::Dimname dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5479"><span class="ln">5479 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::sort_dimname_stable::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), stable, dim, descending);</span>
<a name="l5480"><span class="ln">5480 </span></a><span class="s0">}</span>
<a name="l5481"><span class="ln">5481 </span></a>
<a name="l5482"><span class="ln">5482 </span></a><span class="s3">// aten::msort(Tensor self) -&gt; Tensor</span>
<a name="l5483"><span class="ln">5483 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::msort() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5484"><span class="ln">5484 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::msort::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5485"><span class="ln">5485 </span></a><span class="s0">}</span>
<a name="l5486"><span class="ln">5486 </span></a>
<a name="l5487"><span class="ln">5487 </span></a><span class="s3">// aten::argsort(Tensor self, int dim=-1, bool descending=False) -&gt; Tensor</span>
<a name="l5488"><span class="ln">5488 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::argsort(int64_t dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5489"><span class="ln">5489 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::argsort::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, descending);</span>
<a name="l5490"><span class="ln">5490 </span></a><span class="s0">}</span>
<a name="l5491"><span class="ln">5491 </span></a>
<a name="l5492"><span class="ln">5492 </span></a><span class="s3">// aten::argsort.stable(Tensor self, *, bool stable, int dim=-1, bool descending=False) -&gt; Tensor</span>
<a name="l5493"><span class="ln">5493 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::argsort(</span><span class="s1">bool </span><span class="s0">stable, int64_t dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5494"><span class="ln">5494 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::argsort_stable::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), stable, dim, descending);</span>
<a name="l5495"><span class="ln">5495 </span></a><span class="s0">}</span>
<a name="l5496"><span class="ln">5496 </span></a>
<a name="l5497"><span class="ln">5497 </span></a><span class="s3">// aten::argsort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; Tensor</span>
<a name="l5498"><span class="ln">5498 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::argsort(at::Dimname dim, </span><span class="s1">bool </span><span class="s0">descending) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5499"><span class="ln">5499 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::argsort_dimname::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dim, descending);</span>
<a name="l5500"><span class="ln">5500 </span></a><span class="s0">}</span>
<a name="l5501"><span class="ln">5501 </span></a>
<a name="l5502"><span class="ln">5502 </span></a><span class="s3">// aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<a name="l5503"><span class="ln">5503 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::topk(int64_t k, int64_t dim, </span><span class="s1">bool </span><span class="s0">largest, </span><span class="s1">bool </span><span class="s0">sorted) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5504"><span class="ln">5504 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::topk::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dim, largest, sorted);</span>
<a name="l5505"><span class="ln">5505 </span></a><span class="s0">}</span>
<a name="l5506"><span class="ln">5506 </span></a>
<a name="l5507"><span class="ln">5507 </span></a><span class="s3">// aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<a name="l5508"><span class="ln">5508 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::topk_symint(c10::SymInt k, int64_t dim, </span><span class="s1">bool </span><span class="s0">largest, </span><span class="s1">bool </span><span class="s0">sorted) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5509"><span class="ln">5509 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::topk::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), k, dim, largest, sorted);</span>
<a name="l5510"><span class="ln">5510 </span></a><span class="s0">}</span>
<a name="l5511"><span class="ln">5511 </span></a>
<a name="l5512"><span class="ln">5512 </span></a><span class="s3">// aten::all(Tensor self) -&gt; Tensor</span>
<a name="l5513"><span class="ln">5513 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::all() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5514"><span class="ln">5514 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::all::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5515"><span class="ln">5515 </span></a><span class="s0">}</span>
<a name="l5516"><span class="ln">5516 </span></a>
<a name="l5517"><span class="ln">5517 </span></a><span class="s3">// aten::any(Tensor self) -&gt; Tensor</span>
<a name="l5518"><span class="ln">5518 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::any() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5519"><span class="ln">5519 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::any::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5520"><span class="ln">5520 </span></a><span class="s0">}</span>
<a name="l5521"><span class="ln">5521 </span></a>
<a name="l5522"><span class="ln">5522 </span></a><span class="s3">// aten::renorm(Tensor self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor</span>
<a name="l5523"><span class="ln">5523 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::renorm(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; p, int64_t dim, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; maxnorm) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5524"><span class="ln">5524 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::renorm::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dim, maxnorm);</span>
<a name="l5525"><span class="ln">5525 </span></a><span class="s0">}</span>
<a name="l5526"><span class="ln">5526 </span></a>
<a name="l5527"><span class="ln">5527 </span></a><span class="s3">// aten::renorm_(Tensor(a!) self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor(a!)</span>
<a name="l5528"><span class="ln">5528 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::renorm_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; p, int64_t dim, </span><span class="s1">const </span><span class="s0">at::Scalar &amp; maxnorm) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5529"><span class="ln">5529 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::renorm_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), p, dim, maxnorm);</span>
<a name="l5530"><span class="ln">5530 </span></a><span class="s0">}</span>
<a name="l5531"><span class="ln">5531 </span></a>
<a name="l5532"><span class="ln">5532 </span></a><span class="s3">// aten::unfold(Tensor(a) self, int dimension, int size, int step) -&gt; Tensor(a)</span>
<a name="l5533"><span class="ln">5533 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::unfold(int64_t dimension, int64_t size, int64_t step) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5534"><span class="ln">5534 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::unfold::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), dimension, size, step);</span>
<a name="l5535"><span class="ln">5535 </span></a><span class="s0">}</span>
<a name="l5536"><span class="ln">5536 </span></a>
<a name="l5537"><span class="ln">5537 </span></a><span class="s3">// aten::equal(Tensor self, Tensor other) -&gt; bool</span>
<a name="l5538"><span class="ln">5538 </span></a><span class="s2">inline </span><span class="s1">bool </span><span class="s0">Tensor::equal(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5539"><span class="ln">5539 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::equal::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5540"><span class="ln">5540 </span></a><span class="s0">}</span>
<a name="l5541"><span class="ln">5541 </span></a>
<a name="l5542"><span class="ln">5542 </span></a><span class="s3">// aten::pow.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<a name="l5543"><span class="ln">5543 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::pow(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5544"><span class="ln">5544 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::pow_Tensor_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5545"><span class="ln">5545 </span></a><span class="s0">}</span>
<a name="l5546"><span class="ln">5546 </span></a>
<a name="l5547"><span class="ln">5547 </span></a><span class="s3">// aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<a name="l5548"><span class="ln">5548 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::pow(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5549"><span class="ln">5549 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::pow_Tensor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5550"><span class="ln">5550 </span></a><span class="s0">}</span>
<a name="l5551"><span class="ln">5551 </span></a>
<a name="l5552"><span class="ln">5552 </span></a><span class="s3">// aten::pow_.Scalar(Tensor(a!) self, Scalar exponent) -&gt; Tensor(a!)</span>
<a name="l5553"><span class="ln">5553 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::pow_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5554"><span class="ln">5554 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::pow__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5555"><span class="ln">5555 </span></a><span class="s0">}</span>
<a name="l5556"><span class="ln">5556 </span></a>
<a name="l5557"><span class="ln">5557 </span></a><span class="s3">// aten::pow_.Tensor(Tensor(a!) self, Tensor exponent) -&gt; Tensor(a!)</span>
<a name="l5558"><span class="ln">5558 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::pow_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5559"><span class="ln">5559 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::pow__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5560"><span class="ln">5560 </span></a><span class="s0">}</span>
<a name="l5561"><span class="ln">5561 </span></a>
<a name="l5562"><span class="ln">5562 </span></a><span class="s3">// aten::float_power.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<a name="l5563"><span class="ln">5563 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::float_power(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5564"><span class="ln">5564 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::float_power_Tensor_Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5565"><span class="ln">5565 </span></a><span class="s0">}</span>
<a name="l5566"><span class="ln">5566 </span></a>
<a name="l5567"><span class="ln">5567 </span></a><span class="s3">// aten::float_power.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<a name="l5568"><span class="ln">5568 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::float_power(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5569"><span class="ln">5569 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::float_power_Tensor_Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5570"><span class="ln">5570 </span></a><span class="s0">}</span>
<a name="l5571"><span class="ln">5571 </span></a>
<a name="l5572"><span class="ln">5572 </span></a><span class="s3">// aten::float_power_.Scalar(Tensor(a!) self, Scalar exponent) -&gt; Tensor(a!)</span>
<a name="l5573"><span class="ln">5573 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::float_power_(</span><span class="s1">const </span><span class="s0">at::Scalar &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5574"><span class="ln">5574 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::float_power__Scalar::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5575"><span class="ln">5575 </span></a><span class="s0">}</span>
<a name="l5576"><span class="ln">5576 </span></a>
<a name="l5577"><span class="ln">5577 </span></a><span class="s3">// aten::float_power_.Tensor(Tensor(a!) self, Tensor exponent) -&gt; Tensor(a!)</span>
<a name="l5578"><span class="ln">5578 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::float_power_(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; exponent) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5579"><span class="ln">5579 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::float_power__Tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), exponent);</span>
<a name="l5580"><span class="ln">5580 </span></a><span class="s0">}</span>
<a name="l5581"><span class="ln">5581 </span></a>
<a name="l5582"><span class="ln">5582 </span></a><span class="s3">// aten::normal_(Tensor(a!) self, float mean=0, float std=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<a name="l5583"><span class="ln">5583 </span></a><span class="s2">inline </span><span class="s0">at::Tensor &amp; Tensor::normal_(</span><span class="s1">double </span><span class="s0">mean, </span><span class="s1">double </span><span class="s0">std, ::std::optional&lt;at::Generator&gt; generator) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5584"><span class="ln">5584 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::normal_::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), mean, std, generator);</span>
<a name="l5585"><span class="ln">5585 </span></a><span class="s0">}</span>
<a name="l5586"><span class="ln">5586 </span></a>
<a name="l5587"><span class="ln">5587 </span></a><span class="s3">// aten::alias(Tensor(a) self) -&gt; Tensor(a)</span>
<a name="l5588"><span class="ln">5588 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::alias() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5589"><span class="ln">5589 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::alias::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5590"><span class="ln">5590 </span></a><span class="s0">}</span>
<a name="l5591"><span class="ln">5591 </span></a>
<a name="l5592"><span class="ln">5592 </span></a><span class="s3">// aten::isfinite(Tensor self) -&gt; Tensor</span>
<a name="l5593"><span class="ln">5593 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isfinite() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5594"><span class="ln">5594 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isfinite::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5595"><span class="ln">5595 </span></a><span class="s0">}</span>
<a name="l5596"><span class="ln">5596 </span></a>
<a name="l5597"><span class="ln">5597 </span></a><span class="s3">// aten::isinf(Tensor self) -&gt; Tensor</span>
<a name="l5598"><span class="ln">5598 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isinf() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5599"><span class="ln">5599 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isinf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5600"><span class="ln">5600 </span></a><span class="s0">}</span>
<a name="l5601"><span class="ln">5601 </span></a>
<a name="l5602"><span class="ln">5602 </span></a><span class="s3">// aten::record_stream(Tensor(a!) self, Stream s) -&gt; ()</span>
<a name="l5603"><span class="ln">5603 </span></a><span class="s2">inline </span><span class="s1">void </span><span class="s0">Tensor::record_stream(at::Stream s) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5604"><span class="ln">5604 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::record_stream::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), s);</span>
<a name="l5605"><span class="ln">5605 </span></a><span class="s0">}</span>
<a name="l5606"><span class="ln">5606 </span></a>
<a name="l5607"><span class="ln">5607 </span></a><span class="s3">// aten::isposinf(Tensor self) -&gt; Tensor</span>
<a name="l5608"><span class="ln">5608 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isposinf() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5609"><span class="ln">5609 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isposinf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5610"><span class="ln">5610 </span></a><span class="s0">}</span>
<a name="l5611"><span class="ln">5611 </span></a>
<a name="l5612"><span class="ln">5612 </span></a><span class="s3">// aten::isneginf(Tensor self) -&gt; Tensor</span>
<a name="l5613"><span class="ln">5613 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::isneginf() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5614"><span class="ln">5614 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::isneginf::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5615"><span class="ln">5615 </span></a><span class="s0">}</span>
<a name="l5616"><span class="ln">5616 </span></a>
<a name="l5617"><span class="ln">5617 </span></a><span class="s3">// aten::det(Tensor self) -&gt; Tensor</span>
<a name="l5618"><span class="ln">5618 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::det() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5619"><span class="ln">5619 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::det::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5620"><span class="ln">5620 </span></a><span class="s0">}</span>
<a name="l5621"><span class="ln">5621 </span></a>
<a name="l5622"><span class="ln">5622 </span></a><span class="s3">// aten::slogdet(Tensor self) -&gt; (Tensor sign, Tensor logabsdet)</span>
<a name="l5623"><span class="ln">5623 </span></a><span class="s2">inline </span><span class="s0">::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::slogdet() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5624"><span class="ln">5624 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::slogdet::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5625"><span class="ln">5625 </span></a><span class="s0">}</span>
<a name="l5626"><span class="ln">5626 </span></a>
<a name="l5627"><span class="ln">5627 </span></a><span class="s3">// aten::logdet(Tensor self) -&gt; Tensor</span>
<a name="l5628"><span class="ln">5628 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::logdet() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5629"><span class="ln">5629 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::logdet::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5630"><span class="ln">5630 </span></a><span class="s0">}</span>
<a name="l5631"><span class="ln">5631 </span></a>
<a name="l5632"><span class="ln">5632 </span></a><span class="s3">// aten::inverse(Tensor self) -&gt; Tensor</span>
<a name="l5633"><span class="ln">5633 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::inverse() </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5634"><span class="ln">5634 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::inverse::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">));</span>
<a name="l5635"><span class="ln">5635 </span></a><span class="s0">}</span>
<a name="l5636"><span class="ln">5636 </span></a>
<a name="l5637"><span class="ln">5637 </span></a><span class="s3">// aten::inner(Tensor self, Tensor other) -&gt; Tensor</span>
<a name="l5638"><span class="ln">5638 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::inner(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; other) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5639"><span class="ln">5639 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::inner::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), other);</span>
<a name="l5640"><span class="ln">5640 </span></a><span class="s0">}</span>
<a name="l5641"><span class="ln">5641 </span></a>
<a name="l5642"><span class="ln">5642 </span></a><span class="s3">// aten::outer(Tensor self, Tensor vec2) -&gt; Tensor</span>
<a name="l5643"><span class="ln">5643 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::outer(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5644"><span class="ln">5644 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::outer::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), vec2);</span>
<a name="l5645"><span class="ln">5645 </span></a><span class="s0">}</span>
<a name="l5646"><span class="ln">5646 </span></a>
<a name="l5647"><span class="ln">5647 </span></a><span class="s3">// aten::ger(Tensor self, Tensor vec2) -&gt; Tensor</span>
<a name="l5648"><span class="ln">5648 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::ger(</span><span class="s1">const </span><span class="s0">at::Tensor &amp; vec2) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5649"><span class="ln">5649 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::ger::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), vec2);</span>
<a name="l5650"><span class="ln">5650 </span></a><span class="s0">}</span>
<a name="l5651"><span class="ln">5651 </span></a>
<a name="l5652"><span class="ln">5652 </span></a><span class="s3">// aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -&gt; Tensor</span>
<a name="l5653"><span class="ln">5653 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_padded_tensor(</span><span class="s1">double </span><span class="s0">padding, at::OptionalIntArrayRef output_size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5654"><span class="ln">5654 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_padded_tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), padding, output_size.has_value() ? ::std::make_optional(c10::fromIntArrayRefSlow(*output_size)) : ::std::nullopt);</span>
<a name="l5655"><span class="ln">5655 </span></a><span class="s0">}</span>
<a name="l5656"><span class="ln">5656 </span></a>
<a name="l5657"><span class="ln">5657 </span></a><span class="s3">// aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -&gt; Tensor</span>
<a name="l5658"><span class="ln">5658 </span></a><span class="s2">inline </span><span class="s0">at::Tensor Tensor::to_padded_tensor_symint(</span><span class="s1">double </span><span class="s0">padding, at::OptionalSymIntArrayRef output_size) </span><span class="s1">const </span><span class="s0">{</span>
<a name="l5659"><span class="ln">5659 </span></a>    <span class="s1">return </span><span class="s0">at::_ops::to_padded_tensor::call(</span><span class="s2">const_cast</span><span class="s0">&lt;Tensor&amp;&gt;(*</span><span class="s2">this</span><span class="s0">), padding, output_size);</span>
<a name="l5660"><span class="ln">5660 </span></a><span class="s0">}</span>
<a name="l5661"><span class="ln">5661 </span></a><span class="s0">} </span><span class="s3">// namespace at</span>
<a name="l5662"><span class="ln">5662 </span></a>
<a name="l5663"><span class="ln">5663 </span></a>
<a name="l5664"><span class="ln">5664 </span></a><span class="s2">namespace </span><span class="s0">c10 {</span>
<a name="l5665"><span class="ln">5665 </span></a><span class="s0">template &lt;&gt;</span>
<a name="l5666"><span class="ln">5666 </span></a><span class="s1">struct </span><span class="s0">MaybeOwnedTraits&lt;at::Tensor&gt; {</span>
<a name="l5667"><span class="ln">5667 </span></a>  <span class="s2">using </span><span class="s0">owned_type = at::Tensor;</span>
<a name="l5668"><span class="ln">5668 </span></a>  <span class="s2">using </span><span class="s0">borrow_type = at::Tensor;</span>
<a name="l5669"><span class="ln">5669 </span></a>
<a name="l5670"><span class="ln">5670 </span></a>  <span class="s1">static </span><span class="s0">borrow_type createBorrow(</span><span class="s1">const </span><span class="s0">owned_type&amp; from) {</span>
<a name="l5671"><span class="ln">5671 </span></a>    <span class="s3">// NOTE: this can be implemented without the special</span>
<a name="l5672"><span class="ln">5672 </span></a>    <span class="s3">// unsafe_borrow_t Tensor constructor as</span>
<a name="l5673"><span class="ln">5673 </span></a>    <span class="s3">//</span>
<a name="l5674"><span class="ln">5674 </span></a>    <span class="s3">// return borrow_type(c10::intrusive_ptr&lt;at::TensorImpl, at::UndefinedTensorImpl&gt;::reclaim(from.unsafeGetTensorImpl()));</span>
<a name="l5675"><span class="ln">5675 </span></a>    <span class="s3">//</span>
<a name="l5676"><span class="ln">5676 </span></a>    <span class="s3">// but that hurts inlining due to the nullptr check in the</span>
<a name="l5677"><span class="ln">5677 </span></a>    <span class="s3">// Tensor(c10::intrusive_ptr&lt;...&gt;) constructor. We already know</span>
<a name="l5678"><span class="ln">5678 </span></a>    <span class="s3">// that from.impl_ isn't null because from is a valid Tensor, so</span>
<a name="l5679"><span class="ln">5679 </span></a>    <span class="s3">// we needn't do the check again. (using __builtin_assume can</span>
<a name="l5680"><span class="ln">5680 </span></a>    <span class="s3">// avoid this, but wouldn't be portable to MSVC.)</span>
<a name="l5681"><span class="ln">5681 </span></a>    <span class="s1">return </span><span class="s0">borrow_type(borrow_type::unsafe_borrow_t{}, from);</span>
<a name="l5682"><span class="ln">5682 </span></a>  <span class="s0">}</span>
<a name="l5683"><span class="ln">5683 </span></a>
<a name="l5684"><span class="ln">5684 </span></a>  <span class="s1">static void </span><span class="s0">assignBorrow(borrow_type&amp; lhs, </span><span class="s1">const </span><span class="s0">borrow_type&amp; rhs) {</span>
<a name="l5685"><span class="ln">5685 </span></a>    <span class="s0">lhs.unsafeReleaseTensorImpl();</span>
<a name="l5686"><span class="ln">5686 </span></a>    <span class="s3">// See above note: this can be implemented with public API</span>
<a name="l5687"><span class="ln">5687 </span></a>    <span class="s3">// similarly to createBorrow(), but that would hurt inlining.</span>
<a name="l5688"><span class="ln">5688 </span></a>    <span class="s0">lhs = borrow_type(borrow_type::unsafe_borrow_t{}, rhs);</span>
<a name="l5689"><span class="ln">5689 </span></a>  <span class="s0">}</span>
<a name="l5690"><span class="ln">5690 </span></a>
<a name="l5691"><span class="ln">5691 </span></a>  <span class="s1">static void </span><span class="s0">destroyBorrow(borrow_type&amp; toDestroy) {</span>
<a name="l5692"><span class="ln">5692 </span></a>    <span class="s0">toDestroy.unsafeReleaseTensorImpl(); </span><span class="s3">// &quot;leak&quot; it, but it was already +0.</span>
<a name="l5693"><span class="ln">5693 </span></a>  <span class="s0">}</span>
<a name="l5694"><span class="ln">5694 </span></a>
<a name="l5695"><span class="ln">5695 </span></a>  <span class="s1">static const </span><span class="s0">owned_type&amp; referenceFromBorrow(</span><span class="s1">const </span><span class="s0">borrow_type&amp; borrow) {</span>
<a name="l5696"><span class="ln">5696 </span></a>    <span class="s1">return </span><span class="s0">borrow;</span>
<a name="l5697"><span class="ln">5697 </span></a>  <span class="s0">}</span>
<a name="l5698"><span class="ln">5698 </span></a>
<a name="l5699"><span class="ln">5699 </span></a>  <span class="s1">static const </span><span class="s0">owned_type* pointerFromBorrow(</span><span class="s1">const </span><span class="s0">borrow_type&amp; borrow) {</span>
<a name="l5700"><span class="ln">5700 </span></a>    <span class="s1">return </span><span class="s0">&amp;borrow;</span>
<a name="l5701"><span class="ln">5701 </span></a>  <span class="s0">}</span>
<a name="l5702"><span class="ln">5702 </span></a>
<a name="l5703"><span class="ln">5703 </span></a>  <span class="s1">static bool </span><span class="s0">debugBorrowIsValid(</span><span class="s1">const </span><span class="s0">borrow_type&amp; </span><span class="s3">/*borrow*/</span><span class="s0">) {</span>
<a name="l5704"><span class="ln">5704 </span></a>    <span class="s1">return </span><span class="s2">true</span><span class="s0">;</span>
<a name="l5705"><span class="ln">5705 </span></a>  <span class="s0">}</span>
<a name="l5706"><span class="ln">5706 </span></a><span class="s0">};</span>
<a name="l5707"><span class="ln">5707 </span></a>
<a name="l5708"><span class="ln">5708 </span></a><span class="s0">template &lt;&gt;</span>
<a name="l5709"><span class="ln">5709 </span></a><span class="s1">struct </span><span class="s0">ExclusivelyOwnedTraits&lt;at::Tensor&gt; {</span>
<a name="l5710"><span class="ln">5710 </span></a>  <span class="s2">using </span><span class="s0">repr_type = at::Tensor;</span>
<a name="l5711"><span class="ln">5711 </span></a>  <span class="s2">using </span><span class="s0">pointer_type = at::Tensor*;</span>
<a name="l5712"><span class="ln">5712 </span></a>  <span class="s2">using </span><span class="s0">const_pointer_type = </span><span class="s1">const </span><span class="s0">at::Tensor*;</span>
<a name="l5713"><span class="ln">5713 </span></a>
<a name="l5714"><span class="ln">5714 </span></a>  <span class="s1">static </span><span class="s0">repr_type nullRepr() {</span>
<a name="l5715"><span class="ln">5715 </span></a>    <span class="s1">return </span><span class="s0">at::Tensor();</span>
<a name="l5716"><span class="ln">5716 </span></a>  <span class="s0">}</span>
<a name="l5717"><span class="ln">5717 </span></a>
<a name="l5718"><span class="ln">5718 </span></a>  <span class="s0">template &lt;</span><span class="s2">class</span><span class="s0">... Args&gt;</span>
<a name="l5719"><span class="ln">5719 </span></a>  <span class="s1">static </span><span class="s0">repr_type createInPlace(Args&amp;&amp;... args) {</span>
<a name="l5720"><span class="ln">5720 </span></a>    <span class="s1">return </span><span class="s0">at::Tensor(std::forward&lt;Args&gt;(args)...);</span>
<a name="l5721"><span class="ln">5721 </span></a>  <span class="s0">}</span>
<a name="l5722"><span class="ln">5722 </span></a>
<a name="l5723"><span class="ln">5723 </span></a>  <span class="s1">static </span><span class="s0">repr_type moveToRepr(at::Tensor&amp;&amp; x) {</span>
<a name="l5724"><span class="ln">5724 </span></a>    <span class="s1">return </span><span class="s0">std::move(x);</span>
<a name="l5725"><span class="ln">5725 </span></a>  <span class="s0">}</span>
<a name="l5726"><span class="ln">5726 </span></a>
<a name="l5727"><span class="ln">5727 </span></a>  <span class="s1">static void </span><span class="s0">destroyOwned(at::Tensor&amp; x) {</span>
<a name="l5728"><span class="ln">5728 </span></a>    <span class="s1">return </span><span class="s0">ExclusivelyOwnedTraits&lt;at::TensorBase&gt;::destroyOwned(x);</span>
<a name="l5729"><span class="ln">5729 </span></a>  <span class="s0">}</span>
<a name="l5730"><span class="ln">5730 </span></a>
<a name="l5731"><span class="ln">5731 </span></a>  <span class="s1">static </span><span class="s0">at::Tensor take(at::Tensor&amp; x) {</span>
<a name="l5732"><span class="ln">5732 </span></a>    <span class="s1">return </span><span class="s0">std::move(x);</span>
<a name="l5733"><span class="ln">5733 </span></a>  <span class="s0">}</span>
<a name="l5734"><span class="ln">5734 </span></a>
<a name="l5735"><span class="ln">5735 </span></a>  <span class="s1">static </span><span class="s0">pointer_type getImpl(repr_type&amp; x) {</span>
<a name="l5736"><span class="ln">5736 </span></a>    <span class="s1">return </span><span class="s0">&amp;x;</span>
<a name="l5737"><span class="ln">5737 </span></a>  <span class="s0">}</span>
<a name="l5738"><span class="ln">5738 </span></a>
<a name="l5739"><span class="ln">5739 </span></a>  <span class="s1">static </span><span class="s0">const_pointer_type getImpl(</span><span class="s1">const </span><span class="s0">repr_type&amp; x) {</span>
<a name="l5740"><span class="ln">5740 </span></a>    <span class="s1">return </span><span class="s0">&amp;x;</span>
<a name="l5741"><span class="ln">5741 </span></a>  <span class="s0">}</span>
<a name="l5742"><span class="ln">5742 </span></a><span class="s0">};</span>
<a name="l5743"><span class="ln">5743 </span></a><span class="s0">} </span><span class="s3">// namespace c10</span>
<a name="l5744"><span class="ln">5744 </span></a>
<a name="l5745"><span class="ln">5745 </span></a><span class="s2">namespace </span><span class="s0">at {</span>
<a name="l5746"><span class="ln">5746 </span></a>
<a name="l5747"><span class="ln">5747 </span></a><span class="s2">inline </span><span class="s0">c10::MaybeOwned&lt;Tensor&gt; borrow_from_optional_tensor(</span>
<a name="l5748"><span class="ln">5748 </span></a>    <span class="s1">const </span><span class="s0">std::optional&lt;Tensor&gt;&amp; opt) {</span>
<a name="l5749"><span class="ln">5749 </span></a>  <span class="s1">return </span><span class="s0">opt.has_value()</span>
<a name="l5750"><span class="ln">5750 </span></a>    <span class="s0">? c10::MaybeOwned&lt;Tensor&gt;::borrowed(*opt)</span>
<a name="l5751"><span class="ln">5751 </span></a>    <span class="s0">: c10::MaybeOwned&lt;Tensor&gt;::owned(std::in_place);</span>
<a name="l5752"><span class="ln">5752 </span></a><span class="s0">}</span>
<a name="l5753"><span class="ln">5753 </span></a>
<a name="l5754"><span class="ln">5754 </span></a><span class="s2">inline </span><span class="s0">c10::MaybeOwned&lt;Tensor&gt; Tensor::expect_contiguous(MemoryFormat memory_format) </span><span class="s1">const </span><span class="s0">&amp; {</span>
<a name="l5755"><span class="ln">5755 </span></a>  <span class="s1">if </span><span class="s0">(is_contiguous(memory_format)) {</span>
<a name="l5756"><span class="ln">5756 </span></a>    <span class="s1">return </span><span class="s0">c10::MaybeOwned&lt;Tensor&gt;::borrowed(*</span><span class="s2">this</span><span class="s0">);</span>
<a name="l5757"><span class="ln">5757 </span></a>  <span class="s0">} </span><span class="s1">else </span><span class="s0">{</span>
<a name="l5758"><span class="ln">5758 </span></a>    <span class="s1">return </span><span class="s0">c10::MaybeOwned&lt;Tensor&gt;::owned(__dispatch_contiguous(memory_format));</span>
<a name="l5759"><span class="ln">5759 </span></a>  <span class="s0">}</span>
<a name="l5760"><span class="ln">5760 </span></a><span class="s0">}</span>
<a name="l5761"><span class="ln">5761 </span></a><span class="s0">} </span><span class="s3">// namespace at</span>
<a name="l5762"><span class="ln">5762 </span></a></pre>
</body>
</html>